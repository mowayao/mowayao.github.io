<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Kaggle比赛小结-iMaterialist Challenge (Furniture) at FGVC5]]></title>
      <url>/2018/06/01/Kaggle%E6%AF%94%E8%B5%9B%E5%B0%8F%E7%BB%93-iMaterialist-Challenge-Furniture-at-FGVC5/</url>
      <content type="html"><![CDATA[<p><a href="https://www.kaggle.com/c/imaterialist-challenge-furniture-2018" target="_blank" rel="external">https://www.kaggle.com/c/imaterialist-challenge-furniture-2018</a></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1frw1y1wwhhj31fa02adg9.jpg" alt=""></p>
<p>参加完比赛，做个简单的总结：</p>
<ul>
<li>数据增强：random flip, color jitter, resize and crop</li>
<li>数据的不平衡需要设置采样权重(这个好像不一定能work)</li>
<li>网络模型，DenseNet201，SENet，InceptionResNetv2，SEResNext</li>
<li>Focal Loss不work</li>
<li>Adam or SGD</li>
<li>Multi-crop for testing</li>
<li>Ensemble: 取log后相加</li>
</ul>
]]></content>
      
        <categories>
            
            <category> competition </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
            <tag> computer vision </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Leetcode Hard DP]]></title>
      <url>/2018/06/01/Leetcode-Hard-DP/</url>
      <content type="html"><![CDATA[<p>[TOC]</p>
<p>###72. Edit Distance</p>
<p>Given two words word1 and word2, find the minimum number of operations required to convert word1 to word2.<br>You have the following 3 operations permitted on a word:</p>
<ol>
<li>Insert a character</li>
<li>Delete a character</li>
<li>Replace a character</li>
</ol>
<p>Example 1:</p>
<p>Input: word1 = “horse”, word2 = “ros”<br>Output: 3<br>Explanation:<br>horse -&gt; rorse (replace ‘h’ with ‘r’)<br>rorse -&gt; rose (remove ‘r’)<br>rose -&gt; ros (remove ‘e’)</p>
<p>Example 2:</p>
<p>Input: word1 = “intention”, word2 = “execution”<br>Output: 5<br>Explanation:<br>intention -&gt; inention (remove ‘t’)<br>inention -&gt; enention (replace ‘i’ with ‘e’)<br>enention -&gt; exention (replace ‘n’ with ‘x’)<br>exention -&gt; exection (replace ‘n’ with ‘c’)<br>exection -&gt; execution (insert ‘u’)</p>
<p>dp(i,j)的后续状态有dp(i-1, j)+1, dp(i, j-1)+1, dp(i-1, j-1)+1分别表示(删除或添加)和(替换)</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minDistance</span><span class="params">(<span class="built_in">string</span> word1, <span class="built_in">string</span> word2)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = word1.size(), m = word2.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; dp(n+<span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(m+<span class="number">1</span>, <span class="number">1e9</span>));</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= n; i++) dp[i][<span class="number">0</span>] = i;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= m; j++) dp[<span class="number">0</span>][j] = j;</div><div class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= m; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (word1[i<span class="number">-1</span>] == word2[j<span class="number">-1</span>]) &#123;</div><div class="line">                    dp[i][j] = min(dp[i][j], dp[i<span class="number">-1</span>][j<span class="number">-1</span>]);</div><div class="line">                &#125;</div><div class="line">                dp[i][j] = min(dp[i][j], min(dp[i<span class="number">-1</span>][j], min(dp[i][j<span class="number">-1</span>], dp[i<span class="number">-1</span>][j<span class="number">-1</span>]))+<span class="number">1</span>);</div><div class="line">            &#125;</div><div class="line">        </div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[n][m];</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minDistance</span><span class="params">(<span class="built_in">string</span> word1, <span class="built_in">string</span> word2)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = word1.size(), m = word2.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(m+<span class="number">1</span>, <span class="number">1e9</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= m; i++) dp[i] = i;</div><div class="line">        <span class="comment">//dp[i-1j-1]</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</div><div class="line">            <span class="keyword">int</span> before = dp[<span class="number">0</span>];</div><div class="line">            dp[<span class="number">0</span>] = i;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= m; j++) &#123;</div><div class="line">                <span class="keyword">int</span> ret = <span class="number">1e9</span>;</div><div class="line">                <span class="keyword">if</span> (word1[i<span class="number">-1</span>] == word2[j<span class="number">-1</span>]) &#123;</div><div class="line">                    ret = min(ret, before);</div><div class="line">                &#125;</div><div class="line">                ret = min(ret, min(dp[j]+<span class="number">1</span>, min(dp[j<span class="number">-1</span>]+<span class="number">1</span>, before+<span class="number">1</span>)));</div><div class="line">                before = dp[j];</div><div class="line">                dp[j] = ret;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[m];</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>###664. Strange Printer</p>
<p>There is a strange printer with the following two special requirements:</p>
<ol>
<li>The printer can only print a sequence of the same character each time.</li>
<li>At each turn, the printer can print new characters starting from and ending at any places, and will cover the original existing characters.</li>
</ol>
<p>Given a string consists of lower English letters only, your job is to count the minimum number of turns the printer needed in order to print it.<br>Example 1:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Input: &quot;aaabbb&quot;</div><div class="line">Output: 2</div><div class="line">Explanation: Print &quot;aaa&quot; first and then print &quot;bbb&quot;.</div></pre></td></tr></table></figure>
<p>Example 2:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Input: &quot;aba&quot;</div><div class="line">Output: 2</div><div class="line">Explanation: Print &quot;aaa&quot; first and then print &quot;b&quot; from the second place of the string, which will cover the existing character &apos;a&apos;.</div></pre></td></tr></table></figure>
<p>Hint: Length of the given string will not exceed 100.</p>
<p>dp(i, j)　如果s[i]=s[j]，那么可以选择由dp(i-1, j)或者dp(i, j-1)搞定，否则的话就是寻找最佳的分割点</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; dp, <span class="built_in">string</span>&amp; s)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (l == r) <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span> (dp[l][r] != <span class="number">-1</span>) <span class="keyword">return</span> dp[l][r];</div><div class="line">        <span class="keyword">int</span> ret = <span class="number">1e9</span>;</div><div class="line">        <span class="keyword">if</span> (s[l] == s[r]) &#123;</div><div class="line">            ret = min(dfs(l+<span class="number">1</span>, r, dp, s), dfs(l, r<span class="number">-1</span>, dp, s));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = l; i &lt; r; i++) &#123;</div><div class="line">            ret = min(ret, dfs(l, i, dp, s)+dfs(i+<span class="number">1</span>,r, dp, s));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[l][r] = ret;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">strangePrinter</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = s.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; dp(n, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n, <span class="number">-1</span>));</div><div class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, s);</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="730-Count-Different-Palindromic-Subsequences"><a href="#730-Count-Different-Palindromic-Subsequences" class="headerlink" title="730. Count Different Palindromic Subsequences"></a>730. Count Different Palindromic Subsequences</h3><p>Given a string S, find the number of different non-empty palindromic subsequences in S, and <strong>return that number modulo 10^9 + 7.</strong></p>
<p>A subsequence of a string S is obtained by deleting 0 or more characters from S.</p>
<p>A sequence is palindromic if it is equal to the sequence reversed.</p>
<p>Two sequences <code>A_1, A_2, ...</code> and <code>B_1, B_2, ...</code> are different if there is some <code>i</code> for which <code>A_i != B_i</code>.</p>
<p><strong>Example 1:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Input: </div><div class="line">S = &apos;bccb&apos;</div><div class="line">Output: 6</div><div class="line">Explanation: </div><div class="line">The 6 different non-empty palindromic subsequences are &apos;b&apos;, &apos;c&apos;, &apos;bb&apos;, &apos;cc&apos;, &apos;bcb&apos;, &apos;bccb&apos;.</div><div class="line">Note that &apos;bcb&apos; is counted only once, even though it occurs twice.</div></pre></td></tr></table></figure>
<p><strong>Example 2:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Input: </div><div class="line">S = &apos;abcdabcdabcdabcdabcdabcdabcdabcddcbadcbadcbadcbadcbadcbadcbadcba&apos;</div><div class="line">Output: 104860361</div><div class="line">Explanation: </div><div class="line">There are 3104860382 different non-empty palindromic subsequences, which is 104860361 modulo 10^9 + 7.</div></pre></td></tr></table></figure>
<p><strong>Note:</strong></p>
<p>The length of <code>S</code> will be in the range <code>[1, 1000]</code>.</p>
<p>Each character <code>S[i]</code> will be in the set <code>{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;}</code>.</p>
<p>枚举当前位置可选择的字符，再往下迭代，如果存在一对合理的，那么总共有３种选择，一种是偶数结束，一种是奇数结束，还有一种是选择这两个继续向下迭代，这样保证没有重复，非常tricky!!!!</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> ll;</div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> mod = <span class="number">1e9</span> + <span class="number">7</span>;</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">countPalindromicSubsequences</span><span class="params">(<span class="built_in">string</span> S)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = S.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;ll&gt;&gt; dp(n, <span class="built_in">vector</span>&lt;ll&gt;(n, <span class="number">-1</span>));</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; idxs(<span class="number">4</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            idxs[S[i]-<span class="string">'a'</span>].push_back(i);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> d = dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, idxs);</div><div class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, idxs);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function">ll <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;ll&gt;&gt;&amp;dp, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; idxs)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (start &gt; end) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="keyword">if</span> (dp[start][end] != <span class="number">-1</span>) <span class="keyword">return</span> dp[start][end];</div><div class="line">        ll ans = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</div><div class="line">            <span class="keyword">auto</span> l = lower_bound(idxs[i].begin(), idxs[i].end(), start);</div><div class="line">            <span class="keyword">if</span> (l == idxs[i].end()) &#123;</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">int</span> left = *l;</div><div class="line">            <span class="keyword">auto</span> r = upper_bound(idxs[i].begin(), idxs[i].end(), end);</div><div class="line">            <span class="keyword">int</span> right = <span class="number">-1</span>;</div><div class="line">            <span class="keyword">if</span> (r == idxs[i].end()) &#123;</div><div class="line">                right = idxs[i].back();</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                r--;</div><div class="line">                right = *r;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span> (right == left) &#123;</div><div class="line">                ans = (ans + <span class="number">1</span>) % mod;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (right &gt; left) &#123;</div><div class="line">                ans = (ans + dfs(left+<span class="number">1</span>, right<span class="number">-1</span>, dp, idxs) + <span class="number">2</span>) % mod;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[start][end] = ans;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="97-Interleaving-String"><a href="#97-Interleaving-String" class="headerlink" title="97. Interleaving String"></a>97. Interleaving String</h3><p>Given <em>s1</em>, <em>s2</em>, <em>s3</em>, find whether <em>s3</em> is formed by the interleaving of <em>s1</em> and <em>s2</em>.</p>
<p><strong>Example 1:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: s1 = &quot;aabcc&quot;, s2 = &quot;dbbca&quot;, s3 = &quot;aadbbcbcac&quot;</div><div class="line">Output: true</div></pre></td></tr></table></figure>
<p><strong>Example 2:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: s1 = &quot;aabcc&quot;, s2 = &quot;dbbca&quot;, s3 = &quot;aadbbbaccc&quot;</div><div class="line">Output: false</div></pre></td></tr></table></figure>
<p>注意边界条件</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isInterleave</span><span class="params">(<span class="built_in">string</span> s1, <span class="built_in">string</span> s2, <span class="built_in">string</span> s3)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = s1.size(), m = s2.size(), t = s3.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>)  <span class="keyword">return</span> s2 == s3;</div><div class="line">        <span class="keyword">if</span> (m == <span class="number">0</span>)  <span class="keyword">return</span> s1 == s3;</div><div class="line">        <span class="keyword">if</span> (t == <span class="number">0</span>)  <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        <span class="keyword">if</span> (n+m != t) <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&gt; dp(n+<span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;(m+<span class="number">1</span>, <span class="literal">false</span>));</div><div class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="literal">true</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">if</span> (s3[i] == s1[i]) &#123;</div><div class="line">                dp[i+<span class="number">1</span>][<span class="number">0</span>] = dp[i][<span class="number">0</span>];</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                dp[i+<span class="number">1</span>][<span class="number">0</span>] = <span class="literal">false</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        </div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;</div><div class="line">            <span class="keyword">if</span> (s3[i] == s2[i]) &#123;</div><div class="line">                dp[<span class="number">0</span>][i+<span class="number">1</span>] = dp[<span class="number">0</span>][i];</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                dp[<span class="number">0</span>][i+<span class="number">1</span>] = <span class="literal">false</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; m; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (s3[i+j+<span class="number">1</span>] == s2[j]) &#123;</div><div class="line">                    dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = dp[i+<span class="number">1</span>][j+<span class="number">1</span>] || dp[i+<span class="number">1</span>][j];</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">if</span> (s3[i+j+<span class="number">1</span>] == s1[i]) &#123;</div><div class="line">                    dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = dp[i+<span class="number">1</span>][j+<span class="number">1</span>] || dp[i][j+<span class="number">1</span>];</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[n][m];</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="312-Burst-Balloons"><a href="#312-Burst-Balloons" class="headerlink" title="312. Burst Balloons"></a>312. Burst Balloons</h3><p>Given <code>n</code> balloons, indexed from <code>0</code> to <code>n-1</code>. Each balloon is painted with a number on it represented by array <code>nums</code>. You are asked to burst all the balloons. If the you burst balloon <code>i</code> you will get <code>nums[left] * nums[i] * nums[right]</code> coins. Here <code>left</code> and <code>right</code>are adjacent indices of <code>i</code>. After the burst, the <code>left</code> and <code>right</code> then becomes adjacent.</p>
<p>Find the maximum coins you can collect by bursting the balloons wisely.</p>
<p><strong>Note:</strong></p>
<ul>
<li>You may imagine <code>nums[-1] = nums[n] = 1</code>. They are not real therefore you can not burst them.</li>
<li>0 ≤ <code>n</code> ≤ 500, 0 ≤ <code>nums[i]</code> ≤ 100</li>
</ul>
<p><strong>Example:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Input: [3,1,5,8]</div><div class="line">Output: 167 </div><div class="line">Explanation: nums = [3,1,5,8] --&gt; [3,5,8] --&gt;   [3,8]   --&gt;  [8]  --&gt; []</div><div class="line">             coins =  3*1*5      +  3*5*8    +  1*3*8      + 1*8*1   = 167</div></pre></td></tr></table></figure>
<p>区间dp，选择中间burst的气球，然后分割区间，一个比较好用的trick就是在头尾补1</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxCoins</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">        nums.insert(nums.begin(), <span class="number">1</span>);</div><div class="line">        nums.insert(nums.end(), <span class="number">1</span>);</div><div class="line">        </div><div class="line">        <span class="keyword">int</span> n = nums.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; dp(n, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n, <span class="number">-1</span>));</div><div class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, nums);</div><div class="line">        <span class="comment">//return 0;</span></div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; dp, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (l+<span class="number">1</span> &gt;= r) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> (dp[l][r] != <span class="number">-1</span>) <span class="keyword">return</span> dp[l][r];</div><div class="line">        <span class="keyword">int</span> ret = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = l+<span class="number">1</span>; i &lt; r; i++) &#123;</div><div class="line">            ret = max(ret, nums[l]*nums[i]*nums[r] + dfs(l, i, dp, nums) + dfs(i, r, dp, nums));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[l][r] = ret;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="354-Russian-Doll-Envelopes"><a href="#354-Russian-Doll-Envelopes" class="headerlink" title="354. Russian Doll Envelopes"></a>354. Russian Doll Envelopes</h3><p>You have a number of envelopes with widths and heights given as a pair of integers <code>(w, h)</code>. One envelope can fit into another if and only if both the width and height of one envelope is greater than the width and height of the other envelope.</p>
<p>What is the maximum number of envelopes can you Russian doll? (put one inside other)</p>
<p><strong>Example:</strong><br>Given envelopes = <code>[[5,4],[6,4],[6,7],[2,3]]</code>, the maximum number of envelopes you can Russian doll is <code>3</code> ([2,3] =&gt; [5,4] =&gt; [6,7]).</p>
<p>思路类似最长上升子序列</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxEnvelopes</span><span class="params">(<span class="built_in">vector</span>&lt;pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;&amp; envelopes)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = envelopes.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        sort(envelopes.begin(), envelopes.end());</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(n, <span class="number">0</span>);</div><div class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++) &#123;</div><div class="line">            dp[i] = <span class="number">1</span>;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (envelopes[j].first &lt; envelopes[i].first &amp;&amp; envelopes[j].second &lt; envelopes[i].second)</div><div class="line">                    dp[i] = max(dp[i], dp[j]+<span class="number">1</span>);</div><div class="line">            &#125;</div><div class="line">           <span class="comment">// cout &lt;&lt; dp[i] &lt;&lt; endl;</span></div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> ret = <span class="number">1</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            ret = max(ret, dp[i]);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> ret;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxEnvelopes</span><span class="params">(<span class="built_in">vector</span>&lt;pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;&amp; envelopes)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = envelopes.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        sort(envelopes.begin(), envelopes.end(), [](pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&amp; p1, pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&amp; p2)&#123;</div><div class="line">            <span class="keyword">return</span> p1.first == p2.first ? p1.second &gt; p2.second : p1.first &lt; p2.first; <span class="comment">//当first相同时，second按大到小排序避免冲突！！！</span></div><div class="line">        &#125;);</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">int</span> l = lower_bound(dp.begin(), dp.end(), envelopes[i].second) - dp.begin();</div><div class="line">            <span class="keyword">if</span> (l == dp.size()) &#123;</div><div class="line">                dp.push_back(envelopes[i].second);</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                dp[l] = envelopes[i].second;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp.size();</div><div class="line">      </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="140-Word-Break-II"><a href="#140-Word-Break-II" class="headerlink" title="140. Word Break II"></a>140. Word Break II</h3><p>Given a <strong>non-empty</strong> string <em>s</em> and a dictionary <em>wordDict</em> containing a list of <strong>non-empty</strong> words, add spaces in <em>s</em> to construct a sentence where each word is a valid dictionary word. Return all such possible sentences.</p>
<p><strong>Note:</strong></p>
<ul>
<li>The same word in the dictionary may be reused multiple times in the segmentation.</li>
<li>You may assume the dictionary does not contain duplicate words.</li>
</ul>
<p><strong>Example 1:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">s = &quot;catsanddog&quot;</div><div class="line">wordDict = [&quot;cat&quot;, &quot;cats&quot;, &quot;and&quot;, &quot;sand&quot;, &quot;dog&quot;]</div><div class="line">Output:</div><div class="line">[</div><div class="line">  &quot;cats and dog&quot;,</div><div class="line">  &quot;cat sand dog&quot;</div><div class="line">]</div></pre></td></tr></table></figure>
<p><strong>Example 2:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">s = &quot;pineapplepenapple&quot;</div><div class="line">wordDict = [&quot;apple&quot;, &quot;pen&quot;, &quot;applepen&quot;, &quot;pine&quot;, &quot;pineapple&quot;]</div><div class="line">Output:</div><div class="line">[</div><div class="line">  &quot;pine apple pen apple&quot;,</div><div class="line">  &quot;pineapple pen apple&quot;,</div><div class="line">  &quot;pine applepen apple&quot;</div><div class="line">]</div><div class="line">Explanation: Note that you are allowed to reuse a dictionary word.</div></pre></td></tr></table></figure>
<p><strong>Example 3:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">s = &quot;catsandog&quot;</div><div class="line">wordDict = [&quot;cats&quot;, &quot;dog&quot;, &quot;sand&quot;, &quot;and&quot;, &quot;cat&quot;]</div><div class="line">Output:</div><div class="line">[]</div></pre></td></tr></table></figure>
<p>预处理</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; wordBreak(<span class="built_in">string</span> s, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; wordDict) &#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; ret;</div><div class="line">        </div><div class="line">        <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>, <span class="keyword">bool</span>&gt; dict;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> word: wordDict) &#123;</div><div class="line">            dict[word] = <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> n = s.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; pre(n+<span class="number">1</span>);</div><div class="line">        pre[<span class="number">0</span>].push_back(<span class="number">-1</span>);</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</div><div class="line">                <span class="built_in">string</span> substr = s.substr(j, i-j);</div><div class="line">                <span class="keyword">if</span> (dict[substr] &amp;&amp; pre[j].size() != <span class="number">0</span>) &#123;</div><div class="line">                    pre[i].push_back(j);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; cur;</div><div class="line">        dfs(cur, n, ret, pre, s);</div><div class="line">        <span class="keyword">return</span> ret;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp;cur, <span class="keyword">int</span> idx, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; ret, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; pre, <span class="built_in">string</span>&amp; s)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (idx == <span class="number">0</span>) &#123;</div><div class="line">            <span class="built_in">string</span> str;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = cur.size()<span class="number">-1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</div><div class="line">                <span class="keyword">if</span> (i != cur.size()<span class="number">-1</span>) str += <span class="string">" "</span>;</div><div class="line">                str += cur[i];</div><div class="line">            &#125;</div><div class="line">            ret.push_back(str);</div><div class="line">            <span class="keyword">return</span>;</div><div class="line">        &#125; </div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> t: pre[idx]) &#123;</div><div class="line">            cur.push_back(s.substr(t, idx-t));</div><div class="line">            dfs(cur, t, ret, pre, s);</div><div class="line">            cur.pop_back();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="410-Split-Array-Largest-Sum"><a href="#410-Split-Array-Largest-Sum" class="headerlink" title="410. Split Array Largest Sum"></a>410. Split Array Largest Sum</h3><p>Given an array which consists of non-negative integers and an integer <em>m</em>, you can split the array into <em>m</em> non-empty continuous subarrays. Write an algorithm to minimize the largest sum among these <em>m</em> subarrays.</p>
<p><strong>Note:</strong><br>If <em>n</em> is the length of array, assume the following constraints are satisfied:</p>
<ul>
<li>1 ≤ <em>n</em> ≤ 1000</li>
<li>1 ≤ <em>m</em> ≤ min(50, <em>n</em>)</li>
</ul>
<p><strong>Examples:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">nums = [7,2,5,10,8]</div><div class="line">m = 2</div><div class="line"></div><div class="line">Output:</div><div class="line">18</div><div class="line"></div><div class="line">Explanation:</div><div class="line">There are four ways to split nums into two subarrays.</div><div class="line">The best way is to split it into [7,2,5] and [10,8],</div><div class="line">where the largest sum among the two subarrays is only 18.</div></pre></td></tr></table></figure>
<p>二分,贪心</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> ll;</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">splitArray</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> m)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = nums.size();</div><div class="line">        ll s = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            s += nums[i];</div><div class="line">        &#125;</div><div class="line">        ll l = <span class="number">0</span>, r = s;</div><div class="line">       <span class="keyword">while</span> (l &lt;= r) &#123;</div><div class="line">            ll mid = (l+r) / <span class="number">2</span>;</div><div class="line">            <span class="keyword">if</span> (!check(mid, nums, m)) &#123;</div><div class="line">                l = mid + <span class="number">1</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                r = mid - <span class="number">1</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> l;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">check</span><span class="params">(ll x, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> m)</span> </span>&#123;</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.size(); i++) &#123;</div><div class="line">            <span class="keyword">int</span> j = i<span class="number">-1</span>;</div><div class="line">            ll s = <span class="number">0</span>;</div><div class="line">            <span class="keyword">while</span>(j+<span class="number">1</span> &lt; nums.size() &amp;&amp; s+nums[j+<span class="number">1</span>] &lt;= x) s += nums[j+<span class="number">1</span>], ++j;</div><div class="line">            <span class="keyword">if</span> (j &lt; i) <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">            --m;</div><div class="line">            i = j;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (m &gt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="818-Race-Car"><a href="#818-Race-Car" class="headerlink" title="818. Race Car"></a>818. Race Car</h3><p>Your car starts at position 0 and speed +1 on an infinite number line.  (Your car can go into negative positions.)</p>
<p>Your car drives automatically according to a sequence of instructions A (accelerate) and R (reverse).</p>
<p>When you get an instruction “A”, your car does the following: <code>position += speed, speed *= 2</code>.</p>
<p>When you get an instruction “R”, your car does the following: if your speed is positive then <code>speed = -1</code> , otherwise <code>speed = 1</code>.  (Your position stays the same.)</p>
<p>For example, after commands “AAR”, your car goes to positions 0-&gt;1-&gt;3-&gt;3, and your speed goes to 1-&gt;2-&gt;4-&gt;-1.</p>
<p>Now for some target position, say the <strong>length</strong> of the shortest sequence of instructions to get there.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Example 1:</div><div class="line">Input: </div><div class="line">target = 3</div><div class="line">Output: 2</div><div class="line">Explanation: </div><div class="line">The shortest instruction sequence is &quot;AA&quot;.</div><div class="line">Your position goes from 0-&gt;1-&gt;3.</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Example 2:</div><div class="line">Input: </div><div class="line">target = 6</div><div class="line">Output: 5</div><div class="line">Explanation: </div><div class="line">The shortest instruction sequence is &quot;AAARA&quot;.</div><div class="line">Your position goes from 0-&gt;1-&gt;3-&gt;7-&gt;7-&gt;6.</div></pre></td></tr></table></figure>
<p><strong>Note:</strong></p>
<ul>
<li><code>1 &lt;= target &lt;= 10000</code>.</li>
</ul>
<p>贪心，选择合适的策略，没到，回去或超过再回去</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">racecar</span><span class="params">(<span class="keyword">int</span> target)</span> </span>&#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(target+<span class="number">1</span>, <span class="number">-1</span>);</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> dfs(target, dp);</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> target, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; dp)</span> </span>&#123;</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> (target == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="keyword">if</span> (dp[target] != <span class="number">-1</span>) <span class="keyword">return</span> dp[target];</div><div class="line">        </div><div class="line">        <span class="keyword">int</span> t = <span class="built_in">floor</span>(log2(target+<span class="number">1</span>));</div><div class="line">        <span class="comment">//cout &lt;&lt; target &lt;&lt;" " &lt;&lt; t &lt;&lt; endl;</span></div><div class="line">        <span class="keyword">if</span> (<span class="number">1</span>&lt;&lt;t == target+<span class="number">1</span>) <span class="keyword">return</span> dp[target] = t;</div><div class="line">        <span class="keyword">int</span> ret = dfs((<span class="number">1</span>&lt;&lt;(t+<span class="number">1</span>))<span class="number">-1</span>-target, dp) + t + <span class="number">2</span>; <span class="comment">//forward excess target then backward t+1 + 1(reverse)</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; t; i++) &#123;</div><div class="line">            ret = min(ret, dfs(target - (<span class="number">1</span>&lt;&lt;t) + (<span class="number">1</span>&lt;&lt;i), dp) + t + i + <span class="number">2</span>); <span class="comment">//forward n then backward m (reverse twice)</span></div><div class="line">        &#125;</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> dp[target] = ret;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<h3 id="132-Palindrome-Partitioning-II"><a href="#132-Palindrome-Partitioning-II" class="headerlink" title="132. Palindrome Partitioning II"></a>132. Palindrome Partitioning II</h3><p>Given a string <em>s</em>, partition <em>s</em> such that every substring of the partition is a palindrome.</p>
<p>Return the minimum cuts needed for a palindrome partitioning of <em>s</em>.</p>
<p><strong>Example:</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Input: &quot;aab&quot;</div><div class="line">Output: 1</div><div class="line">Explanation: The palindrome partitioning [&quot;aa&quot;,&quot;b&quot;] could be produced using 1 cut.</div></pre></td></tr></table></figure>
<p>预处理</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">judge_palindrom</span><span class="params">(<span class="built_in">string</span>&amp;s, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</div><div class="line">        <span class="keyword">while</span> (i &lt; j) &#123;</div><div class="line">            <span class="keyword">if</span> (s[i] != s[j]) <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">            i++;</div><div class="line">            j--;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minCut</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = s.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; palindrom(n);</div><div class="line">        <span class="comment">//vector&lt;vector&lt;bool&gt;&gt; isPalindrom(n, vector&lt;bool&gt;(n, false));</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= i; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (judge_palindrom(s, j, i)) &#123;</div><div class="line">                    palindrom[i].push_back(j);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(n, <span class="number">1e9</span>);</div><div class="line">        dp[<span class="number">0</span>] = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; palindrom[i].size(); j++) &#123;</div><div class="line">                <span class="keyword">int</span> idx = palindrom[i][j];</div><div class="line">                <span class="keyword">if</span> (idx == <span class="number">0</span>) &#123;</div><div class="line">                    dp[i] = <span class="number">1</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (dp[idx<span class="number">-1</span>] != <span class="number">1e9</span> &amp;&amp; dp[i] &gt; dp[idx<span class="number">-1</span>]+<span class="number">1</span>) &#123;</div><div class="line">                    dp[i] = dp[idx<span class="number">-1</span>] + <span class="number">1</span>;</div><div class="line">                &#125; </div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[n<span class="number">-1</span>] - <span class="number">1</span>;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Leetcode </tag>
            
            <tag> DP </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[感受野的计算及延伸]]></title>
      <url>/2018/05/15/%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%A1%E7%AE%97%E5%8F%8A%E5%BB%B6%E4%BC%B8/</url>
      <content type="html"><![CDATA[<p>感受野(receptive field)的定义:</p>
<blockquote>
<p><em>The</em> <strong>receptive field</strong> <em>is defined as the region in the input space that a particular CNN’s feature is looking at (i.e. be affected by)</em></p>
</blockquote>
<p>当我们计算feature map的大小时，假设输入的大小为: $n\times n$，卷积的参数是k(kernel size), p(padding), s(stride)，我们将得到$\lfloor \frac{n+2<em>p-k}{s}\rfloor+1$，如果我们引入dilation这个参数(相当于连续</em>标准卷积<em>的堆叠的receptive field)，那么最终的大小是$\lfloor \frac{n+2</em>p-k-d*(k-1)}{s}\rfloor+1$，pooling的参数是k，s，那么输出就是$\lfloor \frac{n-k}{s}\rfloor+1$</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1frc4o653j2j30u00bi0u6.jpg" alt=""></p>
<p>为了简化计算，我们假设图像是正方形的，主要有几个式子：<br>$$<br>j_{out} = j_{in}\times s<br>$$</p>
<p>$$<br>r_{out} = r_{in} + (k-1)\times j_{in}<br>$$</p>
<p>$$<br>c_{out} = c_{in} + (\frac{k-1}{2}-p)\times j_{in}<br>$$</p>
<p>第一个等式计算的是jump in the output feature map，s是stride，相当于做完降采样以后，作用域进行了放大（感受野进行了放大，之后每次感受野的增加都需要乘上相应的倍数(jump的数量)），第二个等式计算的是receptive field，k是kernel size（如果没有放大倍数，那么就是按照kernel的大小的进行扩展，如果有倍数的话就乘以相应的倍数，因为这里的一个像素等于原图的jump数个像素）第三个式子计算的是receptive field的中心。那么如果考虑到dialated conv，那么对于receptive field的计算就变成了：<br>$$<br>r_{out} = r_{in} + (k-1+(k-1)\times (d-1))\times j_{in} = r_{in} + ((k-1)\times d)\times j_{in}<br>$$</p>
]]></content>
      
        
        <tags>
            
            <tag> notes </tag>
            
            <tag> computer vision </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[正则化的理解]]></title>
      <url>/2018/05/07/%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%90%86%E8%A7%A3/</url>
      <content type="html"><![CDATA[<p>本文主要介绍一些正则化方法降低模型复杂度的原理（目的是防止过拟合，通过约束参数达到），主要是对l1正则和l2正则的原理进行思考。</p>
<p>这里先对优化问题进行简要介绍，主要有三种最优化问题（凸优化）：</p>
<ol>
<li>无约束的优化问题：就是没有任何约束条件，直接求导求极值点即可</li>
<li>有等式约束的优化问题：</li>
</ol>
<p>$$<br>\min f(X) \ s.t. g(x) = 0<br>$$</p>
<p>通常使用拉格朗日乘子法就行求解，转换成$L(\lambda, x) = f(x) + \lambda g(x)$，分别对x和$\lambda$求偏导，得到极值点集合，然后再验证</p>
<ol>
<li>有不等式约束的优化问题：</li>
</ol>
<p>$$<br>\min f(X) \ s.t. g(x) = 0, h(x)  \le 0<br>$$</p>
<p>f和h为凸函数，g是仿射函数，常用解法还是利用拉格朗日乘子法，即转化成$L(\lambda,\mu,x) = f(x) + \lambda g(x)+ \mu h(x)$，利用其最优化的KKT条件：</p>
<ul>
<li>$L(\lambda, \mu, x)$对变量的导数为0</li>
<li>g(x) = 0</li>
<li>$\mu h(x)=0$</li>
</ul>
<p>以简单的线性回归为例，将$E_D(w)$表示为data-dependent error，$E_w(w)$表示为regularization term，所以整个的error可以表示为：<br>$$<br>\frac{1}{2}\sum_{n=1}^N{t_n-w^T\phi(x_n)}^2+\frac{\lambda}{2}\sum_{j=1}^M|w_j|^q<br>$$<br><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fr52eorbknj31kw0jradg.jpg" alt=""></p>
<p>我们可以把上式写成一般的形式：<br>$$<br>J(w) = f(w) + \lambda h(w)<br>$$<br>也可以还原成有等式约束的形式：<br>$$<br>\min f(w) \ s.t. \lambda h(w) \le c<br>$$<br>特定的regularizer也叫做weight decay，顾名思义，就是会让参数向0作decay（变相地降低模型复杂度），q=1时，也叫做lasso，q=2时，叫做ridge。这里还需要解释一个问题：为什么q=1时，很容易出现参数为0的情况，也就是经常会得到稀疏解（和l2相比更容易得到稀疏解而不是一定会得到稀疏解），下图可以解释：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fr51ndkgxjj313a0qegou.jpg" alt=""></p>
<p>对于l1正则来说，就图中的例子来说，<strong><em>边界</em></strong>可以转化成$w_1+w_2=\frac{c}{\lambda}$，在图中就是一个菱形，而l2正则则可以转化为$w_1^2+w_2^2=\frac{c}{\lambda}$的<strong><em>边界</em></strong>，在图中则是一个圆形。而损失函数图像是圆形（大部分情况是椭圆形），使得菱形和圆形更容易相较于坐标轴上！<strong><em>随着惩罚项$\lambda$增大，菱形和圆形的面积会越来越小，所以求得参数也越来越小！起到降低模型复杂度的效果！</em></strong></p>
<h5 id="prior"><a href="#prior" class="headerlink" title="prior"></a>prior</h5><p>对于bayesian view来说，通过最大化后验概率得到：<br>$$<br>w^<em> = \arg\max_w p(w|D) = \arg\max_w\frac{p(D|w)</em>p(w)}{p(D)} = \arg\max_w p(D|w) * p(w)<br>$$<br>其中p(D|w)是似然函数，表示在w条件下数据D出现的概率，p(w)是参数的先验函数。</p>
<p>对于似然函数，我们假设数据之间都是i.i.d，那么我们有:<br>$$<br>p(D|w) = \prod_{k=1}^np(D_i|w)<br>$$<br>对最大后验概率去log：<br>$$<br>\arg\max_w p(D|w)*p(w) =\prod_{k=1}^np(D_i|w)p(w) = \log\prod_{k=1}^np(D_i|w)p(w) = \arg\min_w -\sum_{k=0}^n \log p(D|w) - \log p(w)<br>$$<br>当假设w服从高斯分布，那么经过转化以后就变成了l2正则，当假设w服从拉普拉斯分布，就可以转换成l1正则。</p>
<p>下图是拉普拉斯分布，可以发现，拉普拉斯分布在0值附近非常突出，而高斯分布更加平缓，所以拉普拉斯更倾向于产生稀疏解，而高斯分布对权值大的惩罚更大（从几何图形也可以看出）</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fr5382j3pqj311y0t23zb.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fr535b1edsj31040r3gp3.jpg" alt=""></p>
]]></content>
      
        
        <tags>
            
            <tag> notes </tag>
            
            <tag> machine learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[R-FCN笔记]]></title>
      <url>/2018/05/02/R-FCN%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：R-FCN: Object Detection via Region-based Fully Convolutional Networks，<strong>NIPS</strong> 2017</p>
<p>作者：Jifeng Dai, Yi Li, Kaiming He, Jian Sun</p>
<p>链接：<a href="https://arxiv.org/pdf/1605.06409.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1605.06409.pdf</a></p>
<p>代码：<a href="https://github.com/daijifeng001/r-fcn" target="_blank" rel="external">https://github.com/daijifeng001/r-fcn</a></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fr2thjx8v0j31ce0oa0zb.jpg" alt=""></p>
<p><strong>objective:</strong> address a dilemma between translation-invariance in image classification and translation-variance in object detection</p>
<p><strong>solution:</strong> position-sensitive score maps</p>
<ul>
<li>83.6% mAP on the 2007 set, 82.0% the 2012 set</li>
<li>a test-time speed of 170ms per image, 2.5-20× faster than the Faster R-CNN counterpart</li>
</ul>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2ttte6q5j30wo0vy1kx.jpg" alt=""></p>
<p>模型的backbone是ResNet-101，并将最后的fc层改成1024d的1x1的conv layer。</p>
<p>在image classification中，网络需要较好的translation invariance，但是在detection中，因为需要准确地定位object的位置，这需要网络具有定位的representation，有一定的translation-variant，例如在candidate box中，网络最好能够对在box中的object的一些translation，例如旋转，平移等有一定的响应。所以为了引入translation invariance，作者提出了Region-based Fully Convolutional Network (R-FCN)。</p>
<p>R-FCN通过构造position-sensitive的score map，每个score map都会对object的相对空间信息进行编码（encode），例如在object的左边还是右边。</p>
<p>对于最后一层的conv layer，它会输出每个类别的$k^2$个position-sensitive score maps，所以一共有$k^2(C+1)$个channel，$k^2$个score maps分别对应$k\times k$的格子，例如k=3，就可以对相对位置进行了编码：{top-left, top-center, top-right, …, bottom-right}，然后再用一个position-sensitive ROI pooling进行信息的整合，文中的做法就是相加</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2sgoe0jtj31cc0omth7.jpg" alt=""></p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p>Table 2是与其他模型的比较，对于R-FCN来说，去k=7要优于k=3</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2tw517esj313u0dadij.jpg" alt=""></p>
<p>Table 3是R-FCN和faster r-cnn在训练和测试的效率比较，可以发现R-FCN的效率要高于Faster r-cnn，同时准确率也要高于faster r-cnn。</p>
<p>Table 4-6是R-FCN和其他模型在PASCAL VOC2007，PASCAL VOC2012，COCO数据集上的比较 </p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2u19dx60j30zg0twdne.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fr2u6dkj5nj30xm0bkn08.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[FPN论文笔记]]></title>
      <url>/2018/04/21/FPN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Feature Pyramid Networks for Object Detection，<strong>CVPR</strong> 2017</p>
<p>作者：Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie</p>
<p>链接：<a href="https://arxiv.org/pdf/1612.03144.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1612.03144.pdf</a></p>
<p>代码(unofficial)：<a href="https://github.com/unsky/FPN" target="_blank" rel="external">https://github.com/unsky/FPN</a></p>
<ul>
<li>feature pyramid在物体识别中比较常用，作者将其应用到object detection中</li>
<li>不同于SSD，作者使用top-down的结构将来自更高pyramid level的semantically stronger的feature map和higher resolution features相结合，使得detection的结构更加准确</li>
</ul>
<p>Figure 1是不同类型的feature map的使用方法，作者使用的是(d)的结构，SSD使用的是(c)的结构</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqnpdczxhuj30w20usgvn.jpg" alt=""></p>
<h5 id="Feature-Pyramid-Networks"><a href="#Feature-Pyramid-Networks" class="headerlink" title="Feature Pyramid Networks"></a>Feature Pyramid Networks</h5><p>Figure 3是top-down pathway的示意结构，现将来自higher pyramid的feature maps升采样，再将该层的feature map做1x1的conv，减少channel dimension（固定为256d），再用element-wise addtion做merge，然后再用3x3的conv去消除上采样aliasing的影响。在C5上（最高层），先用1x1 conv产生粗糙的特征图。</p>
<p>${C2, C3, C4, C5}$层对应的融合特征层为${P2, P3, P4, P5}$</p>
<p>通过这样的操作来加强特征，即<strong>保留空间信息并增强语义信息</strong>。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqnpkyj02ej30tk0jcn00.jpg" alt=""></p>
<h5 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h5><p><strong>Feature Pyramid Networks for RPN</strong></p>
<p>RPN的参数配置和Faster R-CNN类似，作者提到了一点就是在feature pyramid的detection head参数是可以共享的，结果和不共享接近，这说明了<strong>不同level的pyramid的semantic level是相似的</strong>！</p>
<p><strong>Feature Pyramid Networks for Fast R-CNN</strong></p>
<p>这里的重点是ROI的分配：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqnqq1o4irj30m2034dg3.jpg" alt=""></p>
<p>w,h是ROI的宽和高，$k_0$=4，表示的是大小为224x224的ROI的target level，利用这个式子进行转换，分配到相应的pyramid level。</p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p><strong>Ablation Study</strong></p>
<p>Table 1，2，3是ablation study的表格</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fqnqwou2qwj315g0uc7ef.jpg" alt=""></p>
<p>Table 4是单模型在COCO detection benchmark上的表现，FPN取得SOTA的表现</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqnr7se6qpj31kw0iatgv.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RON论文笔记]]></title>
      <url>/2018/04/21/RON%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：RON: Reverse Connection with Objectness Prior Networks for Object Detection，<strong>CVPR</strong> 2017</p>
<p>作者：Tao Kong，Fuchun Sun，Anbang Yao，Huaping Liu，Ming Lu，Yurong Chen</p>
<p>链接：<a href="https://arxiv.org/pdf/1707.01691.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1707.01691.pdf</a></p>
<p>代码：<a href="https://github.com/taokong/RON" target="_blank" rel="external">https://github.com/taokong/RON</a></p>
<p><strong>objective：</strong></p>
<ul>
<li>bridge the gap between the region-based and region-free methodologies </li>
</ul>
<p><strong>solution</strong>：</p>
<ul>
<li>Multi-scale object localization，利用多个scale的feature map做detection<ul>
<li>建立reverse connection，为前面的层提供highly semantic的information</li>
</ul>
</li>
<li>Negative space mining<ul>
<li>通过建立objectness prior减少objects的搜索空间</li>
</ul>
</li>
</ul>
<p>384x384的输入，PASCAL VOC 2007 81.3% mAP，PASCAL VOC 2012 80.7% mAP，COCO 27.4%</p>
<p>效率较高，1.5G的 GPU内存，forward的速度是15FPS</p>
<p>Figure 2是RON的网络模型，有4个scales feature map做detection。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqk5dydd50j30t20tcqde.jpg" alt=""></p>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p>网络以VGG 16为backbone，将FC6和FC7改造为conv layer，在FC7处降采样。</p>
<p>所以每个用于detection的feature map大小为：1/8 (conv 4 3), 1/16 (conv 5 3), 1/32 (conv 6) and 1/64 (conv 7)</p>
<p><strong>Reverse Connection</strong></p>
<p>reverse connection的结构见Figure 3，将后一层的输出经过deconv做upsampling，deconv的通道是512，当前层经过conv，再用summation的方式做merge。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqk5exvqeej30io0g6my5.jpg" alt=""></p>
<p><strong>Reference Boxes</strong></p>
<p>不同层的网络对应不同的receptive field，所以需要设计对应层的ref box的scale和ratio，下面是scale的设计：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqmjznn3cij30rc02umxf.jpg" alt=""></p>
<p>这里$s_{min}$设为$\frac{1}{10}$,不同的对应ratios是${\frac{1}{3},\frac{1}{2}, 1, 2, 3}$</p>
<p><strong>Objectness Prior</strong></p>
<p>针对正负样本比例严重失调， 这里使用 Objectness Prior 来过滤大部分负样本，具体的做法就是利用conv通道的设计，因为每个cell有10个default boxes，所以通道数是10，然后就是做二分类。这里需要设定阈值，将objectness score大于$o_p$的选为样本，这里$o_p$设为0.03，可以过滤掉大部分的样本。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqmmemlca0j30s00fwduh.jpg" alt=""></p>
<p><strong>Detection and Bounding Box Regression</strong></p>
<p>Figure 5是detection bbox reg head的结构，可以发现在分类的module中，作者加入了两个inception module来提高分类的精度</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqk5fg7sxbj30tg0dimz5.jpg" alt=""></p>
<h5 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h5><p><strong>Loss</strong></p>
<p>相似的，也是multi-task loss</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqmmnkgq8jj30so04igm3.jpg" alt=""></p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p>Table 1-3是模型在PASCAL VOC 2007, 2012和COCO上的结果。</p>
<ul>
<li>可以发现RON对小物体的检测提升比较明显，例如boat和bottle。</li>
</ul>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqmmqfxmthj31ko0dqq9a.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqmmraplo7j31kw0g2gt8.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqmmvqkb0xj30tg0hydjk.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OHEM算法笔记]]></title>
      <url>/2018/04/18/OHEM%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Training Region-based Object Detectors with Online Hard Example Mining，<strong>CVPR</strong> 2016</p>
<p>作者：Abhinav Shrivastava, Abhinav Gupta, Ross Girshick</p>
<p>链接：<a href="https://arxiv.org/pdf/1604.03540.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1604.03540.pdf</a></p>
<p>代码：<a href="https://github.com/abhi2610/ohem" target="_blank" rel="external">https://github.com/abhi2610/ohem</a></p>
<p>Hard example mining是机器学习模型训练经常会用的trick，顾名思义，就是sample目前对于模型比较难的example进行“强化”学习。在CNN中对于patch选择根据策略的不同，主要有sliding window和proposal。大部分的情况是根据loss来判断是否是hard，只是作为训练的一个trick。文章针对Fast R-CNN，提出online hard example mining的算法对其进行优化。在VOC2007, 2012都取得了SOTA，mAP分别是78.9%，76.3%。</p>
<h5 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h5><p>FRCNN中，proposal的选择由它与gt的overlap决定，确定一个proposal为背景的阈值范围是：$[bg_{lo},0.5]$，这个范围的假设是这样的proposal是hard的可能性较大。作者认为这样得到的结果很可能是次优的，因为在其他位置可能存在更hard但是infrequent的样本，OHEM算法中移除了这个阈值</p>
<h5 id="OHEM"><a href="#OHEM" class="headerlink" title="OHEM"></a>OHEM</h5><p>idea很简单，就是在forward的时候根据loss排序，然后选择loss最大的，也就是最worst的样本进行backward更新模型的参数。但是这样会存在一个问题，就是当两个ROI位置相近的时候，在feature map上对应的是同一个位置，loss是相近的，所以作者提出了对hard examples做NMS，选择B/N个ROI最backward，这里NMS的阈值为0.7。</p>
<p>接下来就是工程上的优化，ROI进行backward的时候，空间和时间的消耗较大，如果直接做backward，那些没有选中的ROI还是会做backward，所以作者提出了Figure 2的网络结构，包含两个一样的的ROI network，其中一个是immutable的，用于计算forward的loss，只有在forward的时候分配内存，然后hard RoI sampling module使用刚才所说的方法进行采样，作为输入传到第二个ROI network，进行forward和backward，然后累积gradient，再backward。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgutzexflj31kw0v41kx.jpg" alt=""></p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p>Table 3和Table 4是模型在VOC 2007和VOC 2012的表现，都是SOTA，对FRCN提升明显。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqh3cawf16j31600radsm.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SSD笔记]]></title>
      <url>/2018/04/11/SSD%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：SSD: Single Shot MultiBox Detector，<strong>ECCV</strong> 2016</p>
<p>作者：Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg</p>
<p>链接：<a href="https://arxiv.org/pdf/1512.02325.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1512.02325.pdf</a>    </p>
<p>代码：<a href="https://github.com/weiliu89/caffe/tree/ssd" target="_blank" rel="external">https://github.com/weiliu89/caffe/tree/ssd</a></p>
<p>gluon实现：<a href="https://github.com/mowayao/gluon_SSD" target="_blank" rel="external">https://github.com/mowayao/gluon_SSD</a></p>
<ul>
<li>将bbox的输出空间离散化到一些默认的priors，也就是默认设定的anchors</li>
<li>不同Faster R-CNN的two stage的方式，SSD采用的是one shot的方法，精度和faster r-cnn接近，但是效率更高</li>
<li>将多尺度的feature maps应用到detection中，针对不同尺度的feature map，采用不同scale和ratio</li>
</ul>
<p>#####The Single Shot Detector (SSD)</p>
<p>将feature map分成nxn的cells，每个cell可以预测固定数量的box的conf和offset</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fqfue2u6o9j316a0taww0.jpg" alt=""></p>
<p><strong>Model</strong></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgroawjivj315i0r0dnf.jpg" alt=""></p>
<p>模型是基于pretrained的VGG-16进行修改和fine-tune</p>
<ul>
<li>Multi-scale feature map for detection: 在base net后加了conv feature layers用来做detection，这些layer使得feature maps的size逐渐降低，这样就可以做多尺度的预测</li>
<li>Convolutional predictors for detection：在添加的conv feature layer后加入输出层，即conv predictor，生成固定大小的输出，对于mxn，p个channel的feature map，使用3x3xp的卷积核，预测conf和loc。</li>
<li>Default boxes and aspect ratios：每个cell预测k个boxes，以及类别的数量是c，那么最后的输出channel则是(c+4)*k</li>
</ul>
<p><strong>Training</strong></p>
<ul>
<li>Matching strategy: 需要将default boxes做划分，将与gt与box的jaccard overlap大于0.5的定为gt，其他定为background</li>
<li>Training objective:</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqgqb60zbdj30wo040q3a.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqgqb6a4gij30zg09wmyu.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgqb74a9zj315c04mdgq.jpg" alt=""></p>
<ul>
<li>Choosing scales and aspect ratios for default boxes: 为了针对不同scale的object，scale被定义为：</li>
</ul>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqgrc1164dj30wa03q3yw.jpg" alt=""></p>
<p>$s_{min}=0.2, s_{max}=0.9,$ratios $a_r\in {1,2,3,\frac{1}{2}, \frac{1}{3}}$，$w_k=s_k\sqrt a_r, h_k=s_k/\sqrt a_r$。另外对于 ratio = 1 的情况，再指定 scale 为$，s_k=\sqrt {s_ks_{k+1}}$也就是总共有 6 种不同的 default box</p>
<ul>
<li>Hard negative mining: 在做完matching后，大部分的box都是背景，所以需要做采样，选择loss最高的几个，并且保持3:1的比例</li>
<li>Data augmentation：<ul>
<li>使用全图作为输入，</li>
<li>使用IOU和目标物体为0.1, 0.3，0.5, 0.7, 0.9的patch （这些 patch 在原图的大小的 $[0.1,1]$ 之间， 相应的宽高比在$[1/2,2]$之间）</li>
<li>随机采取一个patch</li>
</ul>
</li>
</ul>
<h5 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h5><p>Table 1是SSD在PASCAL VOC2007上的表现，可以发现SSD512的表现优于Faster R-CNN，SSD300兼顾性能和效率</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgqghdz3lj31600k2wo1.jpg" alt=""></p>
<p>Table 4是SSD在 PASCAL VOC2012上的表现，可以发现SSD512取得了SOTA的表现</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgrepc7k2j316w0es7b4.jpg" alt=""></p>
<p>Table 5是在COCO上的表现，同样是SOTA</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgreqfglbj316i0dwtd9.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YOLO&YOLOv2笔记]]></title>
      <url>/2018/04/07/YOLO&amp;YOLOv2%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h3 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h3><p>论文：You Only Look Once: Unified, Real-Time Object Detection，<strong>CVPR</strong> 2016</p>
<p>作者：Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi</p>
<p>链接：<a href="https://arxiv.org/pdf/1506.02640.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1506.02640.pdf</a></p>
<p>代码：<a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="external">https://pjreddie.com/darknet/yolo/</a></p>
<ul>
<li>将detection的分类问题转化为回归问题</li>
<li>在VOC 2007上，达到45FPS，mAP 63.4%，Fast YOLO可以达到155FPS，mAP 52.7%</li>
<li>将整张图划分为7x7的网格，每个格子预测置信度score和坐标位置，5个输出</li>
<li>没有利用proposal（不同于SSD和fast r-cnn），对小目标不是很友好</li>
<li>使用全局的context信息，背景错误较少</li>
</ul>
<h5 id="Unified-Detection"><a href="#Unified-Detection" class="headerlink" title="Unified Detection"></a>Unified Detection</h5><p>首先将输入图像分成SxS块，每个grid cell预测B个bounding box和confidence scores，以及预测C类。这样网络最后一层的输出是SxSx(Bx5+C)的tensor。如果一个object的中心落在某个grid，那么这个grid就需要负责预测这个object。文中的参数S=7,B=2,C=20。所以最后的输出的tensor大小为7x7x30。</p>
<p>confidence score的计算则是:$P(object)\times IOU_{pred}^{gt}$，第一项是表示是否落入grid，第二项则是预测的框和实际的框的IOU值。</p>
<p>loss function的设计为：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7loi7sgqj30ro0hotao.jpg" alt=""></p>
<p>可以发现作者的一个trick，就是对于宽和长，做了开根号的处理，这样做的目的是当物体很小的时候相对于大物体有同等的差值，可以获得更大的loss。</p>
<p>网络结构Figure 3所示，启发于GoogLeNet，但是没有使用inception，而是使用1x1的conv，共有24个卷积层加2个全连接层，先在ImageNet上预训练。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7l4n5bd5j31kw0pjtfl.jpg" alt=""></p>
<p><strong>Limitations of YOLO</strong></p>
<ol>
<li>对bounding box的预测做了较强的空间假设，每个grid只能预测两个boxes，并且只属于一类。这样就对小物体的预测非常不友好，特别是当一些小物体成群出现的时候。</li>
<li>在测试的时候，如果objects有不同的或者不寻常的比例的时候，泛化性会比较差</li>
<li>loss function的设计还需要再优化</li>
</ol>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p>Table 1是各个object detection实时系统的比较，可以发现Fast YOLO的速度非常高，同时保持较高的mAP。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fq7mi5up9aj30v20su0yx.jpg" alt=""></p>
<p>Figure 4是Fast R-CNN和YOLO的错误组成对比，可以发现YOLO对于背景的预测较好，因为利用了全局的context，但是loc的错误较大，这和loss function的设计不无关系。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7mknid1jj30t60mun1s.jpg" alt=""></p>
<h3 id="YOLO-v2"><a href="#YOLO-v2" class="headerlink" title="YOLO v2"></a>YOLO v2</h3><p>论文：YOLO9000: Better, Faster, Stronger Joseph，<strong>CVPR</strong> 2017</p>
<p>作者：Joseph Redmon, Ali Farhadi</p>
<p>链接：<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Redmon_YOLO9000_Better_Faster_CVPR_2017_paper.pdf" target="_blank" rel="external">http://openaccess.thecvf.com/content_cvpr_2017/papers/Redmon_YOLO9000_Better_Faster_CVPR_2017_paper.pdf</a></p>
<p>代码：<a href="http://pjreddie.com/yolo9000/" target="_blank" rel="external">http://pjreddie.com/yolo9000/</a></p>
<h5 id="Better"><a href="#Better" class="headerlink" title="Better"></a>Better</h5><ul>
<li><p>Batch Normalization:在每个conv后加入bn，取消dropout，mAP提高了2%</p>
</li>
<li><p>High Resolution Classifie: pretrain的时候就把图像分辨率调高，从224x224变成448x448，提高了4%</p>
</li>
<li><p>Convolutional With Anchor Boxes: 吸收Faster R-CNN中RPN的思想，去掉全连接层，加入anchor boxes，这样导致acc略有下降，但是召回率提高较多</p>
</li>
<li><p>Dimension Clusters: 通过k-means选择较好的priors，也就是anchor，选择k=5作为复杂度和高召回率的折中，将distance metric定义为：</p>
</li>
<li><p>$$<br>d(box, centroid) = 1-IOU(box, centroid)<br>$$</p>
<p>在k=5的前提下，召回率和使用9个anchor box的相近</p>
</li>
<li><p>Direct location prediction: 对坐标进行转换，和fast r-cnn等类似，提升5%，见Figure 3</p>
</li>
<li><p>Fine-Grained Features: 为了得到奇数大小的feature maps，将图像分辨率调整到416，得到奇数大小的好处是改点就是这个区域的中心，然后调整降采样的步长为32，这样就是416/32=13，参考SSD和faster r-cnn利用多尺度的feature maps，作者提出passthrough layer，将high resolution features和low resolution features结合，对于high resolution的feature maps，将相邻的特征分配到不同的channels，例如26x26x512变换成13x13x2048，再和原来的特征图相连接，相当于把feature maps做深度的扩充，这样有1%的提升</p>
</li>
</ul>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fq7upwxukoj30t60teadt.jpg" alt=""></p>
<ul>
<li>Multi-Scale Training: 每隔10个batches，随机选择一个scale，sclales有：320，352…,608。Table 3是不同尺度的结果，可以发现 544的最优！mAP达到78.6。在288x288的scale上，可以得到90FPS，同时mAP和Fast R-CNN一样</li>
</ul>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fq7vdy6vauj30ty0skjya.jpg" alt=""></p>
<p>Table 2是ablation studies的结果</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fq7vx9xa1aj31kw0nwjy5.jpg" alt=""></p>
<h5 id="Faster"><a href="#Faster" class="headerlink" title="Faster"></a>Faster</h5><p>提出darknet-19，效率相较于VGG 16有了较大的提升。</p>
<p>VGG-16对于224x224的图像做一次forward，卷积层的浮点数计算为30.69 billion。而darknet-19的卷积层浮点数计算为8.52 billion，但是在分类的准确性上略有降低。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fq7x1hlp1vj30jm0pujve.jpg" alt=""></p>
<h5 id="Stronger"><a href="#Stronger" class="headerlink" title="Stronger"></a>Stronger</h5><p>这里作者提出了一个非常fancy的idea，WordNet，解决不同数据集之间label mutually exclusive的问题。WordNet通过构建hierarchical tree来简化问题，并且选择最短的到达root的路径，Figure 6为图示。利用有向图对条件概率计算进行优化，分层地计算概率，然后做出预测。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7wy9z9kxj30pc0wkqaw.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Faster R-CNN笔记]]></title>
      <url>/2018/04/02/Faster-R-CNN%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks，TPAMI 2016</p>
<p>作者：Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun</p>
<p>链接：<a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1506.01497.pdf</a></p>
<p>代码：<a href="https://github.com/rbgirshick/py-faster-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/py-faster-rcnn</a></p>
<ul>
<li>在Fast R-CNN的基础上进行优化，将Region Proposal Network（RPN）取代Selective Search，可以更加有效地检测object candidates，与Fast R-CNN共享参数，RPN的任务是预测物体的bbox和objectness score</li>
<li>在RPN的基础上，提出anchor的概念，每个anchor可以代表不同的scale和ratio，从而达到translation-invariant的效果</li>
</ul>
<p>Figure 2的Faster R-CNN的结构图，主要要经过3个步骤：</p>
<ol>
<li>输入图像进入CNNs，得到相应的feature maps</li>
<li>将feature maps输入到RPN中，得到region proposals</li>
<li>将region proposals输入到Fast R-CNN中，得到detection的结果</li>
</ol>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpyjflds95j30ny0tcq81.jpg" alt=""></p>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p><strong>RPN</strong></p>
<p>RPN的输入为任意形状的图像，输出是一堆proposals的坐标，以及对应的confidence score。为了生成一堆region proposals，对于nxn的feature maps来说，作者通过sliding window（其实也就是3x3的conv）将其映射到固定维度的特征空间，然后再对得到的特征向量做分类和回归（将全连接改造成1x1的卷积，可以接受任何大小的输入）。</p>
<p><strong>anchors</strong></p>
<p>对于每个滑动窗口来说，假设该窗口有k个对应的proposals。这样reg layer就有4k的输出，cls layer有2k个输出。Figure 3就是anchor的示例。anchor可以解释为sliding window的中心点，通过假设这个中心点来自不同原始区域池化得到，所以可以根据这个中心点(anchor)逆推得到这些区域坐标和种类。假设现在有3中scales和3种ratios，以及feature maps的大小是WxH，那么总共有9xWxH个anchors，也可以将其理解成先验的bounding box。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpynk5f034j31d40k8nle.jpg" alt=""></p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p>首先是坐标空间的转换，将其转到相对空间，这在R-CNN中已经介绍过。其实是Multi-task的训练：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fpyo96peu1j30ke064t97.jpg" alt=""></p>
<p><strong>RPN训练</strong></p>
<p>RPN就直接用end-to-end的方法进行训练，对于每张图像，采样256个anchors，正负比例为1：1，如果正样本不够则用负样本补足。</p>
<p><strong>Fast R-CNN训练</strong></p>
<p>两个网络的训练需要比较多的trick，作者采用4-Step Alternating Training:</p>
<ol>
<li>对网络初始化（pretrained model），end-to-end地训练RPN</li>
<li>用RPN生成propals训练Fast R-CNN</li>
<li>将共享的卷积层fix住，训练RPN相关的层</li>
<li>将共享的卷积层fix住，训练Fast R-CNN相关的层</li>
</ol>
<p>Table 6和Table 7是Faster R-CNN在PASCAL VOC 2007和PASCAL VOC 2012两个数据集上的结果们也是RPN和SS的比较，可以看出RPN要好于SS</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fq0p3j4jrnj31580ictfx.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Fast R-CNN笔记]]></title>
      <url>/2018/03/22/Fast-R-CNN%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Fast R-CNN，<strong>ICCV</strong> 2015</p>
<p>作者：Ross Girshick</p>
<p>链接：<a href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" target="_blank" rel="external">https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf</a></p>
<p>代码：<a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="external">https://github.com/rbgirshick/fast-rcnn</a></p>
<ul>
<li><p>简化训练过程，实现end-to-end的训练方式</p>
<ul>
<li>将SVM分类器换成softmax，整合到网络中，鼓励类间竞争</li>
<li>将bounding box regression整合到网络中</li>
</ul>
</li>
<li><p>在Fast-RCNN中，region proposal的计算都是share的，避免重复计算</p>
</li>
<li><p>提出ROI pooling layer使得每个region proposal可以得到确定长度的特征向量</p>
</li>
<li><p>探索了一些训练的tricks，可以参考！</p>
<p>​</p>
<p>Figure 1是Fast R-CNN的图示</p>
</li>
</ul>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FuPCSWv0EUA2laIjMRDcJTU9oA0F" alt=""></p>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p>下图是R-CNN和Fast R-CNN的比较</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FurXilgjM6ixsxoU1HRAgilULtUt" alt=""></p>
<p>回顾一下R-CNN：</p>
<ol>
<li>用selective search提取region proposals</li>
<li>将region warp到固定大小，用CNN提取特征，得到一定长度的特征向量</li>
<li>对于提取到的特征，放到若干个SVM，得到各个类别的概率，再用简单的线性回归模型做 bounding box regression（就是对候选区域进行微调）</li>
<li>利用NMS优化结果</li>
</ol>
<p>可以发现：</p>
<ol>
<li>R-CNN存在着大量的重复计算，即对每个region propasal使用CNN提取特征，如果有n个patch就需要网络n次的forward</li>
<li>需要将region warp到固定大小，造成物体变形分辨率降低影响分类结果</li>
<li>没有end-to-end。。。</li>
</ol>
<p><strong>改进</strong></p>
<p>首先，R-CNN重复大量计算，需要针对这点进行优化，将卷积计算的结果重复利用，减少不必要的重复计算，先用CNN对全图提取特征，得到feature maps，然后用selective search对原图提取region proposals，根据缩放比例，在feature maps上找到相应的区域，再对这个区域进行分类和bounding box的回归。这样我们只需要做一次卷积就可以了。但是这又面临一个问题，这些区域的特征长度是不固定的，所以，收到SPP-Net的启发，提出ROI Pooling layer，使得feature maps输入能够得到固定长度的特征向量。</p>
<p>其次，Fast R-CNN将softmax分类器替换SVM，同时将bounding box regression融合到网络中，实现end-to-end的训练，其实就是通过multi-task的思想，实现对CNN的fine tune。</p>
<p><strong>ROI POOLING</strong></p>
<p>为了能够使得每个region得到相同固定大小的特征，我们需要调整它的维度使得它能够适应全连接层。所以论文提出了ROI POOLING这个方法，下面介绍一下ROI POOLING的工作原理：</p>
<p>假设输入的feature maps的维度是CxHxW，C,H,W分别表示feature maps的深度，高，宽。因为C是固定的而H和W是不固定的，所以论文采用了一种和SPPNet近似的方法。加入我们想要得到固定大小Cxhxw的输出，采用动态pooling的方法，将pooling的kernel size设置成(H/h, W/w)，步长也是一样。这样就可以得到固定长度的feature maps了。</p>
<p><strong>Scale Invariance</strong></p>
<p>为了实现object detector的scale invariance，作者探索了两者方法：</p>
<ol>
<li>直接暴力地resize</li>
<li>使用图像金字塔</li>
</ol>
<p><strong>Truncated SVD</strong></p>
<p>在训练的时候，因为ROIs数量不多，所以大部分的时间花在卷积运算上，而在测试的时候，需要计算每个ROIs的后验概率，有一半的时间花在全连接上，所以文章提出truncated SVD优化计算，将两个全连接取代一个全连接。<br>$$<br>W \approx U\Sigma_tV^T<br>$$<br>U是一个$u\times t$的矩阵，$\Sigma_t$是$t\times t$的矩阵，V是$v\times t$的矩阵，所以参数从$uv$减少到了$t(v+u)$，如果t要远小于$\min(u,v)$。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/Frc5IQiqhfIQW8Z39bNmc8BF3-vM" alt=""></p>
<p><strong>Mini-batch sampling</strong></p>
<p>在训练的时候，每次mini-batch中，从中采样两张图像，每张图像采样64个ROIs，这样每个batch的大小就是128，正负样本比例为1：3。</p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p>Table 1-3是Fast R-CNN在VOC 2007, 2010, 2012三个数据集上的表现，都是SOAT。</p>
<p>Table 4是Fast-RCNN,RCNN以及SPPnet在training和testing效率上的比较，可以发现效率提升非常明显。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FozRMPEXdJimmQmIloMArAEK4bjz" alt=""></p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FkHrR24XRqVg4etaxtFh-t2IF5G3" alt=""></p>
<h5 id="Design-evaluation"><a href="#Design-evaluation" class="headerlink" title="Design evaluation"></a>Design evaluation</h5><ul>
<li>Multi-task训练可以提高分类结果</li>
<li>Multi-scale detection可以帮助提高结果，但是提升不大，折中之下，选了single scale</li>
<li>training data越多越好，数据增强，将VOC2012的数据加到VOC2007中，提升明显！</li>
<li>在FRCN中，softmax要好于SVM，鼓励类间竞争</li>
<li>并不是proposals越多越好，需要取个合适的数量</li>
</ul>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SPPNet笔记]]></title>
      <url>/2018/03/20/SPPNet%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition，<strong>TPAMI</strong> 2015</p>
<p>作者：Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun</p>
<p>链接：<a href="https://arxiv.org/pdf/1406.4729.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1406.4729.pdf</a></p>
<p>代码：<a href="https://github.com/ShaoqingRen/SPP_net" target="_blank" rel="external">https://github.com/ShaoqingRen/SPP_net</a></p>
<ul>
<li>提出spatial pyramid pooling layer，使得网络能够接受任意大小的输入，同时利用multi-level的spatial bins做hierarchy information aggregation，提高模型的鲁棒性</li>
<li>对image classification和object detection（针对RCNN的优化）都可以提升模型的表现</li>
<li>在ILSVRC 2014 object detection中排名第2，image classification中排名第3</li>
</ul>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/56717690.jpg" alt=""></p>
<p>在RCNN中，我们提取各个region proposals，然后将其warp到指定的大小，再用CNN提特征，这样的问题是图像object经过warp以后，会变形严重并且影响分辨率，从而影响分类的结果，所以作者提出SPP layer，使得对于任何大小的输入图像，神经网络都可以输出固定长度的特征，同时提高分类的鲁棒性。</p>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p>见Figure 3，将卷积层的输出经过SPP layer以后，利用max pooling分成3种的spatial bins，第一种是4x4，第二种是2x2，第三种是1x1(global pooling)。在做完pooling以后，我们可以得到16x256,4x256,1x256这三种维度的特征，256是输入的feature map的深度，拼接以后得到21x256长度的特征，其实可以将SPP layer看成是特征层面的re-scaled。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/71347165.jpg" alt=""></p>
<p>例如输入的feature map的大小是axa，需要产生3x3，2x2，1x1的特征向量，那么pooling的window size是ceil(a/n)，步长是floor(a/n)。将这些特征拼接得到固定长度的特征向量，再连接全连接层进行分类。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/44112090.jpg" alt=""></p>
<h5 id="Training-Strategy"><a href="#Training-Strategy" class="headerlink" title="Training Strategy"></a>Training Strategy</h5><p><strong>Multi-size Training</strong></p>
<p>在分类任务的模型训练过程中，采用多个size的输入可以提高模型的结果。对于有两个不同大小输入的训练策略，使用两个固定大小（框架所限）的相同参数的网络进行交替训练。</p>
<p><strong>Full-image Representation</strong></p>
<p>在分类任务的模型训练过程中，将图像resize到min(w,h)=256，保持长宽比不变。</p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p><strong>Image Classifications</strong></p>
<p>Table 1是三种base network的结构。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/11136760.jpg" alt=""></p>
<p>在分类任务中，作者通过实验证明，SPP layer，multi-size training，能够提高分类的精度（见Table 2）。SPP layer能够提高精度是因为利用spatial pyramid pooling可以提高鲁棒性。multi-size training中，有三种策略，一种是单个大小，第二种是180和224，还有一种是从[180,224]随机选择其中的一个size，实验证明，第二种精度最高。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/84456005.jpg" alt=""></p>
<p>从Table 3看，full-image representation相比较于central crop，可以提高准确率。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/81983088.jpg" alt=""></p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/64521005.jpg" alt=""></p>
<p><strong>Object Detection</strong></p>
<p>下图是R-CNN和SPP-Net的对比，R-CNN的缺点是计算量大，包括了大量的重复计算。</p>
<p><img src="http://img.blog.csdn.net/20170617102150673?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdjFfdml2aWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p>
<p>其具体步骤和R-CNN类似：</p>
<ol>
<li>通过selective search得到2000个候选窗口</li>
<li>将整张图像输入到CNN中，完成特征的提取，然后在feature map上找到候选框的区域，在对候选框进行spaital pyramid pooling，得到定长的特征向量,这样做可以大大提高效率。</li>
<li>采用SVM模型，对物体进行分类。</li>
</ol>
<p>从Table 9看出，SPPNet相较于R-CNN计算效率有了较高的提升，同时准确率也有提高。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/35453761.jpg" alt=""></p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/27949731.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RCNN笔记]]></title>
      <url>/2018/03/13/RCNN%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Rich feature hierarchies for accurate object detection and semantic segmentation，CVPR 2014</p>
<p>作者：Ross Girshick，Jeff Donahue，Trevor Darrell，Jitendra Malik</p>
<p>链接：<a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1311.2524.pdf</a></p>
<p>代码：<a href="https://github.com/rbgirshick/rcnn" target="_blank" rel="external">https://github.com/rbgirshick/rcnn</a></p>
<h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h5><ul>
<li>之前的object detection算法都是用一些手工特征，例如SIFT或者HOG等，R-CNN使用pretrained的CNN提取region的特征，然后再用SVM分类做finetune（bridging the gap between image classification and object detection）</li>
<li>尝试不同层的feature作为分类的特征</li>
</ul>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p>R-CNN的模型见Figure 1，主要包括3个部分：</p>
<ol>
<li>提取region proposals</li>
<li>用CNN提取特征，得到一定长度的特征向量</li>
<li>对于提取到的特征，喂到若干个SVM，得到各个类别的概率</li>
<li>利用NMS优化结果</li>
</ol>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fpbdwp017oj30tq0mq0wc.jpg" alt=""></p>
<p><strong>Region proposals</strong></p>
<p>对于region proposals的提取，主要利用selective search这个启发式搜索方法。</p>
<p>selective search的步骤为：</p>
<ul>
<li>使用<a href="http://cs.brown.edu/~pff/segment/" target="_blank" rel="external">Efficient Graph Based Image Segmentation</a>中的方法来得到region</li>
<li>得到所有region之间两两的相似度</li>
<li>合并最像的两个region</li>
<li>重新计算新合并region与其他region的相似度</li>
<li>重复上述过程直到整张图片都聚合成一个大的region</li>
<li>使用一种随机的计分方式给每个region打分，按照分数进行ranking，取出top k的子集，就是selective search的结果</li>
</ul>
<hr>
<p><strong>Feature extraction</strong></p>
<p>使用AlexNet提取特征，AlexNet现在ILSVRC 2012(IMAGENET)上做pre train。将图像的region patch warp到227x227，然后喂到网络，得到特征。</p>
<p><strong>Object category classifier</strong></p>
<p>对于每个类别，训练各自的SVM，这样就可以得到每个类的score，训练的时候将gt视为正样本，与gt的IoU &lt; 0.3视为负样本。因为负样本往往远远大于正样本，所以需要做hard negative mining，控制合理的比例，一般设置为1：3。</p>
<p><strong>Bounding box regression</strong></p>
<p>输入是n对${(P^i,G^i)}i=1,…,N$，其中$P^i=(P_x^i,P_y^i,P_w^i,P_h^i)$，对应bounding box的中心，长宽，$G^i=(G_x,G_y,G_w,G_h)$。将P进行映射（前两者是平移，后两个是缩放）：<br>$$<br>\hat{G}_x = P_wd_x(P)+P_x \ \hat{G}_y = P_hd_y(P)+P_y \ \hat{G}_x = P_w\exp (d_w(P))\ \hat{G}_h = P_h\exp(d_h(P)) \\d_\star(P)=w_\star^T\phi_5(P)<br>$$<br>训练的时候对gt的四个坐标进行转换（上面的逆运算，使得$t_x,t_y$）：<br>$$<br>t_x = (G_x-P_x)/P_w \ t_y =(G_y −P_y)/P_h \ t_w = \log(G_w/P_w)\\t_h = \log(G_h/P_h).<br>$$<br>经过这样的变换，$t_x,t_y$为需要学习的平移量，$t_w, t_h$为需要学习的缩放量。</p>
<p>其中，$G$表示的是ground truth，P表示的训练样本，我们的任务是求解$W_\star$，其实就是通过梯度下降或者最小二乘法求解ridge regression问题，:<br>$$<br>w_\star =  \arg\min_{\hat{w}_\star}(t^i_\star − \hat{w}^T_\star \phi_5(P^i))^2+\lambda ||\hat{w}_\star||^2<br>$$<br>其中$\phi_5(P^i)$表示的是第5个pooling的输出。需要注意的是，正则系数$\lambda=1000$，而且当G和P相差很大的时候，效果会不好，所以需要设置IoU阈值，将其设为0.6。</p>
<h5 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h5><p>Table 1是模型在VOC 2012 test上的表现，可以看出R-CNN BB远超其他baseline，证明了模型的性能。</p>
<p>Table 2是模型在VOC 2007 test上的表现，可以在上面做一些ablation study：</p>
<ul>
<li>对于不finetune的模型，第一行到第三行，可以发现fc6的结果最好，这样就可以移除fc7的参数，简化模型。</li>
<li>对于finetune的模型，第四行到第六行，可以发现fc7的结果最好，经过网络的同层比较，可以发现finetune可以大大提升模型的performance。</li>
<li>通过第七行与第六行比较，可以看出bounding box regression可以较为显著地提升模型性能。</li>
<li>跟其他手工特征相比，CNN提取的特征具有更强的表达能力。</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpbidj661zj31kw0eeq6d.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpbi5y3ykqj31kw0k9wjg.jpg" alt=""></p>
<p>​    </p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> object detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ResNeXt笔记]]></title>
      <url>/2018/03/06/ResNeXt%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 :Aggregated Residual Transformations for Deep Neural Networks, CVPR 2017</p>
<p>链接：<a href="https://arxiv.org/pdf/1611.05431.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1611.05431.pdf</a></p>
<p>作者:  Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He</p>
<p>源码：<a href="https://github.com/facebookresearch/ResNeXt" target="_blank" rel="external">https://github.com/facebookresearch/ResNeXt</a></p>
<h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h5><p>提出ResNeXt网络，基于ResNet和GoogleNet。</p>
<p>提出cardinality的概念，对于每个conv block，对输入做多种不同的（结构相同，参数不同）transformations，然后再aggregation，而transformations的数量就是cardinality。</p>
<p>结构启发于inception module，同样是split-transform-merge的策略，这里的merge和transform都和inception不一样。split-transform-merge的策略主要是<strong><em>通过在一个尽可能小的计算复杂度的前提下，提高模型的表达能力</em></strong>（approach the representational power of large and dense layers, but at a considerably lower computational complexity）！ Inception的问题在于每个block都需要定制，导致了模型的灵活性较差，这些block的定制化设计相当于引入了一堆的超参，大量的超参对模型来讲无疑是不利的。而这篇文章就是基于这点进行改进！</p>
<ul>
<li>模块化</li>
<li>超参少</li>
<li>表达能力强</li>
</ul>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p>首先，总结了两点block设计的原则：</p>
<ol>
<li>对于相同大小的feature map，block的超参要相同，也就是conv的filter参数要一样。【if producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes)】</li>
<li>如果空间维度减半，那么feature maps的数量要加倍。【each time when the spatial map is downsampled by a factor of 2, the width of the blocks is multiplied by a factor of 2】</li>
</ol>
<p>Figure 1是ResNet和ResNeXt的block结构比较，重点看ResNeXt，可以看到这里将256维的输入做32个不同的transformations，每个transformation先通过1x1的conv做降维(information embedding)，然后再经过几个conv，最后将这32个输出做aggregation。</p>
<p>将其公式化:<br>$$<br>F(x) = \sum_{i=1}^C \tau_i(x)<br>$$<br>$\tau_i$的作用就是将x投影到低维空间（embeeding），然后做transform。C就是做transformation的数量，也就是cardinaty。aggregation后，再用short connection做identity mapping。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fp3f3tppr3j30te0i0jur.jpg" alt=""></p>
<p>Figure 3是异构的三种结构，（a）是初始版本，（b）concat，（c）group conv，这三者可以说是等价的。那么在实现上，可以利用group conv，更加方便！</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fp4d6cqzx8j31cq0i2q8m.jpg" alt=""></p>
<p>​    Table 1是ResNet-50和ResNeXt-50的参数对比</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fp4fhovd49j30nw0uaq8x.jpg" alt=""></p>
<h5 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h5><p>Table 3是各个版本的ResNeXt以及ResNet在ImageNet-1K数据集上的表现，可以发现随着Cardinaty增加，模型总体上是变好的，体现在top-1 error逐渐在降低。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fp4fegkbv6j30oc0jqn0j.jpg" alt=""></p>
<p>Table 6是ResNet和ResNeXt在ImageNet-5K上的比较，可以可发现后者都要好于前者。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fp4fkycmlxj30pi0eotbv.jpg" alt=""></p>
<p>Table 5则是各个state-of-the-art的模型在ImageNet-1K数据集上表现，可以发现模型达到了最好的结果。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fp4fmo7mobj30ow0gaacv.jpg" alt=""></p>
<p>从Table 7可以发现，相同的参数，ResNeXt比Wide ResNet表现更好。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fp4fojev6aj30pc09sgn0.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classification </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[DenseNet笔记]]></title>
      <url>/2018/03/06/DenseNet%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：Densely Connected Convolutional Networks, CVPR 2017</p>
<p>链接：<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf" target="_blank" rel="external">http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf</a></p>
<p>作者: Huang Gao, Liu Zhuang, Weinberger, K. Q., &amp; van der Maaten, L. </p>
<p>源码：<a href="https://github.com/liuzhuang13/DenseNet" target="_blank" rel="external">https://github.com/liuzhuang13/DenseNet</a>.</p>
<h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h5><p>DenseNet的idea和ResNet有点相近，既然ResNet可以通过一个skip connection就提高模型的性能，那为什么不多几个呢？</p>
<p>这样的话就可以使得梯度信息的回传更加有效（ResNet通过identity mapping进行另一条路径的梯度回传,而DenseNet的每一层梯度都可以直接回传回它前面的层），可以充分利用各个level的特征，也可以减少参数等。</p>
<ul>
<li>alleviate the vanishing-gradient problem，利用dense connection有效回传梯度</li>
<li>strengthen feature propagation，利用dense connection融合(concat)不同level的特征，使得浅层的特征更容易传播到高层，同时也可以让浅层的conv学一些discriminative features。</li>
<li>encourage feature reuse</li>
<li>substantially reduce the number of parameters，通过控制growth rate减少参数量</li>
</ul>
<p>假设有L层网络，那么如果将网络视为DAG，那么如果实行全连接，并且保证网络前向传播，共有$\frac{L\times(L+1)}{2}$条边。</p>
<h5 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h5><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fp33t32d1mj31kw0bt0xv.jpg" alt=""></p>
<p><strong>Dense Block</strong></p>
<p>首先，将其公式化，我们考虑第l层网络的输入和输出，$x_l$表示为第l层的输出，那么有:<br>$$<br>x_l = H_l([x_0,x_1,…,x_{l-1}])<br>$$<br>这里，$[x_0,x_1,…,x_{l-1}]$表示feature map的按通道拼接，形成新的tensor。</p>
<p>$H_l$是一个组合函数，BN-ReLU-Conv(3x3)。</p>
<p>为了将模型简化，将预想中的DenseNet分拆成若干个dense block，见Figure 2。</p>
<p><strong>Growth Rate</strong></p>
<p>$H_l$的输出是k个feature maps，也被叫做是growth rate。</p>
<p>对于每个dense block来说，假设输入的深度是$k_0$，对于第l个层的输出，则有$k\times(l-1)+k_0$的深度，从Figure 2就可以简单得出。作者将这种dense connection解释为collective knowledge，获取前面层的输出，growth rate则是起到限制knowledge容量的作用，使得knowledge精简化!</p>
<p><strong>Transition Layer</strong></p>
<p>每个block之间用transition layer，包括1x1的conv和pooling层。transition layer起到压缩网络模型的作用，如果每个block包括m个feature maps，那么经过压缩后，就变成$\theta m, 0\le \theta \le 1$，同时利用pooling降采样。我们把$\theta =0.5$的结构（将feature maps的数量降为原来的一般）记作DenseNet-C。</p>
<p><strong>Bottleneck Layer</strong></p>
<p>因为每个block的输出都是k，但是它的输入往往比k更大，所以引入bottleneck layer起到降维的作用，同时保留尽可能多的信息。这样$H_l$就变成了BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3)，我们将使用bottleneck layer的版本记作DenseNet-B。</p>
<p>Table 1是模型的参数结构。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fp3b35pbwqj31kw0qqair.jpg" alt=""></p>
<h5 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h5><p><strong>训练细节</strong></p>
<p>对于CIFAR和SVHN,初始lr设为0.1，在训练50%和75%的epochs时，除以10。</p>
<p>对于IMAGENET,初始lr设为0.1，在30和60个epochs后，除以10。</p>
<p>SGD，weight decay $10^{-4}$</p>
<p>因为CIFAR和SVHN数据集较小，所以在conv后（除第一个）都加了dropout，ratio为0.2。</p>
<p>Tabel 2是各个模型在CIFAR-10，CIFAR-100，SVHN三个数据集上的结果，+号表示做数据增强，将用了Bottleneck layer和feature maps compression的记做DenseNet-BC。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fp3bafnkxmj314u0pwgtx.jpg" alt=""></p>
<p>总的来说，数据增强可以提升表现！</p>
<ul>
<li>可以发现，和ResNet相比，参数更少，错误率更低，模型参数利用率高！</li>
<li>在C10和C100上，DenseNet-BC(L=190,k=40)达到最优的结果。</li>
<li>观察原始的DenseNet（没有BC），可以发现，随着L和k的增大，模型性能在提升（参数量上升，模型容量提升，表达能力提升），说明dense block有较强的抗过拟合的能力。</li>
<li>在SVHN上，DenseNet-BC结果要比没有原始的DenseNet，这可能是数据集过小，模型过拟合了。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classification </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SegNet笔记]]></title>
      <url>/2018/02/26/SegNet%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：SegNet: Identity Mappings in Deep Residual Networks, ECCV 2016</p>
<p>链接：<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7803544" target="_blank" rel="external">http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7803544</a></p>
<p>作者: Vijay Badrinarayanan, Alex Kendall , and Roberto Cipolla</p>
<p><strong>Idea</strong></p>
<ul>
<li>SegNet基于FCN，包含encoder和decoder两个部分，encoder使用VGGNet，decoder则使用skip architecture将相同分辨率的feature map结合再做后续的预测。</li>
<li>上采样的方法不同于transposed convolution和双线性插值等方法，使用maxpooling的逆运算的方法做上采样，得到稀疏的feature map，再做卷积得到稠密的feature map。</li>
</ul>
<p><strong>Architecture</strong></p>
<p>具体的框架结构件Fig.2，主要由两部分组成，encoder和decoder。</p>
<p>encoder的部分包含VGGNet在全连接层前的所有卷积层，这样共有13个卷积层，并且参数是直接从在imagenet预训练过的VGGNet直接拷贝过来，进行初始化。通过移除全连接层，可以大大地减少参数量和提高运算效率，参数量从134M减少到了14.7M。</p>
<p>文章的重点部分在于decoder的设计，decoder部分包含和encoder一样的卷积层数量，并且参数配置一一对应。在VGGNet中，max pooling的stride是2，kernel size是2，所以它的下采样是没有重叠的。在升采样上，和其他类似U-Net等不同的是，SegNet使用的是maxpooling逆运算，也就是利用保存的max pooling的元素下标，将feature map恢复到原来的大小，再利用可训练的卷积层得到稠密的feature map。具体的过程见Fig.3。</p>
<p>因为使用max pooling可以提高特征的translation invariance，同时提高分类的鲁棒性，但是同时也损失了很多边缘信息，因为我们把边缘的位置信息丢弃了。通常来说，响应比较强的都是一些纹理边缘，而max pooling本质上是一个滤波器，将局部最大值保留下来，舍去其他值。通过将max pooling的下标保留下来，可以帮助我们尽可能的恢复边缘位置信息。</p>
<p>使用上述上采样的方法有以下的好处：</p>
<ul>
<li>可以得到更加细致的轮廓</li>
<li>减少训练参数，同时能够end-to-end的训练</li>
<li>可以将其融入到任何encoder-decoder的结构中，具有普适性。</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fotu08o3s4j312u0e4ajm.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotuej8g3gj313a0eo429.jpg" alt=""></p>
<p>Pytorch代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">segnet</span><span class="params">(nn.Module)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_classes=<span class="number">21</span>, in_channels=<span class="number">3</span>, is_unpooling=True)</span>:</span></div><div class="line">        super(segnet, self).__init__()</div><div class="line"></div><div class="line">        self.in_channels = in_channels</div><div class="line">        self.is_unpooling = is_unpooling</div><div class="line"></div><div class="line">        self.down1 = segnetDown2(self.in_channels, <span class="number">64</span>)</div><div class="line">        self.down2 = segnetDown2(<span class="number">64</span>, <span class="number">128</span>)</div><div class="line">        self.down3 = segnetDown3(<span class="number">128</span>, <span class="number">256</span>)</div><div class="line">        self.down4 = segnetDown3(<span class="number">256</span>, <span class="number">512</span>)</div><div class="line">        self.down5 = segnetDown3(<span class="number">512</span>, <span class="number">512</span>)</div><div class="line"></div><div class="line">        self.up5 = segnetUp3(<span class="number">512</span>, <span class="number">512</span>)</div><div class="line">        self.up4 = segnetUp3(<span class="number">512</span>, <span class="number">256</span>)</div><div class="line">        self.up3 = segnetUp3(<span class="number">256</span>, <span class="number">128</span>)</div><div class="line">        self.up2 = segnetUp2(<span class="number">128</span>, <span class="number">64</span>)</div><div class="line">        self.up1 = segnetUp2(<span class="number">64</span>, n_classes)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs)</span>:</span></div><div class="line"></div><div class="line">        down1, indices_1, unpool_shape1 = self.down1(inputs)</div><div class="line">        down2, indices_2, unpool_shape2 = self.down2(down1)</div><div class="line">        down3, indices_3, unpool_shape3 = self.down3(down2)</div><div class="line">        down4, indices_4, unpool_shape4 = self.down4(down3)</div><div class="line">        down5, indices_5, unpool_shape5 = self.down5(down4)</div><div class="line"></div><div class="line">        up5 = self.up5(down5, indices_5, unpool_shape5)</div><div class="line">        up4 = self.up4(up5, indices_4, unpool_shape4)</div><div class="line">        up3 = self.up3(up4, indices_3, unpool_shape3)</div><div class="line">        up2 = self.up2(up3, indices_2, unpool_shape2)</div><div class="line">        up1 = self.up1(up2, indices_1, unpool_shape1)</div><div class="line"></div><div class="line">        <span class="keyword">return</span> up1</div></pre></td></tr></table></figure>
<p><strong>实验</strong></p>
<p>首先针对deocder做了以下几种变形：</p>
<ul>
<li>SegNet-basic: 4个编码块和4个解码块，编码块由conv,bn,relu组成，然后加max pooling，解码器由conv，bn组成，并且没有bias。所有的卷积核的大小都是7x7。</li>
<li>SegNet-Basic-SingleChannelDecoder：卷积是单通道的，分别和对应的feature map层做卷积，这样可以减少训练参数，同时提高inference的速度。</li>
<li>FCN-basic：和SegNet-basic类似，不同的是使用FCN的上采样方法。</li>
<li>FCN-basic-NoAddition：不进行feature map相加，只通过deconv上采样。</li>
<li>Bilinear-Interpolation：使用双线性插值上采样。</li>
<li>SegNet-Basic-EncoderAddition：和FCN的方法类似，比较消耗显存，将几个feature map相加得到最终的feature map</li>
<li>FCN-Basic-NoDimReduction：再输出最终的结果之间不进行降维，FCN-basic会将维度降低到64，然后在做1x1的卷积。</li>
</ul>
<p>比较结果见TABLE 1。参数数量上，FCN-Basic和FCN-Basic-NoAddition最少，inference time则是FCN-Basic-NoAddition最少。</p>
<ul>
<li>在性能上，bilinear-interpolation表现最差，说明了decoder需要学习，而不是简单粗暴的直接上采样！</li>
<li>SegNet-Basic和FCN-Basic相比，精度相近，区别在于后者的显存消耗更大因为后者需要存储多个feature map，而前者只需要存储max pooling的下标。除此之外，后者的forward时间更短，因为它在做预测前对feature map做了降维。</li>
<li>FCN-Basic-NoAddition和SegNet-Basic：两者的decoder最为相似，因为都是直接学上采样，没有feature map的相加，在精度上，SegNet-Basic较好，说明了利用低层次的feature map的重要性，也就是将高层次语义信息和低层次位置信息结合的重要性。</li>
<li>FCN-Basic-NoAddition-NoDimReduction和SegNet-Basic：前者的模型要大于后者，因为没有做降维。在性能上，前者也不如后者。说明并不是模型越大，表现越好，重要的是需要capture更多的边缘信息。</li>
<li>FCN-Basic-NoAddition 和SegNet-Basic-SingleChannelDecoder：证明了当面临存储消耗，精度和inference时间的妥协的时候，我们可以选择SegNet!</li>
<li>当内存和inference时间不受限的时候，模型越大，表现越好。因为FCN-Basic-NoDimReduction和SegNet-EncoderAddition比其他变种要好。</li>
<li>class balance的影响：在class average accuracy和mIoU指标上，可以发现没有class weighted的时候比经过class weighted的要差，而在global accuracy上，情况则相反，这是因为绝大部分的像素都是天空，道路和建筑。</li>
</ul>
<p>总结一下：</p>
<ul>
<li>内存受限的时候，可以用过降维，存储max pooling下标来提升表现。</li>
<li>编码器一定，解码越大，性能越好</li>
<li>编码器的feature map被完整保留下来时，效果最好，毕竟是空间换性能！</li>
</ul>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotvqp2uqsj313y0g2agk.jpg" alt=""></p>
<p>模型在CamVid数据集上的比较结果见TABLE 3，CamVid是一个用于自动驾驶的室外场景，可以发现在迭代次数较少的时候，SegNet要好于其他方法其他方法，但是当迭代次数较高的时候，整体上SegNet还是表现最优，但是在BF指标上不如DeconvNet。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fotwygav2aj313c0a8tc7.jpg" alt=""></p>
<p>模型在SUNRGB-D数据集上的比较结果见TABLE 4，可以发现，所有方法的表现都比较差，在G，C，BF指标上，SegNet好于其他模型，但是mIoU比DeepLab-LargeFOV要差。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fotx37mf6nj31360c642m.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> segmentation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Fully Convolutional Networks for Semantic Segmentation(FCN)笔记]]></title>
      <url>/2018/02/26/Fully-Convolutional-Networks-for-Semantic-Segmentation-FCN-%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Fully Convolutional Networks for Semantic Segmentation，CVPR 2015</p>
<p>链接：<a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" target="_blank" rel="external">https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf</a></p>
<p>作者：Jonathan Long, Evan Shelhamer, Trevor Darrell</p>
<p><strong>Idea</strong></p>
<p>传统的图像分割算法主要依赖于：</p>
<ol>
<li>图像patch的训练，使得效率和准确率都不够。</li>
<li>后处理</li>
<li>multi-scale pyramid的预处理</li>
<li>ensemble</li>
</ol>
<p>…</p>
<p>这篇文章的主要贡献就是建立构造了全卷积神经网络，在显存足够的前提下可以接受任意大小的输入，然后得到对应大小的输出。作者将VGGNet,GoogleNet用于物体分类并预训练好的网络改造成全卷积神经网络，能够实现end-to-end的训练，并将其finetune，用来做图像的语义分割。除此之外，在升采样的过程中，由于之前的降采样丢失了大量的位置信息，所以作者采用了skip architecture将低层的输出传给高层，实现浅层的位置信息和高层的语义信息的融合。</p>
<p><strong>网络结构</strong></p>
<p>以VGGNet为例，见Figure3，最后的全连接层的维度是4096，为了将其改造成全卷积，将全连接层改成1x1的卷积，这样它的输出变成了4096x1x1。然后，通过deconvotion的操作对feature map进行升采样，恢复到和原图一样的大小，所以最终的输出的大小为WxHxC，其中W,H是原图的大小，而C是像素的种类数，每个空间位置表示的是各个类别的概率。降采样会提高感受野，同时也会包含越来越多的语义信息，但是也会丢失位置信息，所以，为了做出更好的像素分类结果，需要将高层的语义信息(what)和底层的位置信息(where)结合起来，使用skip architecture的结构，用低层信息对结果进行修正，提高模型的性能。除此之外，作者还提供了3个变种，即FCN-32s，FCN-16s，FCN-8s。顾名思义，FCN-32s就是通过deconvolution进行32倍的升采样直接输出。FCN-16s则是联合pool4和2倍升采样的conv7，再做16倍的升采样。FCN-8s是pool3，2倍升采样的pool4和4倍升采样的conv7，结合以后再做8倍的升采样。</p>
<p>升采样的方法有多种，可以采用双线性插值等非学习性方法，也可以采用transposed convolution，通过设定步长等参数进行升采样。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fotrxkpssoj31j20tw113.jpg" alt=""></p>
<p>下面是FCN-8的pytorch实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">fcn_8s</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes)</span>:</span></div><div class="line">        super(fcn, self).__init__()</div><div class="line">        self.stage1 = nn.Sequential(*list(pretrained_net.children())[:<span class="number">-4</span>])</div><div class="line">        self.stage2 = list(pretrained_net.children())[<span class="number">-4</span>]</div><div class="line">        self.stage3 = list(pretrained_net.children())[<span class="number">-3</span>] </div><div class="line">        </div><div class="line">        self.scores1 = nn.Conv2d(<span class="number">512</span>, num_classes, <span class="number">1</span>)</div><div class="line">        self.scores2 = nn.Conv2d(<span class="number">256</span>, num_classes, <span class="number">1</span>)</div><div class="line">        self.scores3 = nn.Conv2d(<span class="number">128</span>, num_classes, <span class="number">1</span>)</div><div class="line">        </div><div class="line">        self.upsample_8x = nn.ConvTranspose2d(num_classes, num_classes, <span class="number">16</span>, <span class="number">8</span>, <span class="number">4</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.upsample_4x = nn.ConvTranspose2d(num_classes, num_classes, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.upsample_2x = nn.ConvTranspose2d(num_classes, num_classes, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span>)   </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = self.stage1(x)</div><div class="line">        s1 = x <span class="comment"># 1/8</span></div><div class="line">        </div><div class="line">        x = self.stage2(x)</div><div class="line">        s2 = x <span class="comment"># 1/16</span></div><div class="line">    </div><div class="line">        x = self.stage3(x)</div><div class="line">        s3 = x <span class="comment"># 1/32</span></div><div class="line">        </div><div class="line">        s3 = self.scores1(s3)</div><div class="line">        s3 = self.upsample_2x(s3)</div><div class="line">        s2 = self.scores2(s2)</div><div class="line">        s2 = s2 + s3</div><div class="line">        </div><div class="line">        s1 = self.scores3(s1)</div><div class="line">        s2 = self.upsample_4x(s2)</div><div class="line">        s = s1 + s2</div><div class="line">        s = self.upsample_8x(s2)</div><div class="line">        <span class="keyword">return</span> s</div></pre></td></tr></table></figure>
<p><strong>实验</strong></p>
<p>3个变种的效果在PASCAL VOS数据集上的比较，见Table 2和Figure 4，可以发现都是FCN-8s更胜一筹。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fotswcnw1kj30q60dw76m.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotsvv8zbuj30rw0h4win.jpg" alt=""></p>
<p>3种分类模型在PASCAL VOC 2011数据集的比较：AlexNet，VGGNet，GoogleNet，见Table1，可以发现VGGNet超出其他两个模型很多。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotsyeuufij30q60me42k.jpg" alt=""></p>
<p>同时，FCN在PASCAL-S，NYUDv2，SIFT FLOW数据集也取得了state-of-the-art的结果。</p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> segmentation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Kaggle比赛小结-Camera Model Identification]]></title>
      <url>/2018/02/09/Kaggle%E6%AF%94%E8%B5%9B%E5%B0%8F%E7%BB%93-Camera-Model-Identification/</url>
      <content type="html"><![CDATA[<p><a href="https://www.kaggle.com/c/sp-society-camera-model-identification" target="_blank" rel="external">https://www.kaggle.com/c/sp-society-camera-model-identification</a></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1foa5fw8h19j31k20483yy.jpg" alt=""></p>
<p>参加完比赛，做个简单的总结：</p>
<ul>
<li>数据增强：JPEG压缩，resizing，gamma修正</li>
<li>数据的不平衡需要设置采样权重</li>
<li>Random Crop，尽可能大，取512的结果好于256，先crop 1024，做完数据增强后再crop 512</li>
<li>网络模型，Dense201&gt;Dense161…..</li>
<li>Focal Loss可以提高结果</li>
<li>learning rate: 1e-4，optimizer: Adam，batch size: 16……</li>
<li>ensemble</li>
</ul>
<p>可以考虑的点：</p>
<ul>
<li>因为验证集的结果还不错，可以将测试集用训练得到的模型做分类，再训练，做数据扩充</li>
<li>可以人工地下载更多的数据。。。</li>
<li>结合手工提取的特征做结果的修正，例如noise pattern:<a href="https://www.kaggle.com/zeemeen/i-have-a-clue-what-i-am-doing-noise-patterns" target="_blank" rel="external">https://www.kaggle.com/zeemeen/i-have-a-clue-what-i-am-doing-noise-patterns</a></li>
</ul>
]]></content>
      
        <categories>
            
            <category> competition </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
            <tag> computer vision </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Inception-v4, Inception-ResNet and(Inception v4)笔记]]></title>
      <url>/2018/02/07/Inception-v4-Inception-ResNet-and-Inception-v4-%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, AAAI 2017</p>
<p>链接：<a href="https://arxiv.org/abs/1602.07261" target="_blank" rel="external">https://arxiv.org/abs/1602.07261</a></p>
<p>作者: Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi</p>
<p>呃。。。这篇文章的主要贡献是了尝试了ResNet和Inception结合的多种可能性。。。。对Inception block进行修改和优化，提出了Inception v4（Figure 9），Inception-ResNet-v1和Inception-ResNet-v2（Figure 15），将ImageNet classification task的top-5 error刷到了3.08%。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobembpr0rj30ee0rcwhc.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdqhuy1oj30eo0de3zr.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobdr5dh4pj30ek0c6myf.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobdrmnbfwj30es0fitab.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdroxsyfj30fi0h2jt6.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobdsgyknpj30eg0m8wg5.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdss6xhkj30f40femyk.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fobdsvxatrj30fg0j6dhi.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdt1ggqpj30ew0cc75o.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdtqs6ylj30g00jsdhj.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdu21ayyj30cw0kkgnb.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobdvixvgxj30ek0lewgk.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdvwhgcdj30ek0fe3zx.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdvyzlfvj30ek0j0myu.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobdw3cijkj30fi0c20u5.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdw6e7fqj30f20iiwg6.jpg" alt=""></p>
<p>实验发现：如果feature map的数量超过1000，网络会不work，训练的时候会不稳定，而且在早期就会“die”。所以在residual加个scaling，使得数值偏小，见Figure 20。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fobe052il4j30s00o4q62.jpg" alt=""></p>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p>single crop和single model的比较结果见Table 2，可以发现Inception-ResNet-v2略胜一筹，但是和Inception-v4差距不大。</p>
<p>小数量的crop和single model的比较结果见Table 3，和Table 2的结果类似。</p>
<p>dense crop和single model的比较结果见Table 4，结果依然类似。</p>
<p>以及，crop的数量对结果影响还是很大的！</p>
<p>144 crop的模型ensemble后的比较结果见Table 5。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobe29be8mj30t60e6q5l.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobe24s4gmj30sq0e80vm.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobe25u8vpj30tq0dmju6.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobe291a2tj30uw0gu0wt.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Rethinking the Inception Architecture for Computer Vision(Inception v3)笔记]]></title>
      <url>/2018/02/07/Rethinking-the-Inception-Architecture-for-Computer-Vision-Inception-V3-%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：Rethinking the Inception Architecture for Computer Vision, CVPR 2016</p>
<p>链接：<a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1512.00567.pdf</a></p>
<p>作者: Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, Zbigniew Wojna</p>
<ul>
<li>优化了Inception的结构</li>
<li>讨论了一些设计原则和可以优化的方向</li>
</ul>
<ul>
<li><p>在ILSVRC 2012 classification验证集上取得state-of-the-art的结果：21.2% top-1 error和5.6% top-5 error，ensemble后，取得3.5% top-5 error和17.3% top-1 error。</p>
<p>​</p>
</li>
</ul>
<h5 id="General-Design-Principles"><a href="#General-Design-Principles" class="headerlink" title="General Design Principles"></a>General Design Principles</h5><ul>
<li>为了避免表示瓶颈(representational bottlenecks)，feature map应该缓慢减小！</li>
<li>高维度的feature map能够更容易地处理局部信息（有更多的feature maps），在CNN中提高响应（融合不同感受野的卷积提取的特征）可以解耦更多特征，网络训练也更快</li>
<li>用1x1卷积做embeeding，在没有大量或者一些表现能力损失的基础上降低维度(局部空间的高相关性)。在做完spatial aggregation后用1x1卷积降低维度</li>
<li>网络的深度和宽度应该同时增加或者减少。这两者之间存在某种平衡</li>
</ul>
<h5 id="Factorizing-Convolutions-with-Large-Filter-Size"><a href="#Factorizing-Convolutions-with-Large-Filter-Size" class="headerlink" title="Factorizing Convolutions with Large Filter Size"></a>Factorizing Convolutions with Large Filter Size</h5><p>为了提高计算效率，可以将大的卷积核分解。</p>
<p><strong>Factorization into smaller convolutions</strong></p>
<p>例如5x5的卷积和3x3的卷积在其他条件相同的情况下，前者的计算量是后者的$\frac{25}{9}$。</p>
<p>用两个3x3的卷积代替5x5，两者具有相同的感受野，可以降低28%的计算量，而且经过实验证明，中间还是要有ReLU，而不是线性激活，见Figure 4和Figure 5</p>
<p><strong>Spatial Factorization into Asymmetric Convo- lutions</strong></p>
<p>分解成非对称的卷积，nx1的卷积。例如用3x1加1x3的两个卷积来代替3x3的卷积，这样的话可以降低33%的计算量。扩展一下，我们可以将nxn的卷积分解成1xn和nx1两个卷积，n越大，降低的计算量越大。</p>
<p>实际上，这样的分解在浅层效果并不好，只有在中层的时候效果不错，对于nxn的feature map来说，n一般从12到20，对于这些尺寸，7x1和1x7的小贵最好，见Figure 6。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fo7ytt7rq5j30p60i2tab.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fo7ytqofwjj30tc0mkjtw.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionA</span><span class="params">(nn.Module)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, pool_features)</span>:</span></div><div class="line">        super(InceptionA, self).__init__()</div><div class="line">        self.branch1x1 = BasicConv2d(in_channels, <span class="number">64</span>, kernel_size=<span class="number">1</span>)</div><div class="line"></div><div class="line">        self.branch5x5_1 = BasicConv2d(in_channels, <span class="number">48</span>, kernel_size=<span class="number">1</span>)</div><div class="line">        self.branch5x5_2 = BasicConv2d(<span class="number">48</span>, <span class="number">64</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</div><div class="line"></div><div class="line">        self.branch3x3dbl_1 = BasicConv2d(in_channels, <span class="number">64</span>, kernel_size=<span class="number">1</span>)</div><div class="line">        self.branch3x3dbl_2 = BasicConv2d(<span class="number">64</span>, <span class="number">96</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</div><div class="line">        self.branch3x3dbl_3 = BasicConv2d(<span class="number">96</span>, <span class="number">96</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</div><div class="line"></div><div class="line">        self.branch_pool = BasicConv2d(in_channels, pool_features, kernel_size=<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        branch1x1 = self.branch1x1(x)</div><div class="line"></div><div class="line">        branch5x5 = self.branch5x5_1(x)</div><div class="line">        branch5x5 = self.branch5x5_2(branch5x5)</div><div class="line"></div><div class="line">        branch3x3dbl = self.branch3x3dbl_1(x)</div><div class="line">        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)</div><div class="line">        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)</div><div class="line"></div><div class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</div><div class="line">        branch_pool = self.branch_pool(branch_pool)</div><div class="line"></div><div class="line">        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]</div><div class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</div></pre></td></tr></table></figure>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fo7zsanjwbj30sq0t8dj2.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionC</span><span class="params">(nn.Module)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, channels_7x7)</span>:</span></div><div class="line">        super(InceptionC, self).__init__()</div><div class="line">        self.branch1x1 = BasicConv2d(in_channels, <span class="number">192</span>, kernel_size=<span class="number">1</span>)</div><div class="line"></div><div class="line">        c7 = channels_7x7</div><div class="line">        self.branch7x7_1 = BasicConv2d(in_channels, c7, kernel_size=<span class="number">1</span>)</div><div class="line">        self.branch7x7_2 = BasicConv2d(c7, c7, kernel_size=(<span class="number">1</span>, <span class="number">7</span>), padding=(<span class="number">0</span>, <span class="number">3</span>))</div><div class="line">        self.branch7x7_3 = BasicConv2d(c7, <span class="number">192</span>, kernel_size=(<span class="number">7</span>, <span class="number">1</span>), padding=(<span class="number">3</span>, <span class="number">0</span>))</div><div class="line"></div><div class="line">        self.branch7x7dbl_1 = BasicConv2d(in_channels, c7, kernel_size=<span class="number">1</span>)</div><div class="line">        self.branch7x7dbl_2 = BasicConv2d(c7, c7, kernel_size=(<span class="number">7</span>, <span class="number">1</span>), padding=(<span class="number">3</span>, <span class="number">0</span>))</div><div class="line">        self.branch7x7dbl_3 = BasicConv2d(c7, c7, kernel_size=(<span class="number">1</span>, <span class="number">7</span>), padding=(<span class="number">0</span>, <span class="number">3</span>))</div><div class="line">        self.branch7x7dbl_4 = BasicConv2d(c7, c7, kernel_size=(<span class="number">7</span>, <span class="number">1</span>), padding=(<span class="number">3</span>, <span class="number">0</span>))</div><div class="line">        self.branch7x7dbl_5 = BasicConv2d(c7, <span class="number">192</span>, kernel_size=(<span class="number">1</span>, <span class="number">7</span>), padding=(<span class="number">0</span>, <span class="number">3</span>))</div><div class="line"></div><div class="line">        self.branch_pool = BasicConv2d(in_channels, <span class="number">192</span>, kernel_size=<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        branch1x1 = self.branch1x1(x)</div><div class="line"></div><div class="line">        branch7x7 = self.branch7x7_1(x)</div><div class="line">        branch7x7 = self.branch7x7_2(branch7x7)</div><div class="line">        branch7x7 = self.branch7x7_3(branch7x7)</div><div class="line"></div><div class="line">        branch7x7dbl = self.branch7x7dbl_1(x)</div><div class="line">        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)</div><div class="line">        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)</div><div class="line">        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)</div><div class="line">        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)</div><div class="line"></div><div class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</div><div class="line">        branch_pool = self.branch_pool(branch_pool)</div><div class="line"></div><div class="line">        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]</div><div class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</div></pre></td></tr></table></figure>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fo80dcq1fhj30ri0q8dk2.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">InceptionE</span><span class="params">(nn.Module)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels)</span>:</span></div><div class="line">        super(InceptionE, self).__init__()</div><div class="line">        self.branch1x1 = BasicConv2d(in_channels, <span class="number">320</span>, kernel_size=<span class="number">1</span>)</div><div class="line"></div><div class="line">        self.branch3x3_1 = BasicConv2d(in_channels, <span class="number">384</span>, kernel_size=<span class="number">1</span>)</div><div class="line">        self.branch3x3_2a = BasicConv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=(<span class="number">1</span>, <span class="number">3</span>), padding=(<span class="number">0</span>, <span class="number">1</span>))</div><div class="line">        self.branch3x3_2b = BasicConv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">0</span>))</div><div class="line"></div><div class="line">        self.branch3x3dbl_1 = BasicConv2d(in_channels, <span class="number">448</span>, kernel_size=<span class="number">1</span>)</div><div class="line">        self.branch3x3dbl_2 = BasicConv2d(<span class="number">448</span>, <span class="number">384</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</div><div class="line">        self.branch3x3dbl_3a = BasicConv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=(<span class="number">1</span>, <span class="number">3</span>), padding=(<span class="number">0</span>, <span class="number">1</span>))</div><div class="line">        self.branch3x3dbl_3b = BasicConv2d(<span class="number">384</span>, <span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">0</span>))</div><div class="line"></div><div class="line">        self.branch_pool = BasicConv2d(in_channels, <span class="number">192</span>, kernel_size=<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        branch1x1 = self.branch1x1(x)</div><div class="line"></div><div class="line">        branch3x3 = self.branch3x3_1(x)</div><div class="line">        branch3x3 = [</div><div class="line">            self.branch3x3_2a(branch3x3),</div><div class="line">            self.branch3x3_2b(branch3x3),</div><div class="line">        ]</div><div class="line">        branch3x3 = torch.cat(branch3x3, <span class="number">1</span>)</div><div class="line"></div><div class="line">        branch3x3dbl = self.branch3x3dbl_1(x)</div><div class="line">        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)</div><div class="line">        branch3x3dbl = [</div><div class="line">            self.branch3x3dbl_3a(branch3x3dbl),</div><div class="line">            self.branch3x3dbl_3b(branch3x3dbl),</div><div class="line">        ]</div><div class="line">        branch3x3dbl = torch.cat(branch3x3dbl, <span class="number">1</span>)</div><div class="line"></div><div class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</div><div class="line">        branch_pool = self.branch_pool(branch_pool)</div><div class="line"></div><div class="line">        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]</div><div class="line">        <span class="keyword">return</span> torch.cat(outputs, <span class="number">1</span>)</div></pre></td></tr></table></figure>
<h5 id="Auxiliary-Classifiers"><a href="#Auxiliary-Classifiers" class="headerlink" title="Auxiliary Classifiers"></a>Auxiliary Classifiers</h5><p>目的是为了让梯度回传更加有效，从而加快训练，而事实是辅助分类器在训练初期的时候对结果并没有特别大的帮助，在训练后期的时候会超上没有使用辅助分类器的模型。额外辅助器可以作为一个regularizer。</p>
<h5 id="Efficient-Grid-Size-Reduction"><a href="#Efficient-Grid-Size-Reduction" class="headerlink" title="Efficient Grid Size Reduction"></a>Efficient Grid Size Reduction</h5><p>在feature map深度加倍的时候，空间维度需要减半。对于一个k个dxd的feature map，主要有两种选项：</p>
<ol>
<li>首先进行步长为1的卷积，将深度加倍，然后加个pooling，这样的复杂度是$2d^2k^2$，见Figure 9。</li>
<li>扔掉pooling，也就是用一个卷积直接搞定，那么这样的复杂度是$2(\frac{d}{2})^2k^2$，变成了原来的四分之一，但是这样会有表达瓶颈。</li>
<li>用并行的步长为2卷积和pooling，见Figure 10。</li>
</ol>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fo809hnvetj30sg0k6tbp.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fo809udzjvj30sc0mg42c.jpg" alt=""></p>
<h5 id="Inception-v3"><a href="#Inception-v3" class="headerlink" title="Inception-v3"></a>Inception-v3</h5><p>网络的配置见Table 1。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fo80da87wrj30ra0vcagv.jpg" alt=""></p>
<p><strong>Label Smoothing</strong></p>
<p>为了防止模型预测的时候over-confident，用label smoothing来做一个正则化。</p>
<p>将label distribution从$q(k|x)=\delta_{k,y}$替换为$q(k|y)=(1-\epsilon)\delta_{k,y}+\epsilon\mu$</p>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p>首先针对不同的感受野做了实验，见Table2，299x299在保准计算效率的同时，有较高的准确率。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fobcl3nkrlj30ra0a0dhh.jpg" alt=""></p>
<p>单模型比较结果见Table 3。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fobckztjttj30ra0sq7b3.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Identity Mappings in Deep Residual Networks笔记]]></title>
      <url>/2018/02/01/Identity-Mappings-in-Deep-Residual-Networks%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：Identity Mappings in Deep Residual Networks, ECCV 2016</p>
<p>链接：<a href="https://arxiv.org/pdf/1603.05027.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1603.05027.pdf</a></p>
<p>作者: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</p>
<h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h5><p>ResNet的每个unit可以表示为：<br>$$<br>y_l = h(x_l)+F(x_l,W_l) \ x_{l+1} = f(y_l)<br>$$<br>$x_l$是第l个unit的输入，$x_{l+1}$是l个单元的输出。在ResNet v1中，$h(x_l)=x_l$，表示identity mapping(做了3种尝试，选择了这种)，f是ReLU函数，F包含2-3个卷积层，中间还有BN和ReLU（见Figure 1(a))。如果h和f都是identity mapping的时候，<strong>信号可以直接从一个unit到另一个unit，无论是forward还是backward，这样可以使训练更加容易</strong>。</p>
<p>Forward:<br>$$<br>x_{l+1}=x_l+F(x_l,W_l)… \ x_L = x_l + \sum_{i=l}^{L+1}F(x_i,W_i)<br>$$</p>
<ul>
<li>第L层的特征$x_L$可以表示成$x_l+\sum_{i=l}^{L-1}F(x_i,W_i)$</li>
<li>$x_L=x_o+\sum_{i=0}^{L-1}F(x_i,W_i)$，可以由所有的残差函数相加得到，再加上$x_o$</li>
</ul>
<p>Backward:</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fo5tv0mjxdj30my03mjrs.jpg" alt=""></p>
<p>从梯度计算来看，$x_l$的梯度与l+1到L的layer都有关，$\frac{\partial \epsilon}{\partial x_L}$保证梯度会从L穿回到l，而且梯度不会消失，因为$\frac{\partial}{\partial x_l}\sum_{i=l}^{L-1}F(x_i, W_i)$很少为-1。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fo5n89qljvj318e0v4tjb.jpg" alt=""></p>
<p><strong>Identity Skip Connection</strong></p>
<p>主要是印证当shortcut不取identity mapping时，效果为什么不好</p>
<ul>
<li>Scaling, $h(x)=\lambda x$</li>
</ul>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fo5yn3n5gsj30eo03o0sw.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fo5ynmkwmyj30k803uwev.jpg" alt=""></p>
<p>和原来的梯度相比，从1变成了$\prod_{i=l}^{L-1}\lambda_i$，分类讨论，如果$\lambda_i$都大于1，那么如果层数深，梯度爆炸！如果$\lambda_i$都小于1，那么那项就会很小，梯度弥散！堵塞了shortcut。结果见Table 1，容易发现，结果反而变差了！</p>
<ul>
<li><p>Exclusive gating</p>
<p>gating函数， $g(x)=\sigma(W_gx+b_g)$, $(1-g(x)) \times x + g(x)\times F(x)$,在卷积网络中，g(x)是1x1的卷积。</p>
<p>结果依然不如baseline，结果见Table 1。当g(x)=0的时候，近似于identity，但是又抑制了F(x)</p>
</li>
</ul>
<ul>
<li>Shortcut-only gating</li>
</ul>
<p>$(1-g(x))\times x+F(x)$，当$b_g$负的特别多的时候，例如-6，g(x)非常接近0的时候，近似于identity mapping，结果也比exclusive gating更好，更接近baseline，见Table 1。</p>
<ul>
<li>1x1 conv shortcut</li>
</ul>
<p>用1x1的conv代替identity，当深度加深的时候，效果会变差，见Table 1。</p>
<ul>
<li>Dropout shortcut</li>
</ul>
<p>对identity做dropout，类似于做scale，结果也不理想。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fo5yt8ozenj30ye0iy0x5.jpg" alt=""></p>
<p>总结一下：</p>
<p>上述4种对shortcuts的修改，在实验结果上看，都不如identity mapping，可能的原因是影响了梯度的回传！</p>
<p><strong>The impact of f</strong></p>
<p>在原始的ResNet是ReLU，作者探讨了激活函数可能放置的各种方案，见Figure 4</p>
<ol>
<li>f = ReLU</li>
<li>f = BN + ReLU，在CIFAR-10上的训练曲线见Figure 6，加了BN反而结果变差了！。</li>
<li>ReLU放在加前，会导致F(x)的输入都大于等于0，而残差应该是在负无穷和正无穷之间</li>
<li>非对称化，$x_{l+1}=x_l+F(\hat{f}(x_l),W_l)$，训练曲线见Figure 6，体现在训练时，收敛率更高，测试的错误率也更低。</li>
</ol>
<p>在CIFAR-10数据集上的对比结果见Table 2，可以发现，Figure 4(e)的方法错误率最低！</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fo76e6t07mj30ys0kawic.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fo76u1vr05j30yi0i20yf.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fo776l9s7hj31kw0hytdr.jpg" alt=""></p>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p>在ImageNet,CIFAR-10,CIFAR-100这3个数据集上做了对比试验，都取得了state-of-the-art的结果，见Table 4,5。</p>
<p>在深层网络中，体现出了pre-act的作用！</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fo77epwjbgj31900ss10h.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fo76t0q108j30ym0gagqg.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Residual Learning for Image Recognition笔记]]></title>
      <url>/2018/02/01/Deep-Residual-Learning-for-Image-Recognition%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：Deep Residual Learning for Image Recognition, CVPR 2016</p>
<p>链接：<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" rel="external">https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf</a></p>
<p>作者: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</p>
<ul>
<li>提出ResNet(Residual Net)</li>
<li>ILSVRC 2015的classfication task的冠军，达到3.57%的top-5 error rate(152层的模型)</li>
<li>在ILSVRC 2015和MS-COCO 2015中，横扫一切对手夺冠</li>
<li>和VGG相比，深度更深，准确率更高，计算复杂度更小！</li>
</ul>
<h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h5><p>随着网络深度的增加，随之而来的就是网络的<strong>退化(degradation)</strong>，也就是训练和测试的error比浅层的网络还高，见Fig 1。这个问题并不是由overfitting造成的，但是从直觉上讲，更深的模型应该和浅层的模型表现相当，因为我们可以将浅层网络的参数拷贝，然后其余的层就是做identity mapping，但是为什么效果会更差呢？这是因为这是因为深度网络比浅层网络更难训，<strong>很难用多层的非线性层去优化近似identity mapping</strong>。因此，通过将问题转化为学习残差函数来解决网络退化的问题。x是输入，H(x)是底层的映射函数，也就是网络中堆叠的非线性层，$f(x)=H(x)-x$，等价于$H(x)=f(x)+x$。如果最优函数是identity mapping，那么整个学到的参数就会驱使$f(x)=0$(或者尽可能接近于0)。identity mapping不一定是最优的，但是可以帮助预处理问题，可以简化问题。<strong>作者也对此做了一个假设：优化残差映射比优化一个原始映射容易的多。</strong></p>
<blockquote>
<p>If the optimal function is closer to an identity mapping than to a zero mapping, it should be easier for the solver to find the perturbations with reference to an identity mapping, than to learn the function as a new one.</p>
</blockquote>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fo2bil5j4xj30ts0foq6o.jpg" alt=""></p>
<h5 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h5><p><strong>short connection</strong><br>$$<br>y = \mathbf{F}(x,{W_i})+x<br>$$<br>$\mathbf{F}(x,{W_i})$表示待学习的残差mapping。而后面+x这个运算可以通过shortcuts进行element-wise的加法。优点是不需要额外的参数，当维度不统一的时候，可以进行zero padding或者线性投影（虽然会引入少量的参数）使得两者的维度一致。<br>$$<br>y = \mathbf{F}(x,{W_i})+W_sx<br>$$<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fo2br70niwj30za0g0gnk.jpg" alt=""></p>
<p><strong>Bottleneck design</strong></p>
<p>在3x3卷积前后加入1x1卷积来降低和提高feature map的深度，实现feature map之间的线性组合，提高模型的非线性能力，同时还可以使得输入输出的维度保持一致，具体见Figure 5。</p>
<p>Bottleneck的结构也被应用到了50-layer,101-layer,152-layer的网络中。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fo2c143x8uj30sk0fg0vd.jpg" alt=""></p>
<p>Table 1是各个ResNet的模型参数结构，可以发现18-layer和34-layer最终输出的feature map的深度是512，而其余的都是2048，这个由expansion ratio决定。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fo2bwdncg2j31kw0lhwkk.jpg" alt=""></p>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p><strong>ImageNet</strong></p>
<p>首先分别比较了18-layer和34-layer的plain network和residual network，见Figure 4和Table 2。总结如下：</p>
<ul>
<li>在plain network中发现网络退化的问题，18层的网络比34层的网络错误率更低，优化的困难不是由梯度弥散造成的，作者推测是因为<strong><em>深层网络的收敛率更低</em></strong></li>
<li>在ResNet中，情况正好相反</li>
</ul>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fo5lhucus7j31kw0jldmq.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fo2c4ar19tj30t20aqdhw.jpg" alt=""></p>
<p>然后，作者比较了identity shortcuts和projection shortcuts，结果见Table 4。A是zero-padding。B是维度不同用projection，相同用identity，而C则是所有都用projection</p>
<p>可以发现：</p>
<ul>
<li>B略好于A，可以理解就是通过zero-padding加到相同的维度并不是残差学习！</li>
<li>C好于B，但是C引入了大量的需要学习的参数</li>
<li>考虑到模型复杂度和计算复杂度，选择option B</li>
<li>ResNet 50, 101, 151中，随着深度变大，错误率越来越低</li>
</ul>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fo5lpzvxb1j30rw0m0432.jpg" alt=""></p>
<p>与其他state-of-the-art的方法相比，ResNet提升非常明显，见Table 4, 5！</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fo5lyc0rknj30s00jcn1h.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fo5lwnnsklj30sk0ecq63.jpg" alt=""></p>
<p><strong>CIFAR-10</strong></p>
<p>分析每一层的响应，响应值是通过卷积以后，在经过BN，ReLU以后的值，见Figure 7。可以发现，ResNet的响应值都会偏小，也基本印证了残差函数比非残差函数更偏向于0。除此之外，对于ResNet来说，深度越深，响应值也越小。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fo5m7fmpbnj30sc0jidl2.jpg" alt=""></p>
<p><strong>PASCAL VOC 2007/2012 &amp;&amp;COCO</strong></p>
<p>将faster rcnn和ResNet结合，用于做detection，结果见Table 7,8。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fo5mbkcg6tj30tm0aumzn.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fo5mbgcfvaj30sq0860uk.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift笔记]]></title>
      <url>/2018/01/25/Batch-Normalization-Accelerating-Deep-Network-Training-by-Reducing-Internal-Covariate-Shift%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：Batch Normalization: Accelerating Deep Network Training by Reducing Internal<br>  Covariate Shift, ICML 2015</p>
<p>链接：<a href="http://proceedings.mlr.press/v37/ioffe15.pdf" target="_blank" rel="external">http://proceedings.mlr.press/v37/ioffe15.pdf</a></p>
<p>作者: Sergey Ioffe，Christian Szegedy</p>
<h5 id="Idea"><a href="#Idea" class="headerlink" title="Idea"></a>Idea</h5><p><strong>Internal Covariate Shift</strong></p>
<p>什么是Covariate Shift？</p>
<blockquote>
<p>Another assumption one can make about the connection between the source and the target domains is that given the same observation$X=x$, the conditional distributions of Y are the same in the two domains. However, the marginal distributions of X may be different in the source and the target domains. Formally, we assume that $ P_s(Y \vert X = x) = P_t(Y \vert X = x)$ for all $ x \in \mathcal{X}$! but $ P_s(X) \ne P_t(X)$. This difference between the two domains is called <em>covariate shift</em></p>
</blockquote>
<p>covariates其实就是输入特征，记做X，假设对任意的$x\in \mathcal{X}$,$P_s(Y|X=x)=P_t(Y|X=x)$，表示Y关于X的条件分布在source domain（训练集）和target domain（测试集）是一样的，但是$P_s(X)\neq P_t(X) $，两者的边缘分布是不一样的！这个问题经常发生在transfer learning中。从表面上看，对于分类问题，只要两者的条件分布相同，即使边缘分布不同，也不会影响分类的结果，但是，当模型是有参数的时候，也就是$P(Y|X,\theta)$的时候，我们需要选择最优的参数$\theta^*$来使得loss($\theta$)最小。在这个时候，如果$P_s(X)\neq P_t(X) $，也就打破了传统机器学习中训练集和测试集的数据是i.i.d（独立同分布）的，那么在target domain的最优模型会和source domain的不一样，因为参数的求解依赖于X的分布（似然函数）！<br>$$<br>P(\theta|D)=\frac{P(D|\theta)\times P(\theta)}{P(D)}<br>$$<br>Internal Covariate Shift表示的是在神经网络发生的convariate shift，因为网络参数在更新，在神经网络的特定层的输出分布就发生了改变，这就导致它的后面层需要去适应它分布的变化，这就降低了训练速度，影响了模型的训练效果。</p>
<p><strong>Vanishing Gradient</strong></p>
<p>一些容易饱和的非线性激活函数(tanh, sigmoid等)当输入很大的时候，梯度容易饱和。这使得模型在加深的时候，梯度容易消失！以及，ReLU的使用使得部分神经元“死掉”后不再有梯度传回去，随着网络的不断迭代，越来越多的神经元会“死掉”！所以这需要我们：</p>
<ul>
<li>调低学习率</li>
<li>谨慎的初始化</li>
<li>BN</li>
</ul>
<p><strong>Towards Reducing Internal Covariate Shift</strong></p>
<p>目的是在神经网训练过程中，固定layer inputs x的分布。</p>
<p>作者引用了一些研究的发现：</p>
<blockquote>
<p>Network converges faster when the inputs are <em>whitened</em> - that is, normalized to have zero mean, unit variance, and decorrelated (diagonal covariance).</p>
</blockquote>
<p>当网络的输入数据是白化的（均值为0，方差为1的高斯分布）和独立的，网络收敛会更快！但是对整个数据集做白化的话代价很大！需要计算协方差！</p>
<p>看似容易，其实并不好办，因为我们在考虑白话网络层输出的激活值的时候，需要直接修改网络或者优化算法的参数值来保证分布固定。</p>
<p>例如，某层的输入是u，加上bias b，得到输出u+b，再减掉均值做normalization, $x-E[x]$。这样做的后果就是bias会一直改变，而loss没有任何变化。</p>
<p>$u+(b+\Delta b)-E[u+(b+\Delta b)]=u+b-E[u+b]$</p>
<p>作者也经过实验发现：</p>
<blockquote>
<p>the model blows up when the normalization parameters are computed outside the gradient descent step</p>
</blockquote>
<p><strong>Batch Normalization</strong></p>
<p>所以，作者将每一层的输出在激活函数前做归一化（假设数据都是i.i.d）。利用均值和方差去归一化以后，还对数据做了平移放缩。所有的步骤都是可微的，所以是可以用bp优化的。    </p>
<p>对于卷积层的BN，做法是将每个各自feature map归一化，例如feature map的大小为pxq，batch size为n，就是计算nxpxq的平均值和方差。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fnsve61xlbj30sc0mg787.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fnxqbppxzbj30ja0b4myf.jpg" alt=""></p>
<p><strong>BN的好处</strong></p>
<ul>
<li><p>减少internal covariant shift，梯度爆炸，梯度消失，从而减少训练时间</p>
<ul>
<li>将输入的分布固定</li>
</ul>
</li>
<li><p>可以减少正则化的使用，例如l2正则，dropout等</p>
<ul>
<li>实验证明</li>
</ul>
</li>
<li><p>可以使用一些饱和的非线性函数，sigmoid等, 例如ReLU激活函数，有些neuron在不加BN的情况下已经死掉了，但是经过BN以后，还是会有梯度回传回去</p>
<ul>
<li>平移和缩放</li>
</ul>
</li>
<li><p>可以使用更高的学习率</p>
<p>BN(    Wu)=BN((aW)u),因为$\frac{\partial BN((aW)u)}{\partial u}=\frac{\partial BN(Wu)}{\partial u}$，以及$\frac{\partial BN((aW)u)}{\partial aW}=\frac{1}{a}\frac{\partial BN(Wu)}{\partial W}$。大的weight，反而是会让梯度更小，这样就可以使训练更加平稳。</p>
<p>​</p>
</li>
</ul>
<p><strong>代码实现：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_forward</span><span class="params">(x, gamma, beta, bn_param)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Forward pass for batch normalization.</span></div><div class="line"><span class="string">  During training the sample mean and (uncorrected) sample variance are</span></div><div class="line"><span class="string">  computed from minibatch statistics and used to normalize the incoming data.</span></div><div class="line"><span class="string">  During training we also keep an exponentially decaying running mean of the mean</span></div><div class="line"><span class="string">  and variance of each feature, and these averages are used to normalize data</span></div><div class="line"><span class="string">  at test-time.</span></div><div class="line"><span class="string">  At each timestep we update the running averages for mean and variance using</span></div><div class="line"><span class="string">  an exponential decay based on the momentum parameter:</span></div><div class="line"><span class="string">  running_mean = momentum * running_mean + (1 - momentum) * sample_mean</span></div><div class="line"><span class="string">  running_var = momentum * running_var + (1 - momentum) * sample_var</span></div><div class="line"><span class="string">  Note that the batch normalization paper suggests a different test-time</span></div><div class="line"><span class="string">  behavior: they compute sample mean and variance for each feature using a</span></div><div class="line"><span class="string">  large number of training images rather than using a running average. For</span></div><div class="line"><span class="string">  this implementation we have chosen to use running averages instead since</span></div><div class="line"><span class="string">  they do not require an additional estimation step; the torch7 implementation</span></div><div class="line"><span class="string">  of batch normalization also uses running averages.</span></div><div class="line"><span class="string">  Input:</span></div><div class="line"><span class="string">  - x: Data of shape (N, D)</span></div><div class="line"><span class="string">  - gamma: Scale parameter of shape (D,)</span></div><div class="line"><span class="string">  - beta: Shift paremeter of shape (D,)</span></div><div class="line"><span class="string">  - bn_param: Dictionary with the following keys:</span></div><div class="line"><span class="string">    - mode: 'train' or 'test'; required</span></div><div class="line"><span class="string">    - eps: Constant for numeric stability</span></div><div class="line"><span class="string">    - momentum: Constant for running mean / variance.</span></div><div class="line"><span class="string">    - running_mean: Array of shape (D,) giving running mean of features</span></div><div class="line"><span class="string">    - running_var Array of shape (D,) giving running variance of features</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - out: of shape (N, D)</span></div><div class="line"><span class="string">  - cache: A tuple of values needed in the backward pass</span></div><div class="line"><span class="string">  """</span></div><div class="line">  mode = bn_param[<span class="string">'mode'</span>]</div><div class="line">  eps = bn_param.get(<span class="string">'eps'</span>, <span class="number">1e-5</span>)</div><div class="line">  momentum = bn_param.get(<span class="string">'momentum'</span>, <span class="number">0.9</span>)</div><div class="line"></div><div class="line">  N, D = x.shape</div><div class="line">  running_mean = bn_param.get(<span class="string">'running_mean'</span>, np.zeros(D, dtype=x.dtype))</div><div class="line">  running_var = bn_param.get(<span class="string">'running_var'</span>, np.zeros(D, dtype=x.dtype))</div><div class="line"></div><div class="line">  out, cache = <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line">  <span class="keyword">if</span> mode == <span class="string">'train'</span>:</div><div class="line">    mean = np.sum(x,axis=<span class="number">0</span>)/float(N)</div><div class="line">    x_mean = (x - mean)</div><div class="line">    sqr_x_mean = x_mean**<span class="number">2</span></div><div class="line">    var = np.sum(sqr_x_mean, axis=<span class="number">0</span>)/float(N)</div><div class="line">    sqrt_var = np.sqrt(var+eps)</div><div class="line">    inv_sqrt_var = <span class="number">1.0</span>/sqrt_var</div><div class="line">    x_hat = x_mean*inv_sqrt_var</div><div class="line">    out = gamma * x_hat + beta</div><div class="line">    cache = (x_hat,gamma,sqr_x_mean,mean,var,sqrt_var,x_mean,inv_sqrt_var)</div><div class="line"></div><div class="line">    running_mean = momentum*running_mean + (<span class="number">1.0</span>-momentum)*mean</div><div class="line">    running_var = momentum*running_var + (<span class="number">1.0</span>-momentum)*var</div><div class="line">   </div><div class="line">  <span class="keyword">elif</span> mode == <span class="string">'test'</span>:</div><div class="line"></div><div class="line">    x_hat = (x - running_mean)/np.sqrt(running_var+eps)</div><div class="line">    out = gamma * x_hat + beta</div><div class="line">  <span class="keyword">else</span>:</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'Invalid forward batchnorm mode "%s"'</span> % mode)</div><div class="line"></div><div class="line">  <span class="comment"># Store the updated running means back into bn_param</span></div><div class="line">  bn_param[<span class="string">'running_mean'</span>] = running_mean</div><div class="line">  bn_param[<span class="string">'running_var'</span>] = running_var</div><div class="line">  <span class="keyword">return</span> out, cache</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_backward</span><span class="params">(dout, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Backward pass for batch normalization.</span></div><div class="line"><span class="string">  For this implementation, you should write out a computation graph for</span></div><div class="line"><span class="string">  batch normalization on paper and propagate gradients backward through</span></div><div class="line"><span class="string">  intermediate nodes.</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - dout: Upstream derivatives, of shape (N, D)</span></div><div class="line"><span class="string">  - cache: Variable of intermediates from batchnorm_forward.</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - dx: Gradient with respect to inputs x, of shape (N, D)</span></div><div class="line"><span class="string">  - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)</span></div><div class="line"><span class="string">  - dbeta: Gradient with respect to shift parameter beta, of shape (D,)</span></div><div class="line"><span class="string">  """</span></div><div class="line">  x_hat,gamma,sqr_x_mean,mean,var,sqrt_var,x_mean,inv_sqrt_var = cache</div><div class="line">  dx, dgamma, dbeta = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line"></div><div class="line">  N = x_hat.shape[<span class="number">0</span>]</div><div class="line">    </div><div class="line">  dx_hat = dout * gamma</div><div class="line">  dx_mean = dx_hat*inv_sqrt_var</div><div class="line">  dinv_sqrt_var = np.sum(dx_hat*x_mean,axis=<span class="number">0</span>)</div><div class="line">  dsqrt_var = <span class="number">-1.0</span>/(sqrt_var**<span class="number">2</span>)*dinv_sqrt_var</div><div class="line">  dvar = <span class="number">0.5</span>*inv_sqrt_var*dsqrt_var</div><div class="line">  dsqr_x_mean = <span class="number">1.0</span>/N*np.ones(sqr_x_mean.shape)*dvar</div><div class="line">  dx_mean += <span class="number">2</span>*x_mean*dsqr_x_mean</div><div class="line"></div><div class="line">  dmean = -np.sum(dx_mean,axis=<span class="number">0</span>)</div><div class="line">  dx1 = dx_mean</div><div class="line">  dx2 = <span class="number">1.0</span>/N*np.ones(mean.shape)*dmean</div><div class="line">  dx = dx1+dx2</div><div class="line">  dgamma = np.sum(x_hat*dout,axis=<span class="number">0</span>)</div><div class="line">  dbeta =  np.sum(dout,axis=<span class="number">0</span>)</div><div class="line"></div><div class="line">  <span class="keyword">return</span> dx, dgamma, dbeta</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchnorm_backward_alt</span><span class="params">(dout, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Alternative backward pass for batch normalization.</span></div><div class="line"><span class="string">  For this implementation you should work out the derivatives for the batch</span></div><div class="line"><span class="string">  normalizaton backward pass on paper and simplify as much as possible. You</span></div><div class="line"><span class="string">  should be able to derive a simple expression for the backward pass.</span></div><div class="line"><span class="string">  Note: This implementation should expect to receive the same cache variable</span></div><div class="line"><span class="string">  as batchnorm_backward, but might not use all of the values in the cache.</span></div><div class="line"><span class="string">  Inputs / outputs: Same as batchnorm_backward</span></div><div class="line"><span class="string">  """</span></div><div class="line">  dx, dgamma, dbeta = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line">  x_hat,gamma,sqr_x_mean,mean,var,sqrt_var,x_mean,inv_sqrt_var = cache</div><div class="line">  N = x_hat.shape[<span class="number">0</span>]</div><div class="line">  dbeta = np.sum(dout,axis=<span class="number">0</span>)</div><div class="line">  dgamma = np.sum(dout*x_hat,axis=<span class="number">0</span>)</div><div class="line"></div><div class="line">  dx = <span class="number">1.0</span>/N*inv_sqrt_var*gamma*(</div><div class="line">   N*dout</div><div class="line">   -np.sum(dout,axis=<span class="number">0</span>)</div><div class="line">   -x_mean*(inv_sqrt_var**<span class="number">2</span>)*np.sum(dout*x_mean,axis=<span class="number">0</span>)</div><div class="line">  )</div><div class="line"></div><div class="line">  <span class="keyword">return</span> dx, dgamma, dbeta</div></pre></td></tr></table></figure>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p><strong>MNIST</strong></p>
<p>Fig 1(a)是一个小网络在MNIST数据集上的表现，可以看出加了BN整个训练过程更加平稳。Fig 1(b,c)是输入分布的变化，三条线分别是15，50，85，可以发现BN的数值更加分开，更有区分度，分布更加稳定。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fnxqqs6d9sj30m40eewhn.jpg" alt=""></p>
<p><strong>IMAGENET</strong></p>
<p>做了一些修改：</p>
<ul>
<li>提高学习率</li>
<li>移除Dropout</li>
<li>样本更加分布均匀，完全打乱</li>
<li>减少L2正则</li>
<li>加速learning rate decay</li>
<li>移除LRN</li>
<li>减少一些数据增强的方法</li>
</ul>
<p>见Figure 3, 可以发现BN对结果提升还是比较明显的</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fnxs1k4lpej30kc0c2di6.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Going Deeper with Convolutions笔记]]></title>
      <url>/2018/01/25/Going-Deeper-with-Convolutions%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文 ：Going Deeper with Convolutions,CVPR 2015 </p>
<p>链接：<a href="https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf" target="_blank" rel="external">https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf</a></p>
<p>作者: Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich </p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fnsrwl5iuuj31040kc1dy.jpg" alt=""></p>
<p><strong>Contribution</strong> </p>
<ul>
<li>提出了GoogleNet的网络结构，由若干Inception Module堆叠而成。 </li>
<li>在ILSVRC 2014上拿到了classification task和detection task的冠军。</li>
</ul>
<p><strong>Motivation</strong></p>
<p>对于DCNN来说，增大网络的大小是一个直接提升网络性能的方法，增大网络大小包括增加网络的深度，增大网络的宽度，也就是每个level的神经元数量。 但是增大网络也伴随着问题：</p>
<ol>
<li>大量的参数需要优化</li>
<li>容易过拟合</li>
<li>需要大量的喂大量的标签数据，而数据是很昂贵的！</li>
<li>模型越大，所需要的计算资源也越多</li>
</ol>
<p>所以，本着<em>Occam’s Razor</em>，简洁才是王道的思想，需要更加精细地优化网络结构。</p>
<p>作者也引用了一些理论依据：</p>
<blockquote>
<p>if the probability distribution of the dataset is representable by a large, very sparse deep neural network, then the optimal network topology can be constructed layer after layer by analyzing the correlation statistics of the preceding layer activations and clustering neurons with highly correlated outputs.</p>
<p> Hebbian principle – neurons that fire together, wire together</p>
</blockquote>
<p>还有一些客观事实：</p>
<blockquote>
<p>Steadily improving and highly tuned numerical libraries that allow for extremely fast dense matrix multiplication</p>
</blockquote>
<p>所以，作者想到的是用一些readily avaliable dense blocks去模拟近似构造local sparse structure。</p>
<p><strong>Inception Module:</strong></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fnsryufma2j30o20titbv.jpg" alt=""></p>
<p>Fig 2是Inception Module的图示，从Fig 2(a)可以看出主要有5个部分：</p>
<ol>
<li>$1\times 1$ convolution</li>
<li>$3\times 3$ convolution</li>
<li>$5\times 5$ convolution</li>
<li>$3\times 3$ max pooling</li>
<li>filter concatenation</li>
</ol>
<p>运用了不同感受野的卷积，1x1的卷积可以capture dense information clusters，3x3 and 5x5的卷积可以capture more spatially spread out clusters</p>
<p>但是容易发现，这样的结构会导致channel的数量增长很快！</p>
<p>以下图为例： 输入大小是$28\times28\times256$，输出分别是$28\times28\times128$，$28\times28\times192$，$28\times28\times96$，$28\times28\times256$，filter concatenation以后，输出是$28\times28\times672$!!!</p>
<p>再看一下计算量:</p>
<p>$[1\times1 conv, 128]$  $28\times28\times128\times1\times1\times256$</p>
<p>$[3\times3 conv, 192]$ $28\times28\times192\times3\times3\times256$<br>$[5\times5 conv, 96]$ $28\times28\times96\times5\times5\times256$</p>
<p>总共大概有854M ops。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fnss7rs69gj30qg0gijtb.jpg" alt=""></p>
<p>优化：通过$1\times 1$卷积进行降维（保留空间信息，降低深度），其实可以等价成做embedding，将高维的信息映射到低维，同时保证低维的embeddings包含高维数据的大部分信息。</p>
<p>下图是经过优化后的结构，再统计一下卷积计算量：</p>
<p>$[1\times1 conv, 64]$ $28\times28\times64\times1\times1\times256$<br>$[1\times1 conv, 64]$ $28\times28\times64\times1\times1\times256$<br>$[1\times1 conv, 128]$ $28\times28\times128\times1\times1\times256$<br>$[3\times3 conv, 192]$ $28\times28\times192\times3\times3\times64$<br>$[5\times5 conv, 96]$ $28\times28\times96\times5\times5\times64$<br>$[1\times1 conv, 64]$ $28\times28\times64\times1\times1\times256$<br>总共358M ops</p>
<p>和naive的版本比较，可以说少了一半！</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fnsshqu6hij30qg0kowhs.jpg" alt=""></p>
<p>Fig 3是模型的全图，可以发现，整个模型基本上是由多个inception module堆叠而成，同时模型也利用多multi-scale的特征建立auxiliary classifiers，也可以帮助梯度的回传。Table 1是模型可视化的另一个形式。可以发现，随着深度的增加，inception module里面，1x1卷积的fitlers的数量和3x3卷积或5x5卷积的比率逐渐升高。<strong><em>其实深度越深，空间信息对特征抽象的重要性在逐渐降低（as features of higher abstraction are captured by higher layers, their spatial concentration is expected to decrease.。</em></strong></p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fnssmysygpj30ba0r8go0.jpg" alt=""></p>
<p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fnssrbjv00j312i0qm0zf.jpg" alt=""></p>
<p><strong>训练细节：</strong></p>
<ul>
<li>没有使用额外数据</li>
<li>独立训练7个相同结构的模型</li>
<li>将每个图像resize到四个不同的scale(256,288,320,352)，然后拿到left,center,right的square image，在对每个square image取四个角落，中间，以及resized这6个图像，然后再对它们做镜像，所以每张图像一共有4x3x6x2=144张！</li>
<li>将每个crop的softmax加起来取平均</li>
</ul>
<p><strong>实验：</strong></p>
<p>Table 2-5都是实验对比结果,Table 2中，可以发现GoogLeNet在ILSVRC 2014分类比赛中，拿到第一，并取得了Error(top-5) 6.67%的成绩。Table 4是在detection任务上的表现，获得了第一。Table 5是单模型在detection任务上的表现，也非常不错。Table 3是在预测图像时选用不同模型数量ensemble和crop的数量的表现对比，可以发现，多模型和尽可能多的crop对表现提升最大。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fnst7i0modj30py0hoq5r.jpg" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fnst7k1klyj30q80foacb.jpg" alt=""></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fnst7ottrsj313q0by415.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fnst7mjw0hj30oo0newhg.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Visualizing and UnderstandingConvolutional Networks笔记]]></title>
      <url>/2018/01/18/Visualizing-and-UnderstandingConvolutional-Networks%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>​论文：Visualizing and UnderstandingConvolutional Networks</p>
<p>作者：Matthew D Zeiler, Rob Fergus, ECCV, 2014</p>
<p>链接：<a href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" target="_blank" rel="external">https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf</a></p>
<p>博客链接：<a href="http://wulimengmeng.top/2018/01/18/Visualizing-and-UnderstandingConvolutional-Networks%E7%AC%94%E8%AE%B0/">http://wulimengmeng.top/2018/01/18/Visualizing-and-UnderstandingConvolutional-Networks%E7%AC%94%E8%AE%B0/</a></p>
<p>代码实现： <a href="https://github.com/mowayao/Deconvnet" target="_blank" rel="external">https://github.com/mowayao/Deconvnet</a></p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnkxf4e7rcj318g0dgdke.jpg" alt=""></p>
<p><strong>Idea:</strong> 模型的可视化对模型的优化非常重要，更好的理解模型可以帮助我们更好地改进模型。作者将网络的任一层输出的feature maps通过Deconvnet反馈到最终的输入（input pixel space）上（reveals the input stimuli that excite individual feature maps at any layer in the model）。</p>
<h5 id="Deconvnet"><a href="#Deconvnet" class="headerlink" title="Deconvnet"></a>Deconvnet</h5><p>Deconvnet，顾名思义，就是将卷积，pooling，ReLU等运算做逆运算，将feature maps映射回pixels，可视化该feature map被原图哪部分特征激活，从而理解该feature map从原图像学习了何种特征。</p>
<p>随机选择一些不同层的feature maps，经过“反向运算”，<strong><em>unpooling-&gt;ReLU-&gt;Transposed Conv</em></strong>，映射到输入，具体可以见Fig. 1。左边为Deconvnet，右边是Convnet，Unpooling层和pooling层一一对应。convnet是输入图像提取特征，而deconvnet是从特征映射到输入图像。</p>
<p><strong>Unpooling:</strong> 通过记录每个pooling region的最大值的位置，在运算的时候将最大值复制到原来的位置，其他位置的值设为0。</p>
<p><strong>ReLU</strong>：和forward时的ReLU运算相同</p>
<p><strong>Filtering</strong>: 就是卷积的逆运算，卷积核的转置。</p>
<p>考虑一个简单的卷积层运算，其参数为(feature map dim=4, kernel size=3, stride=1, padding=0, output dim=2)</p>
<p>我们可以将$3\times3$ kernel转换成等价的稀疏矩阵C：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fnqehkh9h4j30kc02hweb.jpg" alt=""></p>
<p>再将$[4\times 4]$的输入转换成等价的16维的向量，那么$y=Cx$的输出就是一个4维向量，再将其转换成$2\times2$的矩阵，得到最终的结果。</p>
<p>而Deconv也称Transposed conv，就是变成$C^Ty$。</p>
<p>其实整个过程和convolution的back-propagation是很像的。<br>$$<br>\frac{\partial L}{\partial x_i} = \sum_j\frac{\partial y_j}{\partial  x_i}\cdot\frac{\partial L}{\partial y_j} \ = \sum_{j}C_{i,j}\cdot \frac{\partial L}{\partial y_j} \ = C^T_{*,i} \frac{\partial L}{\partial y}<br>$$<br>还有一个很重要的概念需要厘清：为什么用这种类似back-propogation的方法将feature map映射回输入图像，可以反应出feature map在原图中学到的东西？</p>
<p>我们假设CNN是一个high level的非线性函数$f(X)$，输出是feature map。我们这里把所有的参数看成一个整体，做一个近似:<br>$$<br>f(X) \approx  W_iX<br>$$<br>这里的$W_i$表示的是第i个pattern，那么$f(X)$求关于X的梯度其实就是pattern W。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnkv3ckslgj30us0qowkv.jpg" alt=""></p>
<h5 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h5><p>基于AlexNet修改，将第一层$11\times 11$的大小减小到$7\times 7$, 并将步长从4减少到2， 并ImageNet 2012数据集上训练，具体见Fig. 3。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnkzcp3ebcj30uy0i2791.jpg" alt=""></p>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p><strong>可视化：</strong></p>
<p>结果见Fig. 2。 </p>
<p>Layer 1: 可以看到基本上是一些图像最基本的元素，例如，edge，corner等。</p>
<p>Layer 2-5： 随着深度的加深，其特征越来越具体，variance也越来越大！具有越来越强的辨别能力。</p>
<p>说明CNN学习到的特征是层次化的！</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnkzpsayskj30ji0sc1kx.jpg" alt=""></p>
<p><strong>遮挡实验：</strong></p>
<p>将图片中的一些区域进行遮挡，将其换成灰色方块，结果见Fig 6。具体以第一行为例，可以发现，当狗的身体一部分被遮挡时，网络还是显示亮蓝色，表示预测的是网球。说明，网络已经学会根据图像的context信息去剔除与目标无关的区域或者物体。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fnl01ru982j30q40s84hp.jpg" alt=""></p>
<p><strong>Varying ImageNet Model Sizes：</strong></p>
<p>对AlextNet进行模型调优，结果见Table 2。主要有几个发现：</p>
<ul>
<li>去掉全连接层反而降低了错误率</li>
<li>增大中间层的卷积的数量可以大大提升模型性能</li>
</ul>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fnl14d4h7dj30zu0m2q8s.jpg" alt=""></p>
<p><strong>Feature Generalization:</strong></p>
<p>测试模型的泛化能力，在Caltech-101, Caltech-256，PASCAL VOC 2012这三个数据集上测试模型提取特征的泛化性。 具体的做法就是1-7层的参数不动，然后训练一个新的softmax分类器。具体结果见Table 3, 4, 5，显示出了很强的泛化能力。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fnl1hi1a55j30z20b8tav.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnl1hwfrjwj30rs0ay40f.jpg" alt=""></p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnl1hydlkcj30zm0iy0yg.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classfication </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Network In Network算法笔记]]></title>
      <url>/2018/01/18/Network-In-Network%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Network In Network</p>
<p>作者：Min Lin, Qiang Chen, Shuicheng Yan  ICLR 2014</p>
<p>链接：<a href="https://arxiv.org/pdf/1312.4400.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1312.4400.pdf</a></p>
<p><strong>Idea:</strong> 传统的CNN一般就是通过linear filter和输入的每个和filter大小相同的local patches做内积，然后再跟一个非线性激活函数。CNN的linear filter对于输入的每个local patch，是一个GLM（generalized linear model）。作者argue：GLM的抽象层次比较低(the level of abstraction of GLM is low)，这里的level of abstrction可以理解成不变性的抽象层次（invariant to the variants of some concepts）。GLM依赖于data或者concept线性可分的assumption，当data或者concept线性不可分的时候抽象能力就大大下降，而实际上现实中图像数据往往是low-dim manifold in high-dim space，所以往往是线性不可分的。因此作者提出用一些非线性的函数逼近器(nonlinear function approximator)来代替GLM，从而能够提取local patches更抽象的特征，提高模型对于local patch的判别能力（discrimminability）。Figure 1就是传统的CNN和NIN的比较。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnkplf4900j319g0kigpu.jpg" alt=""></p>
<h5 id="模型细节"><a href="#模型细节" class="headerlink" title="模型细节"></a>模型细节</h5><p>本质上是将convolution -&gt; relu替换为convolution -&gt; relu -&gt; convolution (1x1 filter) -&gt; relu</p>
<p>对于$1\times 1$的卷积，在二维的情况下只是起到scale的作用，例如输入是$[32×32]$做1×1的卷积，只是对输入的每个元素做放大或者缩小，而如果输入是$[32×32×3]$，再做1×1的卷积，那么它其实就是对该位置的所有通道的线性组合，也可以叫做feature pooling或coordinate-dependent transformation。</p>
<p>最大的贡献是:</p>
<ol>
<li>$1\times 1$ 卷积的用法</li>
<li>Global average pooling的应用</li>
</ol>
<p>优点：</p>
<ol>
<li>local patch的抽象能力强</li>
<li>通过global average pooling减少overfitting</li>
<li>参数少,用GAP代替全连接层</li>
</ol>
<p><strong>MLP Convolution Layers</strong></p>
<p>作者选择多层的感知机(其实也就是 $1\times1$  的卷积层)作为function approximator，并列举了两个理由：</p>
<ol>
<li>和CNN兼容，可以用BP训练</li>
<li>自身可以作为一个deep model，可以用 $1\times 1$ 的卷积替代</li>
</ol>
<p>传统的CNN的feature maps的计算如下,ReLU为激活函数：<br>$$<br>f_{i,j,k} = \max(w_k^Tx_{i,j},0)<br>$$<br>maxout层feature maps的计算如下：<br>$$<br>f_{i,j,k}=\max_m(w_{k_m}^Tx_{i,j})<br>$$<br>maxout其实就是ReLU和Leaky ReLU的扩展，提升非线性能力，弥补了两者的缺点，例如应用ReLU激活函数，训练到后面，大部分neron会“挂掉”，因为已经死掉的neuron不会再有梯度了！除此之外，maxout的拟合能力是非常强的，它可以拟合任意的的凸函数。最直观的解释就是任意的凸函数都可以由分段线性函数以任意精度拟合。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fnlus4z8aaj30e904d74l.jpg" alt=""></p>
<p>mlpconv layer的计算如下：<br>$$<br>f_{i,j,k_1}^1=\max({w_{k_1}^1}^Tx_{i,j}+b_{k_1},0) \ … \ f_{i,j,k_n}^n=\max({w_{k_n}^n}^Tx_{i,j}+b_{k_n},0)<br>$$</p>
<p>n是多层感知机的层数。Figure 2是NIN的整体结构。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fnkq60369mj31780gsn1j.jpg" alt=""></p>
<p><strong>Global Average Pooling</strong></p>
<p>传统的CNN网络在做完所有卷积运算后，会把feature maps拉成一条向量，然后再接几层全连接层做分类。这样的问题是，多层的全连接经常会overfitting，当然也可以加Dropout来作为regularizer提高泛化性。作者提出global average pooling来取代全连接层，顾名思义，就是对每个feature map求全局平均，这样整个输出就变成了长度为feature maps深度的向量，这样能够有更好的空间不变形。除此之外，因为减少了待优化的参数避免了过拟合的发生。</p>
<h5 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h5><p><strong>Pytorch</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes)</span>:</span></div><div class="line">        super(Net, self).__init__()</div><div class="line">        self.num_classes = num_classes</div><div class="line">        self.classifer = nn.Sequential(</div><div class="line">                nn.Conv2d(<span class="number">3</span>, <span class="number">192</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.Conv2d(<span class="number">192</span>, <span class="number">160</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.Conv2d(<span class="number">160</span>,  <span class="number">96</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</div><div class="line">                nn.Dropout(<span class="number">0.5</span>),</div><div class="line"></div><div class="line">                nn.Conv2d(<span class="number">96</span>, <span class="number">192</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.AvgPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>),</div><div class="line">                nn.Dropout(<span class="number">0.5</span>),</div><div class="line"></div><div class="line">                nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.Conv2d(<span class="number">192</span>, <span class="number">192</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.Conv2d(<span class="number">192</span>,  num_classes, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</div><div class="line">                nn.ReLU(inplace=<span class="keyword">True</span>),</div><div class="line">                nn.AvgPool2d(kernel_size=<span class="number">8</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</div><div class="line">                )</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = self.classifer(x)</div><div class="line">        x = x.view(<span class="number">-1</span>, self.num_classes)</div><div class="line">        <span class="keyword">return</span> x</div></pre></td></tr></table></figure>
<h5 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h5><p>作者在CIFAR-10, CIFAR-100, SVHN和MNIST上进行测试。</p>
<p><strong>CIFAR-10</strong>: 50,000个训练样本，10,000个测试样本，图像大小为 $32\times32$ ，实验结果见Table 1。Dropout和data augmentation对结果提升明显。It turns out in our experiment that using dropout in between the mlpconv layers in NIN boosts the performance  of  the  network  by  improving  the  generalization  ability  of  the  model. </p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fnkr9b10ylj30xk0fe0wc.jpg" alt=""></p>
<p><strong>CIFAR-100</strong>: 数据规模和图像大小和cifar-10一样，不同的是它有100类，结果见Table 2。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fnkrewcgz6j30fc066aaq.jpg" alt=""></p>
<p><strong>SVHN</strong>：包含630,420张 $32\times32$ 的图像，将其分类训练集，验证集，测试集。具体结果见Table 3。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fnkrhat3qrj30fy07wt9o.jpg" alt=""></p>
<p><strong>MNIST</strong>：包含60,000张$28\times 28$的训练图像，和10,000张测试图像，具体结果见Table 4。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fnkrjy6lgqj30ey05ejrx.jpg" alt=""></p>
<p><strong>Global Average Pooling</strong></p>
<p>通过控制变量，发现GAP对结果的提升还是比较明显的，可以作为regularizer，具体见Table 5。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fnkrld8nt8j30g8056mxo.jpg" alt=""></p>
<p><strong>Visualization</strong></p>
<p>Figure 4 展示了一些样例图片采样自cifar-10和它们对应类别的features maps。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fnkrpb3zc7j30nu0f80y5.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classfication </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[AlexNet算法笔记]]></title>
      <url>/2018/01/18/AlexNet%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：ImageNet Classification with Deep Convolutional Neural Networks</p>
<p>链接：<a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="external">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf</a></p>
<p>AlexNet是发表在NIPS 2012的一篇文章，可以称作是深度学习的经典之作，获得了ImageNet LSVRC-2010的冠军，达到了15.3%的top-5 error。</p>
<p><strong>模型结构：</strong></p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fndsfv7yy4j31a80fu0y3.jpg" alt=""></p>
<p>下面是模型的具体描述：</p>
<p>$[227\times227\times3]$ 输入<br>$[55\times55\times96]$ CONV1: 96 $11\times11$ filters at stride 4, pad 0   <u>(227-11)/4+1 = 55</u><br>$[27\times27\times96]$  MAX POOL1: $3\times3$ filters at stride 2   <u>(55-3)/2+1=27</u><br>$[27\times27\times96]$ NORM1: Normalization layer<br>$[27\times27\times256]$ CONV2: 256 $5\times5$ filters at stride 1, pad 2   <u>(27+2*2-5)/1 + 1=27</u><br>$[13\times13\times256]$ MAX POOL2: $3\times3$ filters at stride 2   <u>(27-3)/2+1=13</u><br>$[13\times13\times256]$ NORM2: Normalization layer<br>$[13\times13\times384]$ CONV3: 384 $3\times3$ filters at stride 1, pad 1<br>$[13\times13\times384]$ CONV4: 384 $3\times3$ filters at stride 1, pad 1<br>$[13\times13\times256]$ CONV5: 256 $3\times3$ filters at stride 1, pad 1<br>$[6\times6\times256]$ MAX POOL3: $3\times3$ filters at stride 2    <u>(13-3)/2+1=6</u><br>$[4096]$ FC6: 4096 neurons<br>$[4096]$ FC7: 4096 neurons<br>$[1000]$ FC8: 1000 neurons (class scores)</p>
<p>包含了5层卷积层和3层全连接层。</p>
<p><strong>创新点：</strong></p>
<ol>
<li><p>第一次使用了ReLU激活函数。传统的sigmoid和tanh激活函数的问题在于梯度容易饱和，造成训练困难，下图是sigmoid函数的梯度。而$f(x)=\max(0,x)$看出，ReLU是一个非线性激活函数，而且它的梯度不会饱和，当x&gt;0的时候，梯度一直是1，这样和sigmoid和tanh函数相比，加快了训练的速度。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fnhlvvatogj30my0egtbr.jpg" alt=""></p>
</li>
<li><p>使用了Norm Layer，对局部区域进行归一化，对相同空间位置上相邻深度的卷积做归一化。$b_{x,y}^i=\frac{a_{x,y}^i}{(k+\alpha\sum_{j=\max(0,i-n/2)}^{min(N-1,i+n/2)}(a_{i,j})^2)^\beta}$,其中$a_{x,y}^i$表示的是第i个通道的卷积核在$(x,y)$位置处的输出结果，随后经过ReLU激活函数作用。a是每一个神经元的激活值，n是kernel的大小，N是kernel总数，k,alpha,beta都是预设的hyper-parameters.，$k=2,n=5,\alpha=1e-4,\beta=0.75$。从公式可以看出，给原来的激活值$a$加了一个权重，生成了新的激活值b,也就是在不同map的同一空间位置进行了归一化，提高了计算效率。但是这些值为什么这么设置就不得而知了。</p>
</li>
<li><p>大量的数据增强，水平翻转，镜像等。调整RGB channel的值，对数据集所有图像的RGB值做PCA变换，完成去噪功能，同时为了保证图像的多样性，在特征值上加了一个随机的尺度因子，每一轮重新生成一个尺度因子，起到了正则化的作用。</p>
</li>
<li><p>Dropout, hidden layer的输出有0.5的几率会被置为0，那些被droped的点不会参与forward pass和backprogation，这样起到了正则化的作用。需要注意的是，在测试过程中，需要将输出乘上0.5。这是因为在训练的过程中，我们只选择了其中的一半，训练出来的结果相当于原来方法的两倍，所以当测试的时候需要乘上0.5来消除这个影响。</p>
</li>
</ol>
<p><strong>训练细节：</strong></p>
<ul>
<li>batch size为128，momentum为0.9，weight decay为0.0005，其实weight decay是l2正则是有区别的，详细可见：<a href="https://arxiv.org/pdf/1711.05101.pdf" target="_blank" rel="external">https://arxiv.org/pdf/1711.05101.pdf</a></li>
<li>初始的learning rate设为1e-2, 当验证集的正确率停止的时候乘0.1</li>
</ul>
<p><strong>实验结果：</strong></p>
<p>最终的实验结果见Table 1。可以发现，CNN的结果在Top-1 error和Top-5上都超出了传统方法一大截。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fndtpbwzn9j30ke0bcabv.jpg" alt=""></p>
<p>Table 2就是模型ensemble的结果。Averaging the predictions of five similar CNNs gives an error rate of 16.4%。Averaging the predictions of two CNNs that were pre-trained on the entire Fall 2011 release with the aforementioned five CNNs gives an error rate of 15.3%</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fndtpewjn8j30te0egq6a.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classfication </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[VGGNet算法笔记]]></title>
      <url>/2018/01/18/VGGNet%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<p>论文：Very Deep Convolutional Networks for Large-Scale Image Recognition</p>
<p>论文链接：<a href="https://arxiv.org/abs/1409.1556" target="_blank" rel="external">https://arxiv.org/abs/1409.1556</a></p>
<p>这篇文章发表在ICLR 2015上,作者是Karen Simonyan和Andrew Zisserman，其算法获得了ImageNet ILSVRC-2014的localization task的冠军和classification task的第二名。文章通过堆叠$3\times 3$的卷积，ReLU, $2\times 2$的max pooling逐渐加深网络的深度。所以，它的特点就是连续的Conv运算比较多，计算量比较大(与AlexNet相比)，同时也提高了模型的感受野，能够提取更high-level的特征。VGGNet被提出以后被应用在各种任务中，例如物体分类，物体检测(object proposal生成)，语义分割，特征提取(image retrieval)等任务，都取得了非常好的效果。</p>
<p>Table 1是其VGG Net各个变种的网络结构参数，从左到右分别是A，A-LRN，B，C，D，E这6种，各个模型的深度分别是：11，11，13，16，16，19。可以发现，作者其实将整个网络分成两个部分，第一个部分是卷积层，第二个部分是全连接层，卷积层又分成了5个卷积组，卷积组的feature maps的深度从64逐渐增加到512，所以这5个卷积组的feature maps的深度分别是64，128，256，512，512，每个卷积组后面都会加一个$2\times 2$的non-overlapping的max pooling来降低feature maps的维度。</p>
<p>除此之外，为了 在不影响感受野的前提下，提高决策函数的非线性能力(increase the non-linearity of the decision function without affecting the receptive fields of the conv. layers)，作者还在结构C中加入了$1\times1$的卷积。$1\times1$的卷积也被应用到很多的网络结构中，例如Google Net，Network in Network等。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fndp5zk8eaj30t80qcaff.jpg" alt=""></p>
<p>以结构D为例，分析一下消耗的内存和模型的参数量：</p>
<table>
<thead>
<tr>
<th></th>
<th>内存</th>
<th>参数</th>
</tr>
</thead>
<tbody>
<tr>
<td>Input:$224\times 224\times3$</td>
<td>$224\times 224\times3=150k$</td>
<td>0</td>
</tr>
<tr>
<td>Conv3-64:$224\times 224\times64$</td>
<td>$224\times 224\times64=3.2M$</td>
<td>$3\times3\times3\times64=1728$</td>
</tr>
<tr>
<td>Conv3-64:$224\times 224\times64$</td>
<td>$224\times 224\times64=3.2M$</td>
<td>$3\times3\times64\times64=36864$</td>
</tr>
<tr>
<td>maxpool:$112\times112\times64$</td>
<td>$112\times112\times64=800K$</td>
<td>0</td>
</tr>
<tr>
<td>Conv3-128:$112\times112\times128$</td>
<td>$112\times112\times128=1.6M$</td>
<td>$3\times3\times64\times128=73728$</td>
</tr>
<tr>
<td>Conv3-128:$112\times112\times128$</td>
<td>$112\times112\times128=1.6M$</td>
<td>$3\times3\times128\times128=147456$</td>
</tr>
<tr>
<td>maxpool:$56\times56\times128$</td>
<td>$56\times56\times128=400K$</td>
<td>0</td>
</tr>
<tr>
<td>Conv3-256:$56\times56\times256$</td>
<td>$56\times56\times256=800K$</td>
<td>$3\times3\times128\times256=294912$</td>
</tr>
<tr>
<td>Conv3-256:$56\times56\times256$</td>
<td>$56\times56\times256=800K$</td>
<td>$3\times3\times256\times256=589824$</td>
</tr>
<tr>
<td>Conv3-256:$56\times56\times256$</td>
<td>$56\times56\times256=800K$</td>
<td>$3\times3\times256\times256=589824$</td>
</tr>
<tr>
<td>maxpool:$28\times28\times256$</td>
<td>$28\times28\times256=200K$</td>
<td>0</td>
</tr>
<tr>
<td>Conv3-512:$28\times28\times512$</td>
<td>$28\times28\times512=400K$</td>
<td>$3\times3\times256\times512=1179648$</td>
</tr>
<tr>
<td>Conv3-512:$28\times28\times512$</td>
<td>$28\times28\times512=400K$</td>
<td>$3\times3\times512\times512=2359296$</td>
</tr>
<tr>
<td>Conv3-512:$28\times28\times512$</td>
<td>$28\times28\times512=400K$</td>
<td>$3\times3\times512\times512=2359296$</td>
</tr>
<tr>
<td>maxpool:$14\times14\times512$</td>
<td>$14\times14\times512=100K$</td>
<td>0</td>
</tr>
<tr>
<td>Conv3-512:$14\times14\times512$</td>
<td>$14\times14\times512=100K$</td>
<td>$3\times3\times512\times512=2359296$</td>
</tr>
<tr>
<td>Conv3-512:$14\times14\times512$</td>
<td>$14\times14\times512=100K$</td>
<td>$3\times3\times512\times512=2359296$</td>
</tr>
<tr>
<td>Conv3-512:$14\times14\times512$</td>
<td>$14\times14\times512=100K$</td>
<td>$3\times3\times512\times512=2359296$</td>
</tr>
<tr>
<td>maxpool:$7\times7\times512$</td>
<td>$7\times7\times512=25K$</td>
<td>0</td>
</tr>
<tr>
<td>FC-4096 $1\times1\times4096$</td>
<td>4096</td>
<td>$25088\times4096=102760448$</td>
</tr>
<tr>
<td>FC-4096 $1\times1\times4096$</td>
<td>4096</td>
<td>$4096\times4096=102760448$</td>
</tr>
<tr>
<td>FC-1000 $1\times1\times1000$</td>
<td>1000</td>
<td>$4096\times1000=4096000$</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>各个模型的具体参数量可以见Table 2。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fndqy7970tj30jy030gm2.jpg" alt=""></p>
<p>除此之外，作者还解释了为什么不用$5\times5$和$7\times7$的卷积，是因为一个$5\times5$卷积的感受野和两个连续的 $3\times3$的卷积是相同的，一个$7\times7$的卷积的感受野等价于3个连续的$3\times3$的卷积，一个$7\times 7$的卷积需要$7^2C^2$的参数，而3个连续的$3\times3$卷积需要$3(3^2C^2)$,所以用$3\times3$卷积的意义在于保证感受野的同时，可以降低参数数量和增加模型深度来提高模型的非线性能力，模型容量(model capacity)和模型复杂度(model complexity)。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fnhm3fh4d0j30jg0swdkp.jpg" alt=""></p>
<p><strong>训练策略：</strong></p>
<p>训练的时候，作者先将图像scale到S（S大于等于224），然后再crop得到$224\times224$的图像。</p>
<p>In our experiments, we evaluated models trained at two fixed scales: S = 256 and S = 384. Given a ConvNet configuration, we first trained the network using S = 256. To speed-up training of the S = 384 network, it was initialised with the weights pre-trained with S = 256, and we used a smaller initial learning rate of $10^{−3}​$.</p>
<p><strong>实验结果：</strong></p>
<p>作者在ILSVRC-2012 dataset做了模型性能的评估。各个模型评估的结果见Table 3。我们可以发现从左到右随着深度的加深，模型的错误率逐渐降低，VGG 19的效果最好，取得了25.5%的 top-1 val error和8.0%的top-5 val. error。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fndqzo17l7j30qy0bstax.jpg" alt=""></p>
<p>作者也分析了各个图片尺度对结果的影响。作者对比了两个策略：单尺度策略和多尺度策略。单尺度策略是在训练集上选择尺寸S，测试集的大小为${S-32,S,S+32}$。而多尺度策略是选择尺度[$S_{min}$;$S_{max}$]，然后测试集的尺度为${S_{min},0.5(S_{min}+S_{max}),S_{max}}$，可以发现后者的效果会比前者更好一点。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fndqzqx423j30rs0aomz8.jpg" alt=""></p>
<p>训练的图像大小为S，测试的大小为Q。</p>
<p>dense就是用 fully-convolutional替代fully connected，这样就不需要将测试图像rescale到相同的尺度。multi-crop，顾名思义，就是sample多个crop来进行分类，在评估dense和multi-crop时(见Table 5)，发现这两者是可以互补的。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fndrhfe79qj30t607uq4q.jpg" alt=""></p>
<p>最后就是需要将各个模型进行融合，做最后的ensemble。通过将最后输出的softmax其平均，得到最后的概率分布。Table 6就是最终模型fusion的结果。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fndrhr8gxjj30um09u0uz.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> classifcation </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Comic Generation]]></title>
      <url>/2018/01/05/Comic-Generation/</url>
      <content type="html"><![CDATA[<p>最近写了一下李宏毅的MLDS 2017的<a href="https://www.csie.ntu.edu.tw/~yvchen/f106-adl/A4" target="_blank" rel="external">HW4-Comics Generation</a>，正好总结一下GAN以及assignment的做法。</p>
<h2 id="Basic-Idea-of-GAN"><a href="#Basic-Idea-of-GAN" class="headerlink" title="Basic Idea of GAN"></a>Basic Idea of GAN</h2><p>给定数据分布：$P_{data}(x)$</p>
<p>我们有一个分布$P_G(x;\theta)$</p>
<p>从$P_{data}(x)$采样m个样本${x_1,x_2,…x_m}$</p>
<p>我们的目的是找到这样的$\theta$使得分布$P_G(x;\theta)$尽可能的和$P_{data}(x)$接近</p>
<p>如果给定参数$\theta$，我们就可以计算产生这一对样本的似然：<br>$$<br>L=\prod_{i=1}^mP_G(x_i;\theta)<br>$$<br>然后找到$\theta^\ast$最大化似然L：<br>$$<br>\theta^\ast = arg \max_\theta\prod_{i=1}^mP_G(x_i;\theta)=arg\max_\theta\log\prod_{i=1}^mP_G(x_i;\theta) =arg\max_\theta\sum_{i=1}^m\log P_G(x_i;\theta) \ \approx arg\max_\theta E_{x\sim P_{data}}[\log P_G(x;\theta)]<br>$$<br>现在，我们可以用NN来模拟$P_G(x;\theta)$<br>$$<br>P_G(x) = \int_z P_{prior}(z) I_{[G(z)=x]}dz<br>$$<br>z服从unit gaussian，但是这样似然明显很难计算！</p>
<ul>
<li>Generator G<ul>
<li>G is a function, input z, output x</li>
<li>Given a prior distribution$ P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G</li>
</ul>
</li>
<li>Discriminator D<ul>
<li>D is a function, input x, output scalar</li>
<li>Evaluate the “difference” between $P_G(x)$ and $P_{data}(x)$</li>
</ul>
</li>
</ul>
<p>目的是找到最佳的G：<br>$$<br>G^\ast = arg\min_G\max_DV(G,D)<br>$$</p>
<p>$$<br>V= E_{x\sim P_{data}}[\log D(x)] + E_{x\sim P_G}[\log (1-D(x))]<br>$$</p>
<p>下面是将上述问题转化为：</p>
<p>首先最优的D：<br>$$<br>P_{data}(x)\log D(x) + P_G(x) \log (1-D(x))<br>$$</p>
<p>$$<br>f(D) = a\log(D) + b\log(1-D)<br>$$</p>
<p>求极值，得到：<br>$$<br>D^\ast(x) =\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}<br>$$<br>所以<br>$$<br>\max_DV(G,D) = V(G,D^*)=E_{x\sim P_{data}}[\log\frac{P_{data}(x)}{P_{data}(x)+P_G(x)}] + E_{x\sim P_G}[\log\frac{P_G(x)}{P_{data}(x)+P_G(x)}] \ = -2\log 2+E_{x\sim P_{data}}[\log\frac{P_{data}(x)}{(P_{data}(x)+P_G(x))/2}] + E_{x\sim P_G}[\log\frac{P_G(x)}{(P_{data}(x)+P_G(x))/2}] \ =-2\log 2 + KL(P_{data}(x)||\frac{P_{data}(x)+P_G(x)}{2}) + KL(P_{G}(x)||\frac{P_{data}(x)+P_G(x)}{2})<br>$$<br>将分母项 $P_{data}(x)+P_G(x)$ 除以2，那么整个式子就需要减去 $2\log\frac{1}{2}$ ，这就等价成了JS散度，定义了两个分布的相似性：</p>
<p>$$<br>JSD(P||Q) = \frac{1}{2}KL(P||M)+\frac{1}{2}KL(Q||M), M = \frac{1}{2}(P+Q)<br>$$</p>
<h3 id="一些tricks"><a href="#一些tricks" class="headerlink" title="一些tricks:"></a>一些tricks:</h3><p>有时候在训练的时候会碰到discriminator loss几乎一直是平的（0），这样就会让discriminator的作用变小（telling little information），也就意味着$P_{data}$和$P_{G}$几乎没有overlap，这是因为两者都是low dim manifold in high-dim space。</p>
<ul>
<li>add noise，增加两个分布的接触点或面，而且noise要随机事件decay。</li>
<li>​</li>
</ul>
<h3 id="Conditional-GAN"><a href="#Conditional-GAN" class="headerlink" title="Conditional GAN"></a>Conditional GAN</h3><p>z是噪声,y是条件，在初始的GAN加入了额外的条件y，y可以是任何形式的额外信息，包括类的属性等。</p>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fn60wm16qej30oe0ki40z.jpg" alt=""></p>
<h3 id="FGAN"><a href="#FGAN" class="headerlink" title="FGAN"></a>FGAN</h3><p>用f-divergence代替原始的KL divergence</p>
<p>f-divergence, f is convex:<br>$$<br>D_f(P||Q) = \int_xq(x)f(\frac{p(x)}{q(x)})dx<br>$$<br>例如：<br>$$<br>f(x) = x\log x \ f(x) = -\log x \ f(x) = (x-1)^2<br>$$</p>
<h4 id="Fenchel-Conjugate"><a href="#Fenchel-Conjugate" class="headerlink" title="Fenchel Conjugate"></a>Fenchel Conjugate</h4><p>$$<br>f^\ast(t) = \max_{x\in dom(f)}(xt-f(x))<br>$$</p>
<p>$$<br>f(x) = \max_{t\in dom(f^<em>)}{xt-f^\ast(t} \ D_f(P||Q) = \int_x q(x)(\max_{t\in dom(f^</em>)}{\frac{p(x)}{q(x)}t-f^\ast(t)}dx<br>$$</p>
<p>$$<br>D_f(P||Q) \ge \int_x q(x)(x\frac{p(x)}{q(x)}D(x)-f^\ast(D(x)))dx \ = \int_xp(x)D(x)dx-\int_x q(x)f^\ast(D(x))dx \ =\max_DE_{x_\sim P}(D(x))-E_{x\sim Q}f^\ast(D(x))<br>$$</p>
<p>D is a function whose input is x and output is t</p>
<p>这就相当于定义了一个新的V(G,D)</p>
<h3 id="LSGAN（Least-Squares-GANs）"><a href="#LSGAN（Least-Squares-GANs）" class="headerlink" title="LSGAN（Least Squares GANs）"></a>LSGAN（Least Squares GANs）</h3><p>使用最小二乘损失函数代替了GAN的损失函数,事实上，作者认为使用JS散度并不能拉近真实分布和生成分布之间的距离，使用最小二乘可以将图像的分布尽可能的接近决策边界<br>$$<br>\min_DV_{LSGAN}(D) = \frac{1}{2}E_{x\sim p_{data}(x)}[(D(x)-b)^2]+\frac{1}{2}E_{x\sim p_{z}(z)}[(D(G(z))-a)^2]<br>$$</p>
<p>$$<br>\min_GV_{LSGAN}(G)= \frac{1}{2}E_{x\sim p_{data}(x)}[(D(G(z))-c)^2]<br>$$</p>
<h3 id="infoGAN"><a href="#infoGAN" class="headerlink" title="infoGAN"></a>infoGAN</h3><p>$$<br>\min_{G,Q}\max_DV_{infoGAN}(D,G,Q) = V(D,G) - \lambda L_I(G,Q)<br>$$</p>
<p>其中，$L_1(G,Q)=E_{c\sim P(c),x\sim G(z,c)}[\log Q(c|x)]+H(c)$</p>
<p>也就是：<br>$$<br>L_{D,Q}=L_D^{GAN} - \lambda L_1(c,c’) \ L_{G} = L_G^{GAN} - \lambda L_1(c,c’)<br>$$</p>
<p>###WGAN</p>
<p>$$<br>L_D^{WGAN} = E[D(x)]-E[D(G(z))]<br>$$</p>
<p>$$<br>L_G^{WGAN} = E[D(G(Z))]<br>$$</p>
<p>$$<br>W_D\leftarrow clip_by_value(W_D, -0.01, 0.01)<br>$$</p>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> GAN </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CS224n assignment1]]></title>
      <url>/2017/12/18/CS224n-assignment1/</url>
      <content type="html"><![CDATA[<h2 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h2><p>(a) 证明softmax(x) = softmax(x+c), 这样就可以把c设为$\max(x)$来保证数值计算的稳定性</p>
<p>$$<br>softmax(x)_i = \frac{e^{x_i}}{\sum_je^{x_j}}<br>$$</p>
<p>$$<br>(softmax(x+c))_i = \frac{\exp(x_i+c)}{\sum_{j=1}\exp(x_j+c)}=\ \frac{\exp(x_i)\exp(c)}{\exp(c)\sum_{j=1}\exp(x_j)} = \frac{\exp(x_i)}{\sum_{j=1}\exp(x_j)}<br>$$</p>
<p>(b) 实现q1_softmax.py: </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="string">"""Compute the softmax function for each row of the input x.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    x -- A N dimensional vector or M x N dimensional numpy matrix.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">    x -- You are allowed to modify x in-place</span></div><div class="line"><span class="string">    """</span></div><div class="line">    orig_shape = x.shape</div><div class="line"></div><div class="line">    <span class="keyword">if</span> len(x.shape) &gt; <span class="number">1</span>:</div><div class="line">        <span class="comment"># Matrix</span></div><div class="line">        x -= np.max(x, axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</div><div class="line">        x = np.exp(x) / np.sum(np.exp(x), axis=<span class="number">1</span>, keepdims=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># Vector</span></div><div class="line">        x -= np.max(x)</div><div class="line">        x = np.exp(x) / np.sum(np.exp(x))</div><div class="line"></div><div class="line">    <span class="keyword">assert</span> x.shape == orig_shape</div><div class="line">    <span class="keyword">return</span> x</div></pre></td></tr></table></figure>
<h2 id="Neural-Network-Basics"><a href="#Neural-Network-Basics" class="headerlink" title="Neural Network Basics"></a>Neural Network Basics</h2><p>(a) 推导一下sigmoid函数的导数：<br>$$<br>\sigma(x) = \frac{1}{1+e^{-x}}<br>$$</p>
<p>$$<br>\sigma^\prime(x) = \sigma(x)(1 − \sigma(x))<br>$$</p>
<p>(b) 推导一下softmax函数的导数：<br>$$<br>CE(y,\hat{y}) = -\sum_i y_i \log(\hat{y}_i), \hat{y} = softmax(\theta)<br>$$<br>k是目标类<br><span>$$\frac{\partial CE(y,\hat{y})}{\partial \theta_i} =  \left\{
\begin{align} 
&amp;\hat{y_i} - 1,i=k \\ 
&amp;\hat{y_i}, otherwise
\end{align}
\right.$$</span><!-- Has MathJax --><br>等价于：</p>
<p>$$<br>\frac{\partial CE(y,\hat{y})}{\partial \theta} = \hat{y} -y<br>$$</p>
<p>(c) x是一层神经网络的输入，推导x的梯度也就是$\frac{\partial J}{\partial x}$, $J = CE(y, \hat{y})$，神经网络的隐藏层激活函数是$sigmoid$，而最后一层的是$softmax$</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-18%20%E4%B8%8B%E5%8D%8812.15.18.png" alt=""><br>$$<br>z1 = xW_1 + b_1, h = sigmoid(z_1), z_2=hW_2 + b_2, \hat{y} = softmax(z_2),<br>$$</p>
<p>$$<br>\frac{\partial J}{\partial x} = \frac{\partial J}{\partial z_2} \frac{\partial z_2}{\partial h}\frac{\partial h}{\partial z_1}\frac{\partial z_1}{\partial x}<br>$$</p>
<p>$$<br>\frac{\partial J}{\partial z_2} = \hat{y} -y<br>$$</p>
<p>$$<br>\frac{\partial z_2}{\partial h} = W_2<br>$$</p>
<p>$$<br>\frac{\partial h}{\partial z_1} = sigmoid(z_1) (1-sigmoid(z_1))<br>$$</p>
<p>$$<br>\frac{\partial z_1}{\partial x} = W_1<br>$$</p>
<p>(d) 上个网络的参数个数, 输入的维度是$D_x$,输出的维度是$D_y$, 隐藏层是H：<br>$$<br>D_x \cdot H + H + H \cdot D_y + D_y<br>$$<br>(e) 实现q2 sigmoid.py:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Compute the sigmoid function for the input here.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    x -- A scalar or numpy array.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">    s -- sigmoid(x)</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    s = <span class="number">1</span> / (<span class="number">1</span>+np.exp(-x))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> s</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_grad</span><span class="params">(s)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Compute the gradient for the sigmoid function here. Note that</span></div><div class="line"><span class="string">    for this implementation, the input s should be the sigmoid</span></div><div class="line"><span class="string">    function value of your original input x.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    s -- A scalar or numpy array.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">    ds -- Your computed gradient.</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    ds = s * (<span class="number">1</span>-s)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> ds</div></pre></td></tr></table></figure>
<p>(f) 实现梯度检查: q2 gradcheck.py<br>$$<br>\frac{\partial J(\theta)}{\partial \theta} = \lim_{\epsilon\rightarrow0}\frac{J(\theta+\epsilon)-J(\theta-\epsilon)}{2\epsilon}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradcheck_naive</span><span class="params">(f, x)</span>:</span></div><div class="line">    <span class="string">""" Gradient check for a function f.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    f -- a function that takes a single argument and outputs the</span></div><div class="line"><span class="string">         cost and its gradients</span></div><div class="line"><span class="string">    x -- the point (numpy array) to check the gradient at</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    rndstate = random.getstate()</div><div class="line">    random.setstate(rndstate)</div><div class="line">    fx, grad = f(x) <span class="comment"># Evaluate function value at original point</span></div><div class="line">    h = <span class="number">1e-4</span>        <span class="comment"># Do not change this!</span></div><div class="line"></div><div class="line">    <span class="comment"># Iterate over all indexes in x</span></div><div class="line">    it = np.nditer(x, flags=[<span class="string">'multi_index'</span>], op_flags=[<span class="string">'readwrite'</span>])</div><div class="line">    <span class="keyword">while</span> <span class="keyword">not</span> it.finished:</div><div class="line">        ix = it.multi_index</div><div class="line"></div><div class="line">        <span class="comment"># Try modifying x[ix] with h defined above to compute</span></div><div class="line">        <span class="comment"># numerical gradients. Make sure you call random.setstate(rndstate)</span></div><div class="line">        <span class="comment"># before calling f(x) each time. This will make it possible</span></div><div class="line">        <span class="comment"># to test cost functions with built in randomness later.</span></div><div class="line"></div><div class="line">        old_xix = x[ix]</div><div class="line">        x[ix] = old_xix + h</div><div class="line">        random.setstate(rndstate)</div><div class="line">        fp = f(x)[<span class="number">0</span>]</div><div class="line">        x[ix] = old_xix - h</div><div class="line">        random.setstate(rndstate)</div><div class="line">        fm = f(x)[<span class="number">0</span>]</div><div class="line">        x[ix] = old_xix</div><div class="line">        <span class="comment">#random.setstate(rndstate)</span></div><div class="line">        numgrad = (fp-fm) / (<span class="number">2</span>*h)</div><div class="line">        <span class="comment"># Compare gradients</span></div><div class="line">        reldiff = abs(numgrad - grad[ix]) / max(<span class="number">1</span>, abs(numgrad), abs(grad[ix]))</div><div class="line">        <span class="keyword">if</span> reldiff &gt; <span class="number">1e-5</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">"Gradient check failed."</span></div><div class="line">            <span class="keyword">print</span> <span class="string">"First gradient error found at index %s"</span> % str(ix)</div><div class="line">            <span class="keyword">print</span> <span class="string">"Your gradient: %f \t Numerical gradient: %f"</span> % (</div><div class="line">                grad[ix], numgrad)</div><div class="line">            <span class="keyword">return</span></div><div class="line"></div><div class="line">        it.iternext() <span class="comment"># Step to next dimension</span></div><div class="line"></div><div class="line">    <span class="keyword">print</span> <span class="string">"Gradient check passed!"</span></div></pre></td></tr></table></figure>
<p>(g) 实现: q2 neural.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward_backward_prop</span><span class="params">(data, labels, params, dimensions)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Forward and backward propagation for a two-layer sigmoidal network</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Compute the forward propagation and for the cross entropy cost,</span></div><div class="line"><span class="string">    and backward propagation for the gradients for all parameters.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    data -- M x Dx matrix, where each row is a training example.</span></div><div class="line"><span class="string">    labels -- M x Dy matrix, where each row is a one-hot vector.</span></div><div class="line"><span class="string">    params -- Model parameters, these are unpacked for you.</span></div><div class="line"><span class="string">    dimensions -- A tuple of input dimension, number of hidden units</span></div><div class="line"><span class="string">                  and output dimension</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    <span class="comment">### Unpack network parameters (do not modify)</span></div><div class="line">    ofs = <span class="number">0</span></div><div class="line">    Dx, H, Dy = (dimensions[<span class="number">0</span>], dimensions[<span class="number">1</span>], dimensions[<span class="number">2</span>])</div><div class="line"></div><div class="line">    W1 = np.reshape(params[ofs:ofs+ Dx * H], (Dx, H))</div><div class="line">    ofs += Dx * H</div><div class="line">    b1 = np.reshape(params[ofs:ofs + H], (<span class="number">1</span>, H))</div><div class="line">    ofs += H</div><div class="line">    W2 = np.reshape(params[ofs:ofs + H * Dy], (H, Dy))</div><div class="line">    ofs += H * Dy</div><div class="line">    b2 = np.reshape(params[ofs:ofs + Dy], (<span class="number">1</span>, Dy))</div><div class="line"></div><div class="line">    </div><div class="line">    z1 = np.dot(data, W1) + b1</div><div class="line">    h1 = sigmoid(z1)</div><div class="line">    z2 = np.dot(h1, W2) + b2</div><div class="line">    y = softmax(z2)</div><div class="line"></div><div class="line">    cost = -np.sum(labels * np.log(y))</div><div class="line"></div><div class="line">    gradz2 = y - labels</div><div class="line"></div><div class="line"></div><div class="line">    gradW2 = np.dot(h1.T, gradz2)</div><div class="line">    gradb2 = np.sum(gradz2, axis=<span class="number">0</span>).reshape((<span class="number">1</span>, Dy))</div><div class="line"></div><div class="line">    gradh1 = np.dot(gradz2, W2.T)</div><div class="line">    gradz1 = gradh1 * sigmoid_grad(h1)</div><div class="line"></div><div class="line">    gradW1 = np.dot(data.T, gradz1)</div><div class="line">    gradb1 = np.sum(gradz1, axis=<span class="number">0</span>).reshape((<span class="number">1</span>, H))</div><div class="line"></div><div class="line">    <span class="keyword">assert</span> gradW1.shape == W1.shape</div><div class="line">    <span class="keyword">assert</span> gradW2.shape == W2.shape</div><div class="line">    <span class="comment">### Stack gradients (do not modify)</span></div><div class="line">    grad = np.concatenate((gradW1.flatten(), gradb1.flatten(),</div><div class="line">        gradW2.flatten(), gradb2.flatten()))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> cost, grad</div></pre></td></tr></table></figure>
<h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><p>主要包括word embeeding中的两个模型： Skip-gram和CBOW</p>
<ol>
<li>skipgram:Predict context words given target (position independent)</li>
</ol>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-18%20%E4%B8%8B%E5%8D%883.47.29.png" alt=""></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fml280dpabj313q0to1kx.jpg" alt=""></p>
<ol>
<li>Predict target word from bag-of-words context</li>
</ol>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fml67e6yo4j30fa0cpdht.jpg" alt=""></p>
<p>(a) 求skipgram的关于$v_c$和$\mu_w$的梯度： </p>
<p>$$<br>\hat{y}_o= p(o|c)=\frac{\exp(\mu_o^T v_c)}{\sum_{w=1}^W\exp(\mu_w^T v_c)}<br>$$</p>
<p>o表示输出词的下标，c表示的是中心词的下标，$u_o$表示输出向量</p>
<p>预测的词向量$v_c$代表第c个中心词，$w$表示的是第w个词, i表示目标。<br>$$<br>J_{softmax-CE}(o,v_c, U) = CE(y, \hat{y}), U= [u_1,u_2,…,u_W]<br>$$</p>
<p>$$<br>\frac{\partial J}{\partial v_c} = -u_i + \sum_{w=1}^Wu_w\hat{y}_w = U(\hat{y}-y)<br>$$</p>
<span>$$\frac{\partial J}{\partial u_w} =  \left\{
\begin{align} 
&amp;(\hat{y_w} - 1)v_c,w=o \\ 
&amp;\hat{y_w}v_c, otherwise
\end{align}
\right.$$</span><!-- Has MathJax -->
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmaxCostAndGradient</span><span class="params">(predicted, target, outputVectors, dataset)</span>:</span></div><div class="line">    <span class="string">""" Softmax cost function for word2vec models</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    predicted -- numpy ndarray, predicted word vector (\hat&#123;v&#125; in</span></div><div class="line"><span class="string">                 the written component)</span></div><div class="line"><span class="string">    target -- integer, the index of the target word</span></div><div class="line"><span class="string">    outputVectors -- "output" vectors (as rows) for all tokens</span></div><div class="line"><span class="string">    dataset -- needed for negative sampling, unused here.   </span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">    cost -- cross entropy cost for the softmax word prediction</span></div><div class="line"><span class="string">    gradPred -- the gradient with respect to the predicted word</span></div><div class="line"><span class="string">           vector</span></div><div class="line"><span class="string">    grad -- the gradient with respect to all the other word</span></div><div class="line"><span class="string">           vectors</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line">    out = np.dot(outputVectors, predicted)</div><div class="line">    score = out[target]</div><div class="line">    exp_sum = np.sum(np.exp(out))</div><div class="line">    cost = np.log(exp_sum) - score</div><div class="line">    margin = np.exp(out) / np.sum(np.exp(out))</div><div class="line">    margin[target] -= <span class="number">1</span> </div><div class="line">    gradPred = np.dot(margin.T, outputVectors)</div><div class="line">    grad = np.dot(margin, predicted.T)</div><div class="line">    <span class="keyword">return</span> cost, gradPred, grad</div></pre></td></tr></table></figure>
<p>(b) negative sampling:  更新全词表的代价有点大，从而负采样K个，更新。$v_c$是预测的词向量，$o$是期望输出词<br>$$<br>J_{neg-sample}(o,v_c,U) = -\log(\sigma(u_o^Tv_c)) - \sum_{k=1}^K \log(\sigma(-u_k^Tv_c))<br>$$</p>
<p>$$<br>\frac{\partial J}{\partial v_c} =(\sigma(u_o^Tv_c)-1)u_o-\sum_{k=1}^K(\sigma(-u_k^Tv_c)-1)u_k<br>$$</p>
<p>$$<br>\frac{\partial J}{\partial u_o} =(\sigma(u_o^Tv_c)-1)v_c<br>$$</p>
<p>$$<br>\frac{\partial J}{\partial u_k} =-(\sigma(-u_k^Tv_c)-1)v_c, k = 1,2,…,K<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNegativeSamples</span><span class="params">(target, dataset, K)</span>:</span></div><div class="line">    <span class="string">""" Samples K indexes which are not the target """</span></div><div class="line"></div><div class="line">    indices = [<span class="keyword">None</span>] * K</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> xrange(K):</div><div class="line">        newidx = dataset.sampleTokenIdx()</div><div class="line">        <span class="keyword">while</span> newidx == target:</div><div class="line">            newidx = dataset.sampleTokenIdx()</div><div class="line">        indices[k] = newidx</div><div class="line">    <span class="keyword">return</span> indices</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">negSamplingCostAndGradient</span><span class="params">(predicted, target, outputVectors, dataset,</span></span></div><div class="line"><span class="function"><span class="params">                               K=<span class="number">10</span>)</span>:</span></div><div class="line">    <span class="string">""" Negative sampling cost function for word2vec models</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Implement the cost and gradients for one predicted word vector</span></div><div class="line"><span class="string">    and one target word vector as a building block for word2vec</span></div><div class="line"><span class="string">    models, using the negative sampling technique. K is the sample</span></div><div class="line"><span class="string">    size.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Note: See test_word2vec below for dataset's initialization.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments/Return Specifications: same as softmaxCostAndGradient</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    <span class="comment"># Sampling of indices is done for you. Do not modify this if you</span></div><div class="line">    <span class="comment"># wish to match the autograder and receive points!</span></div><div class="line">    indices = [target]</div><div class="line">    indices.extend(getNegativeSamples(target, dataset, K))</div><div class="line"></div><div class="line">    labels = -np.ones((K+<span class="number">1</span>,))</div><div class="line">    labels[<span class="number">0</span>] = <span class="number">1</span></div><div class="line"></div><div class="line">    out = np.dot(outputVectors[indices], predicted) * labels</div><div class="line">    </div><div class="line">    scores = sigmoid(out)</div><div class="line">    cost = -np.sum(np.log(scores))</div><div class="line"></div><div class="line">    d = labels * (scores<span class="number">-1</span>)</div><div class="line">    gradPred = np.dot(d.reshape((<span class="number">1</span>, <span class="number">-1</span>)), outputVectors[indices]).flatten()</div><div class="line">    gradtemp = np.dot(d.reshape((<span class="number">-1</span>, <span class="number">1</span>)), predicted.reshape((<span class="number">1</span>,<span class="number">-1</span>)))</div><div class="line">    grad = np.zeros_like(outputVectors)</div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(K+<span class="number">1</span>):</div><div class="line">        grad[indices[k]] += gradtemp[k,:]</div><div class="line">    <span class="keyword">return</span> cost, gradPred, grad</div></pre></td></tr></table></figure>
<p>(c) 推导skip gram和CBOW的梯度：</p>
<p>给定一系列的上下文单词$[word_{c-m},…,word_{c-1},word_c,word_{c+1},…,word_{c+m}]$</p>
<p>输入词向量为$v_k$,输出词向量为$u_k$, $\hat{v}=v_c$</p>
<p>这里， skip gram的cost函数为：<br>$$<br>J_{skip_gram}(word_{c-m…c+m}) = \sum_{-m\le j\le m, j\ne0} F(w_{c+j}, v_c)<br>$$</p>
<p>$$<br>\frac{\partial J_{skip_gram}(word_{c-m…c+m})}{\partial U} =\sum_{-m\le j\le m, j\ne0} \frac{\partial F(w_{c+j}, v_c)}{\partial U}<br>$$</p>
<p>$$<br>\frac{\partial J_{skip_gram}(word_{c-m…c+m})}{\partial v_c} =\sum_{-m\le j\le m, j\ne0} \frac{\partial F(w_{c+j}, v_c)}{\partial v_c}<br>$$</p>
<p>$$<br>\frac{\partial J_{skip_gram}(word_{c-m…c+m})}{\partial v_j} =0, j \ne c<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">skipgram</span><span class="params">(currentWord, C, contextWords, tokens, inputVectors, outputVectors,</span></span></div><div class="line"><span class="function"><span class="params">             dataset, word2vecCostAndGradient=softmaxCostAndGradient)</span>:</span></div><div class="line">    <span class="string">""" Skip-gram model in word2vec</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    currrentWord -- a string of the current center word</span></div><div class="line"><span class="string">    C -- integer, context size</span></div><div class="line"><span class="string">    contextWords -- list of no more than 2*C strings, the context words</span></div><div class="line"><span class="string">    tokens -- a dictionary that maps words to their indices in</span></div><div class="line"><span class="string">              the word vector list</span></div><div class="line"><span class="string">    inputVectors -- "input" word vectors (as rows) for all tokens</span></div><div class="line"><span class="string">    outputVectors -- "output" word vectors (as rows) for all tokens</span></div><div class="line"><span class="string">    word2vecCostAndGradient -- the cost and gradient function for</span></div><div class="line"><span class="string">                               a prediction vector given the target</span></div><div class="line"><span class="string">                               word vectors, could be one of the two</span></div><div class="line"><span class="string">                               cost functions you implemented above.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Return:</span></div><div class="line"><span class="string">    cost -- the cost function value for the skip-gram model</span></div><div class="line"><span class="string">    grad -- the gradient with respect to the word vectors</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    cost = <span class="number">0.0</span></div><div class="line">    gradIn = np.zeros(inputVectors.shape)</div><div class="line">    gradOut = np.zeros(outputVectors.shape)</div><div class="line"></div><div class="line">    </div><div class="line">    center = tokens[currentWord]</div><div class="line">    predicted = inputVectors[center]</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> target_word <span class="keyword">in</span> contextWords:</div><div class="line">        target = tokens[target_word]</div><div class="line">        cost_i, gradPred, grad = word2vecCostAndGradient(predicted, target, outputVectors, dataset)</div><div class="line">        cost += cost_i</div><div class="line">        gradIn[center] += gradPred</div><div class="line">        gradOut += grad</div><div class="line"></div><div class="line">    <span class="keyword">return</span> cost, gradIn, gradOut</div></pre></td></tr></table></figure>
<p>而CBOW有点不同，首先：<br>$$<br>\hat{v} = \sum_{-m\le j\le m, j\ne0} v_{c+j}<br>$$<br>它的cost函数为：<br>$$<br>J_{CBOW}(word_{c-m…c+m})=F(w_c, \hat{v})<br>$$</p>
<p>$$<br>\frac{\partial J_{CBOW}(word_{c-m…c+m})}{\partial U} = \frac{\partial F(w_c, v_c)}{\partial U}<br>$$</p>
<p>$$<br>\frac{\partial J_{CBOW}(word_{c-m…c+m})}{\partial v_j} = \frac{\partial F(w_c, v_c)}{\partial \hat{v}}, j\in{c-m,…,c-1,c+1,…,c+m}<br>$$</p>
<p>$$<br>\frac{\partial J_{CBOW}(word_{c-m…c+m})}{\partial v_j} =0, j\notin{c-m,…,c-1,c+1,…,c+m}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cbow</span><span class="params">(currentWord, C, contextWords, tokens, inputVectors, outputVectors,</span></span></div><div class="line"><span class="function"><span class="params">         dataset, word2vecCostAndGradient=softmaxCostAndGradient)</span>:</span></div><div class="line">    <span class="string">"""CBOW model in word2vec</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Implement the continuous bag-of-words model in this function.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Arguments/Return specifications: same as the skip-gram model</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    cost = <span class="number">0.0</span></div><div class="line">    gradIn = np.zeros(inputVectors.shape)</div><div class="line">    gradOut = np.zeros(outputVectors.shape)</div><div class="line"></div><div class="line">    </div><div class="line">    target = tokens[currentWord]</div><div class="line">    target_vec = inputVectors[target]</div><div class="line">    source_idx = map(<span class="keyword">lambda</span> x: tokens[x], contextWords)</div><div class="line">    predicted = np.sum(inputVectors[source_idx], axis=<span class="number">0</span>)</div><div class="line"></div><div class="line">    cost, gradPred, gradOut = word2vecCostAndGradient(predicted, target, outputVectors, dataset)</div><div class="line"></div><div class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> source_idx:</div><div class="line">        gradIn[idx] += gradPred</div><div class="line"></div><div class="line">    <span class="keyword">return</span> cost, gradIn, gradOut</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> algorithms </category>
            
        </categories>
        
        
        <tags>
            
            <tag> notes </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Network Architecture of Deblurring]]></title>
      <url>/2017/12/09/Network-Architecture-of-Deblurring/</url>
      <content type="html"><![CDATA[<p>Wieschollek P, Hirsch M, Schölkopf B, et al. Learning Blind Motion Deblurring. arXiv preprint arXiv:1708.04208, 2017. <a href="https://github.com/cgtuebingen/learning-blind-motion-deblurring" target="_blank" rel="external">Codes</a>, <a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Wieschollek_Learning_Blind_Motion_ICCV_2017_paper.pdf" target="_blank" rel="external">Paper</a></p>
<p>这篇文章主要是针对视频的去噪，利用前几帧的信息来帮助预测当前帧，用到一些常用的skip-connection的结构来结合low-level and high resolution的feature map。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-09%20%E4%B8%8B%E5%8D%885.07.49.png" alt=""></p>
<p>Wang L, Li Y, Wang S. DeepDeblur: Fast one-step blurry face images restoration. arXiv preprint arXiv:1711.09515, 2017.</p>
<p>这篇文章主要针对的是人脸的运动噪声去模糊，其中kernel是人工模拟的，利用高斯过程生成，网络结构的话就是利用多个inception module和resnet的结构。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-09%20%E4%B8%8B%E5%8D%885.15.21.png" alt=""></p>
<p>Kupyn O, Budzan V, Mykhailych M, et al. DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks. arXiv preprint arXiv:1711.07064, 2017. </p>
<p>这篇文章的结构比较接单，就是利用多个ResBlocks来作为generater，然后在discriminator loss中加入critic loss（用Wasserstein GAN）和perceptual loss(features dissimilarity)。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-09%20%E4%B8%8B%E5%8D%885.18.01.png" alt=""></p>
<p>Noroozi M, Chandramouli P, Favaro P. Motion Deblurring in the Wild. arXiv preprint arXiv:1701.01486, 2017. </p>
<p>主要利用了mutli-scale和skip-connection</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-09%20%E4%B8%8B%E5%8D%885.57.08.png" alt=""></p>
<p>Nah S, Kim T H, Lee K M. Deep multi-scale convolutional neural network for dynamic scene deblurring. arXiv preprint arXiv:1612.02177, 2016. </p>
<p>这篇文章主要用到了一些残差学习的方法，不仅用了ResBlock，还将小尺度的结果作为残差传给大尺度，简化学习的难度。</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-12-09%20%E4%B8%8B%E5%8D%886.00.27.png" alt=""></p>
]]></content>
      
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> summary </tag>
            
            <tag> computer vision </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Generate Motion Blur]]></title>
      <url>/2017/12/05/Generate-Motion-Blur/</url>
      <content type="html"><![CDATA[<p>本文主要介绍几种常用的人工合成运动噪声的方法：</p>
<p>###基于spline平滑的方法</p>
<p>在一个$n\times n$大小的矩阵内，随机采样6个点，再用三阶的spline平滑拟合，这样采样得到若干个在矩阵内的整数点，这些整数点上的值，再用高斯采样得到，然后就是归一化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_kernel_spline</span><span class="params">(steps, n_samples)</span>:</span></div><div class="line"></div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> xrange(n_samples):</div><div class="line">		psz = <span class="number">24</span>  <span class="comment">##矩阵大小</span></div><div class="line">		kern = np.zeros((psz, psz))</div><div class="line">		x = np.random.randint(<span class="number">1</span>, psz+<span class="number">1</span>, (steps,))</div><div class="line">		y = np.random.randint(<span class="number">1</span>, psz+<span class="number">1</span>, (steps,))</div><div class="line">		</div><div class="line">		x = interpolate.spline(xk=np.linspace(<span class="number">0</span>, <span class="number">1</span>, steps), yk=x, xnew=np.linspace(<span class="number">0</span>, <span class="number">1</span>, steps*<span class="number">5000</span>))</div><div class="line">		y = interpolate.spline(xk=np.linspace(<span class="number">0</span>, <span class="number">1</span>, steps), yk=y, xnew=np.linspace(<span class="number">0</span>, <span class="number">1</span>, steps*<span class="number">5000</span>))</div><div class="line"></div><div class="line"></div><div class="line">		x = np.round(np.maximum(<span class="number">1</span>, np.minimum(psz, x)))</div><div class="line"></div><div class="line">		y = np.round(np.maximum(<span class="number">1</span>, np.minimum(psz, y)))</div><div class="line"></div><div class="line">		idxs = (x<span class="number">-1</span>) * psz + y</div><div class="line"></div><div class="line">		idxs = np.unique(idxs).astype(int)</div><div class="line"></div><div class="line">		wt = np.maximum(<span class="number">0</span>, np.random.randn(idxs.shape[<span class="number">0</span>],) * <span class="number">0.5</span> + <span class="number">1</span>)</div><div class="line">		<span class="keyword">if</span> np.sum(wt) == <span class="number">0</span>:</div><div class="line">			<span class="keyword">continue</span></div><div class="line">		wt /= np.sum(wt)</div><div class="line">		<span class="keyword">for</span> i, idx <span class="keyword">in</span> enumerate(idxs):</div><div class="line">			x = idx % psz</div><div class="line">			y = idx / psz</div><div class="line">			kern[x, y] = wt[i]</div></pre></td></tr></table></figure>
<h3 id="基于高斯过程的方法"><a href="#基于高斯过程的方法" class="headerlink" title="基于高斯过程的方法"></a>基于高斯过程的方法</h3><blockquote>
<p>In <a href="https://en.wikipedia.org/wiki/Probability_theory" target="_blank" rel="external">probability theory</a> and <a href="https://en.wikipedia.org/wiki/Statistics" target="_blank" rel="external">statistics</a>, a <strong>Gaussian process</strong> is a particular kind of statistical model where <a href="https://en.wikipedia.org/wiki/Random_variate" target="_blank" rel="external">observations</a> occur in a continuous domain, e.g. time or space. In a Gaussian process, every point in some continuous input space is associated with a <a href="https://en.wikipedia.org/wiki/Normal_distribution" target="_blank" rel="external">normally distributed</a> <a href="https://en.wikipedia.org/wiki/Random_variable" target="_blank" rel="external">random variable</a>. Moreover, every finite collection of those random variables has a <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution" target="_blank" rel="external">multivariate normal distribution</a>, i.e. every finite <a href="https://en.wikipedia.org/wiki/Linear_combination" target="_blank" rel="external">linear combination</a> of them is normally distributed. The distribution of a Gaussian process is the <a href="https://en.wikipedia.org/wiki/Joint_distribution" target="_blank" rel="external">joint distribution</a> of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.</p>
</blockquote>
<p>高斯过程其实就是多元高斯分布的无限维度扩展，我们通过观察无限维度的数据的子集（这些子集也服从多元高斯分布），然后构造函数来对数据进行建模。</p>
<p>例如，我们需要测量一年中每天中午的温度（温度明显是一个有连续空间的变量），这里GP就是一个函数f, 输入${x_n}_{n=1}^{365}$, $f(x_n)$就是每天温度的预测值。 GP函数主要包含两部分： mean function, $m(x)$和kernel function, $k(x, x^\prime)$。</p>
<p>我们需要对x坐标和y坐标进行采样：<br>$$<br>f_x(t), f_y(t) \sim GP(0, k(t, t’)), k(t,t’) = \sigma_f^2(1+\frac{\sqrt(5)|t-t’|}{l}+\frac{5(t-t’)^2}{3l^2})\exp(-\frac{\sqrt 5|t-t’|}{l})<br>$$<br>这里，$l=0.3$, $\sigma_f=0.25$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">kernel</span><span class="params">(x1, x2)</span>:</span></div><div class="line">	sigma_f = <span class="number">1.</span>/<span class="number">4</span></div><div class="line">	l = <span class="number">0.3</span></div><div class="line">	delta = np.abs(x1-x2)</div><div class="line">	<span class="keyword">return</span> sigma_f * sigma_f * (<span class="number">1</span>+np.sqrt(<span class="number">5</span>)*delta/l + <span class="number">5</span> * delta*delta/(<span class="number">3</span>*l*l)) * np.exp(-np.sqrt(<span class="number">5</span>)*delta/l)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span><span class="params">(xs)</span>:</span></div><div class="line">	<span class="keyword">return</span> [[kernel(x1, x2) <span class="keyword">for</span> x2 <span class="keyword">in</span> xs] <span class="keyword">for</span> x1 <span class="keyword">in</span> xs]</div></pre></td></tr></table></figure>
]]></content>
      
        
        <tags>
            
            <tag> summary </tag>
            
            <tag> computer vision </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Introduction to Capsule Network]]></title>
      <url>/2017/11/24/capsule/</url>
      <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1710.09829" target="_blank" rel="external">Dynamic Routing Between Capsules</a></p>
<p>这是Hinton发表在NIPS2017的一篇文章，提出了capsule的概念。</p>
<p>其实可以把capsule看成是neuron的一个特殊形式，neuron的输出是一个scalar，而capsule则会输出vector。除此之外，neuron可以detect到一个特定的pattern，但是这又存在很大的局限性，会有pattern冗余，例如：</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-24%20%E4%B8%8B%E5%8D%883.11.12.png" alt=""></p>
<p>所以capsule输出vector就可以避免这样的情况，输出特征v的每个维度表示的是对应pattern的特性，以上图为例，可能某个表示鸟嘴方向的维度，分别对应1和-1。</p>
<p>再以人脸为例，传统的CNN可能可以detect到眼睛的pattern, 嘴巴的pattern等，只能表示它的存在，但是无法表示五官的属性，例如相对位置，大小，相对角度等等。而向量的大小表示的是整个pattern的概率，或者可以叫做confidence, 例如下图：</p>
<p><img src="https://jhui.github.io/assets/capsule/face4.jpg" alt=""><img src="https://jhui.github.io/assets/capsule/face5.jpg" alt=""></p>
<p>具体的计算过程见下图：</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-24%20%E4%B8%8B%E5%8D%883.15.27.png" alt=""></p>
<p>$$<br>u^1=W^1V^1, u^2=W^2v^2 \ s=c_1u^1 \ v=Squash(s) , v = \frac{|s|}{1+|s|^2}\frac{s}{|s|}<br>$$<br>接下来就是核心，dynamic routing:</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-24%20%E4%B8%8B%E5%8D%883.51.30.png" alt=""></p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-24%20%E4%B8%8B%E5%8D%883.24.52.png" alt=""></p>
<p>和传统CNN简单粗暴的max pooling不同的是它动态地调整routing的系数，系数是在testing的时候online地决定的，调整的方法就是通过T次迭代，根据aggrement，其实就是提高越相关的v的系数。 上图中，如果$a^r$和$u^i$相关性较强的话，就可以得到更大的$b_i$。</p>
<p>也可以将dynamic routing的过程看成是一个不断排除outlier的一个过程，例如现在$u^1$,$u^2$很接近，而$u^3$与他们差距很大，他们两个队最终的$a^r$贡献很大，那么随着不断迭代，$u^3$就被消除了。</p>
]]></content>
      
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> notes </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Fixing  Weight Decay Regularization in Adam]]></title>
      <url>/2017/11/21/FIXING-WEIGHT-DECAY-REGULARIZATION-IN-ADAM/</url>
      <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/1711.05101.pdf" target="_blank" rel="external">文章的链接</a></p>
<p>首先，文章理清了l2正则和weight decay的区别，它们并不是对等的。 weight decay可以表示成:</p>
<p>$$<br>x_{t+1} = (1-w_t)x_{t}-\alpha_t\nabla f_t(x_t)<br>$$</p>
<p>而l2正则的表示是：</p>
<p>$$<br>f_{t,reg(x_t)} = f_t(x_t)+ \frac{w_t}{2} |x_t|_2^2<br>$$</p>
<p>所以：</p>
<p>$$<br>\nabla f_{t,reg(x_t)} = \nabla f_t(x_t)+w_tx_t<br>$$</p>
<p>注意到weight decay的系数只有$w_t$，那么，在大部分框架中，例如tensorflow, keras, pytorch等把weight decay和l2正则等价了，</p>
<p>我们切换到SGD Mometum中来：因求完梯度以后，需要累加mometum，在$x_t$前面就存在了三个参数：$\alpha$学习率,$w_t$,$\eta_t$平滑系数。那么就和weight decay不对等了，当然可以把这三者乘积看成一个系数，但是这样还是削弱了原本的weight decay（系数变小了）。</p>
<p>因此，作者把传统的SGD with momentum做了以下修改：</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-21%20%E4%B8%8B%E5%8D%887.17.09.png" alt=""></p>
<p>简单总结一下： 就是除了在梯度计算中加入weight decay，在mometum也加入了weight decay。这样就增强了weight decay的作用。</p>
<p>除了对SGD with Mometum有影响，作者还对Adam进行了修改：</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-21%20%E4%B8%8B%E5%8D%887.26.39.png" alt=""></p>
<p>看一下Adam的公式：</p>
<p>$$x_t = x_{t-1} - \eta_t\alpha \frac{\beta_1m_{t-1}+(1-\beta_1)g_t}{\sqrt{\beta_2v_{t-1}+(1-\beta_2)g_t^2+\epsilon}}$$</p>
<p>with $g_t=\nabla f_t(x_{t-1})+w_tx_{t-1}$</p>
<p>这里可以看到$g_t$被归一化了，同时$w_t$也带着被归一化了，这样$w_t$就被减弱了。</p>
<p>实验结果：</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-21%20%E4%B8%8B%E5%8D%887.38.45.png" alt=""></p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-21%20%E4%B8%8B%E5%8D%887.38.53.png" alt=""></p>
<p>横纵坐标分别是不同的weight decay和learning rate的组合, 可以看到learning rate和weight decay的相关性很大，固定weight decay，去调整learning rate，那么效果会变化较大，从图中看到，明显作者提出的算法，最有区域较大，更利于找出最优的参数组合。</p>
]]></content>
      
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> paper notes </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Dual Path Networks]]></title>
      <url>/2017/11/14/Networks/</url>
      <content type="html"><![CDATA[<p>This paper propose a novel deep CNN architecture called <strong>Dual Path Networks(DPN)</strong>. This idea is  based on the fact that the ResNet enables feature re-usage while DenseNet enable new features exploration which are both important for learning good feature representation.  </p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/image.png" alt=""></p>
<blockquote>
<p>Basically, the ResNet and DenseNet differ in the way of “wiring”. ResNet provides a path with which a layer can get access to both the output and the input of the immediately previous layer. The DenseNet provides a path that can access the outputs of multiple previous layers. </p>
</blockquote>
<p><img src="http://ovshqtujw.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-14%20%E4%B8%8B%E5%8D%886.25.45.png" alt="Architecture comparison of different networks"></p>
<p>The DPN balance ResNet and DenseNet in a tricky way, and can be formulated as:<br>$$<br>x^k = \sum_{t=1}^{k-1} f_t^k (h^t),\ y^k = \sum_{t=1}^{k-1} v_t(h^t) = y^{k-1} +\phi^{k-1}(y^{k-1}),\\r^k=x^k+y^k,\\h^k=g^k(r^k)<br>$$<br>where $x_k$ and $y_k$ denote the extracted information at k-th step from individual path, $v_t(\cdot)$is a feature learning function as $f_k^t(\cdot)$, $\phi_k(\cdot) = f_k(g_k(\cdot))$.  The dual path means the left side is ResNet, the right side is DenseNet. The block parameters are shared between them. The outputs of two sides will be concated as next block’s input.</p>
<p>This is the implementation of dual path block</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">DualPathBlock</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_chs, num_1x1_a, num_3x3_b, num_1x1_c, inc, G, _type=<span class="string">'normal'</span>)</span>:</span></div><div class="line">        super(DualPathBlock, self).__init__()</div><div class="line">        self.num_1x1_c = num_1x1_c</div><div class="line"></div><div class="line">        <span class="keyword">if</span> _type <span class="keyword">is</span> <span class="string">'proj'</span>:</div><div class="line">            key_stride = <span class="number">1</span></div><div class="line">            self.has_proj = <span class="keyword">True</span></div><div class="line">        <span class="keyword">if</span> _type <span class="keyword">is</span> <span class="string">'down'</span>:</div><div class="line">            key_stride = <span class="number">2</span></div><div class="line">            self.has_proj = <span class="keyword">True</span></div><div class="line">        <span class="keyword">if</span> _type <span class="keyword">is</span> <span class="string">'normal'</span>:</div><div class="line">            key_stride = <span class="number">1</span></div><div class="line">            self.has_proj = <span class="keyword">False</span></div><div class="line"></div><div class="line">        <span class="keyword">if</span> self.has_proj:</div><div class="line">            self.c1x1_w = self.BN_ReLU_Conv(in_chs=in_chs, out_chs=num_1x1_c+<span class="number">2</span>*inc, kernel_size=<span class="number">1</span>, stride=key_stride)</div><div class="line"></div><div class="line">        self.layers = nn.Sequential(OrderedDict([</div><div class="line">            (<span class="string">'c1x1_a'</span>, self.BN_ReLU_Conv(in_chs=in_chs, out_chs=num_1x1_a, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>)),</div><div class="line">            (<span class="string">'c3x3_b'</span>, self.BN_ReLU_Conv(in_chs=num_1x1_a, out_chs=num_3x3_b, kernel_size=<span class="number">3</span>, stride=key_stride, padding=<span class="number">1</span>, groups=G)),</div><div class="line">            (<span class="string">'c1x1_c'</span>, self.BN_ReLU_Conv(in_chs=num_3x3_b, out_chs=num_1x1_c+inc, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>)),</div><div class="line">        ]))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">BN_ReLU_Conv</span><span class="params">(self, in_chs, out_chs, kernel_size, stride, padding=<span class="number">0</span>, groups=<span class="number">1</span>)</span>:</span></div><div class="line">        <span class="keyword">return</span> nn.Sequential(OrderedDict([</div><div class="line">            (<span class="string">'norm'</span>, nn.BatchNorm2d(in_chs)),</div><div class="line">            (<span class="string">'relu'</span>, nn.ReLU(inplace=<span class="keyword">True</span>)),</div><div class="line">            (<span class="string">'conv'</span>, nn.Conv2d(in_chs, out_chs, kernel_size, stride, padding, groups=groups, bias=<span class="keyword">False</span>)),</div><div class="line">        ]))</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        data_in = torch.cat(x, dim=<span class="number">1</span>) <span class="keyword">if</span> isinstance(x, list) <span class="keyword">else</span> x</div><div class="line">        <span class="keyword">if</span> self.has_proj:</div><div class="line">            data_o = self.c1x1_w(data_in)</div><div class="line">            data_o1 = data_o[:,:self.num_1x1_c,:,:]</div><div class="line">            data_o2 = data_o[:,self.num_1x1_c:,:,:]</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            data_o1 = x[<span class="number">0</span>]</div><div class="line">            data_o2 = x[<span class="number">1</span>]</div><div class="line"></div><div class="line">        out = self.layers(data_in)</div><div class="line"></div><div class="line">        summ = data_o1 + out[:,:self.num_1x1_c,:,:]</div><div class="line">        dense = torch.cat([data_o2, out[:,self.num_1x1_c:,:,:]], dim=<span class="number">1</span>)</div><div class="line">        <span class="keyword">return</span> [summ, dense]</div></pre></td></tr></table></figure>
]]></content>
      
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> paper notes </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Meet in the middle的一些实例]]></title>
      <url>/2017/11/12/meet-in-the-middle%E7%9A%84%E4%B8%80%E4%BA%9B%E5%AE%9E%E4%BE%8B/</url>
      <content type="html"><![CDATA[<p>Meet in the Middle是在搜索问题经常会用到的一个技巧，其核心思想就是解决一个A&lt;-&gt;B的问题，分别从A端和B端出发，向对方进发，当他们在中点相遇的时候，就找到了A&lt;-&gt;B的一个解。</p>
<h3 id="先看一道简单题："><a href="#先看一道简单题：" class="headerlink" title="先看一道简单题："></a>先看一道简单题：</h3><p><a href="http://codeforces.com/contest/888/problem/E" target="_blank" rel="external">CF888E Maximum Subsequence</a></p>
<p>You are given an array <em>a</em> consisting of <em>n</em> integers, and additionally an integer <em>m</em>. You have to choose some sequence of indices $b_1, b_2, …, b_k (1 \le b_1 \lt b_2 \lt … \lt b_k\le n)$ in such a way that the value of <img src="http://codeforces.com/predownloaded/db/28/db283c0794aac433c817bad7534d99cc6287207c.png" alt="img"> is maximized. Chosen sequence can be empty.</p>
<p>Print the maximum possible value of <img src="http://codeforces.com/predownloaded/db/28/db283c0794aac433c817bad7534d99cc6287207c.png" alt="img">.</p>
<p><strong>Input</strong></p>
<p>The first line contains two integers <em>n</em> and <em>m</em> ($1 \le n\le 35$, $1 \le m \le 10^9$).</p>
<p>The second line contains <em>n</em> integers $a_1, a_2, …, a_n$ ($1 \le a_i \le10^9$).</p>
<p><strong>Output</strong></p>
<p>Print the maximum possible value of <img src="http://codeforces.com/predownloaded/db/28/db283c0794aac433c817bad7534d99cc6287207c.png" alt="img">.</p>
<p>题目意思很简单，就是从一个大小为n的数组中挑选k个，使他们的和对m求余最大。</p>
<p>如果直接枚举a的所有子集，大小为$2^{35}$， 明显会超时。</p>
<p>如果利用meet in the middle的思路： 先枚举左边17，右边17，再让他们meet in the middle，然后利用求余的性质，左边和右边的和都小于m，进行排序，二分即可： $L_i+R_i \lt m$   or  $ m \lt L_i + R_i \lt 2*m$</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxn = <span class="number">40</span>;</div><div class="line"></div><div class="line"><span class="keyword">int</span> a[maxn];</div><div class="line"></div><div class="line"><span class="keyword">int</span> L[<span class="number">1</span>&lt;&lt;<span class="number">18</span>], R[<span class="number">1</span>&lt;&lt;<span class="number">18</span>];</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line"></div><div class="line">	<span class="comment">//freopen("in", "r", stdin);</span></div><div class="line">	<span class="keyword">int</span> n, m;</div><div class="line">	<span class="built_in">cin</span> &gt;&gt; n &gt;&gt; m;</div><div class="line"></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">		<span class="built_in">cin</span> &gt;&gt; a[i];</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">int</span> ans = <span class="number">0</span>;</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> mask = <span class="number">0</span>; mask &lt; (<span class="number">1</span>&lt;&lt;<span class="number">18</span>); mask++) &#123;</div><div class="line">		<span class="keyword">int</span> res = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">18</span>; j++) &#123;</div><div class="line">			<span class="keyword">if</span> ((mask &gt;&gt; j) &amp; <span class="number">1</span>) &#123;</div><div class="line">				res = (res+a[j]) % m;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		L[mask] = res;</div><div class="line">		ans = max(ans, res);</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">if</span> (n &lt;= <span class="number">18</span>) &#123;</div><div class="line">		<span class="built_in">cout</span> &lt;&lt; ans &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">		<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> mask = <span class="number">0</span>; mask &lt; (<span class="number">1</span>&lt;&lt;(n<span class="number">-18</span>)); mask++) &#123;</div><div class="line">		<span class="keyword">int</span> res = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">18</span>; j &lt; n; j++) &#123;</div><div class="line">			<span class="keyword">if</span> ((mask &gt;&gt; (j<span class="number">-18</span>)) &amp; <span class="number">1</span>) &#123;</div><div class="line">				res = (res+a[j]) % m;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		R[mask] = res;</div><div class="line">		ans = max(ans, res);</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="keyword">int</span> Lsz = (<span class="number">1</span>&lt;&lt;<span class="number">18</span>);</div><div class="line">	<span class="keyword">int</span> Rsz = (<span class="number">1</span>&lt;&lt;(n<span class="number">-18</span>));</div><div class="line">	sort(R, R+Rsz);</div><div class="line"></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; Lsz; i++) &#123;</div><div class="line">		<span class="keyword">int</span> res = L[i];</div><div class="line">		<span class="keyword">int</span> *t1 = upper_bound(R, R+Rsz, m<span class="number">-1</span>-res);</div><div class="line">		<span class="keyword">if</span> (t1 != R) &#123;</div><div class="line">			t1--;</div><div class="line">			ans = max(ans, (res+(*t1))%m);</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">int</span> *t2 = upper_bound(R, R+Rsz, <span class="number">2</span>*m<span class="number">-1</span>-res);</div><div class="line">		<span class="keyword">if</span> (t2 != R) &#123;</div><div class="line">			t2--;</div><div class="line">			ans = max(ans, (res+(*t2))%m);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; ans &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="进阶一点"><a href="#进阶一点" class="headerlink" title="进阶一点"></a>进阶一点</h3><p><a href="https://community.topcoder.com/stat?c=problem_statement&amp;pm=11644&amp;rd=14548" target="_blank" rel="external">topcoder srm 523 AlphabetPath</a></p>
<p><strong>Problem Statement</strong></p>
<p>The original Latin alphabet contained the following 21 letters: </p>
<p>A B C D E F Z H I K L M N O P Q R S T V X</p>
<p>You are given a 2-dimensional matrix of characters represented by the String[] letterMaze. The i-th character of the j-th element of letterMaze will represent the character at row i and column j. The matrix will contain each of the 21 letters at least once. It may also contain empty cells marked as ‘.’ (quotes for clarity).</p>
<p>A path is a sequence of matrix elements such that the second element is (horizontally or vertically) adjacent to the first one, the third element is adjacent to the second one, and so on. No element may be repeated on a path. A Latin alphabet path is a path consisting of exactly 21 elements, each containing a different letter of the Latin alphabet. The letters are not required to be in any particular order.</p>
<p>Return the total number of Latin alphabet paths in the matrix described by letterMaze.</p>
<p>题目意思就是给定一个$R\times C$的矩阵，格子里要么是空，要么包含0~20的整数，长度为21的路径，每个整数恰出现一次， $R,C\le 21$</p>
<p>那么，我们枚举middle点，这样有$R\times C$种选择，假设Middle点为x，从Middle点出发DFS10步，令$S(P)$为不包含Middle点的10个格子的数值的集合。那么$S(P_1)\cup S(P_2)….\cup {x}$ = {0,1…20},那么整个时间复杂度就变成了$O(RC\times 4 \times 3^9)$</p>
<h3 id="密码学中的应用"><a href="#密码学中的应用" class="headerlink" title="密码学中的应用"></a>密码学中的应用</h3><h4 id="DES"><a href="#DES" class="headerlink" title="DES"></a>DES</h4><p>首先介绍一下DES（Data Encryption Standard），DES是一种分组的对称加密技术，具体见下图（coursera crypto stanford笔记）：</p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/WechatIMG11.jpeg" alt="DES"></p>
<p>那么如何attack DES呢？</p>
<p>Lemma: Suppose that DES is an ideal cipher ($2^{56}$ random invertible functions, key是56位)</p>
<p>为什么不能用double DES呢？因为我们可以用meet in the middle attack来攻击：</p>
<p>对于double DES来说：</p>
<ol>
<li>我们需要找到这样的$k_1$和$k_2$：$E(k_1, E(k_2, M))=C$,这和$E(k_2, M) = D(k_1, C)$一个意思</li>
<li>首先，我们用表M记录$k_2$和$C^\prime=DES(k_2, M)$的所有值，时间复杂度为$O(2^{56})$</li>
<li>然后我们就可以暴力枚举$k_1$，计算$C^{\prime\prime} =DES^{-1}(k_1, C)$, 看是否有对应的值在表中</li>
<li>这样attack的时间复杂度就变成了$O(2^{56}+2^{56}) \lt O(2^{63})$ ,这比期望的$2^{112}$要小很多，以及空间复杂度为$O(2^{56})$。</li>
</ol>
<p>而换成3DES就没有这样的问题了！</p>
<p>$C = E(K_3, D(K_2, E(K_1,P) ) ) $</p>
]]></content>
      
        
        <tags>
            
            <tag> algorithms </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[GatedRNN]]></title>
      <url>/2017/11/12/GatedRNN/</url>
      <content type="html"><![CDATA[<h2 id="Gated-RNN"><a href="#Gated-RNN" class="headerlink" title="Gated RNN"></a>Gated RNN</h2><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>$$<br>h^\prime, y = f(h, x), h^\prime = \sigma(W^hh + W^i x), y = \sigma(W^oh^\prime)<br>$$</p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-12%20%E4%B8%8B%E5%8D%881.11.44.png" alt="RNN"></p>
<p>下面是RNN的实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_forward</span><span class="params">(x, prev_h, Wx, Wh, b)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Run the forward pass for a single timestep of a vanilla RNN that uses a tanh</span></div><div class="line"><span class="string">  activation function.</span></div><div class="line"><span class="string">  The input data has dimension D, the hidden state has dimension H, and we use</span></div><div class="line"><span class="string">  a minibatch size of N.</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - x: Input data for this timestep, of shape (N, D).</span></div><div class="line"><span class="string">  - prev_h: Hidden state from previous timestep, of shape (N, H)</span></div><div class="line"><span class="string">  - Wx: Weight matrix for input-to-hidden connections, of shape (D, H)</span></div><div class="line"><span class="string">  - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H)</span></div><div class="line"><span class="string">  - b: Biases of shape (H,)</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - next_h: Next hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - cache: Tuple of values needed for the backward pass.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  next_h = np.tanh(x.dot(Wx)+prev_h.dot(Wh)+b)</div><div class="line">  cache = (next_h,x,prev_h,Wx,Wh)</div><div class="line">  <span class="keyword">return</span> next_h, cache</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_step_backward</span><span class="params">(dnext_h, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Backward pass for a single timestep of a vanilla RNN.</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - dnext_h: Gradient of loss with respect to next hidden state</span></div><div class="line"><span class="string">  - cache: Cache object from the forward pass</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - dx: Gradients of input data, of shape (N, D)</span></div><div class="line"><span class="string">  - dprev_h: Gradients of previous hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - dWx: Gradients of input-to-hidden weights, of shape (D, H)</span></div><div class="line"><span class="string">  - dWh: Gradients of hidden-to-hidden weights, of shape (H, H)</span></div><div class="line"><span class="string">  - db: Gradients of bias vector, of shape (H,)</span></div><div class="line"><span class="string">  """</span></div><div class="line">  dx, dprev_h, dWx, dWh, db = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line">  next_h,x,prev_h,Wx,Wh = cache</div><div class="line">  dout = dnext_h*(<span class="number">1</span>-next_h**<span class="number">2</span>)</div><div class="line">  db = np.sum(dout,axis=<span class="number">0</span>)</div><div class="line">  dx = dout.dot(Wx.T)</div><div class="line">  dprev_h = dout.dot(Wh.T)</div><div class="line">  dWx = np.dot(x.T,dout)</div><div class="line">  dWh = np.dot(prev_h.T,dout)</div><div class="line">  <span class="keyword">return</span> dx, dprev_h, dWx, dWh, db</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_forward</span><span class="params">(x, h0, Wx, Wh, b)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Run a vanilla RNN forward on an entire sequence of data. We assume an input</span></div><div class="line"><span class="string">  sequence composed of T vectors, each of dimension D. The RNN uses a hidden</span></div><div class="line"><span class="string">  size of H, and we work over a minibatch containing N sequences. After running</span></div><div class="line"><span class="string">  the RNN forward, we return the hidden states for all timesteps.</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - x: Input data for the entire timeseries, of shape (N, T, D).</span></div><div class="line"><span class="string">  - h0: Initial hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - Wx: Weight matrix for input-to-hidden connections, of shape (D, H)</span></div><div class="line"><span class="string">  - Wh: Weight matrix for hidden-to-hidden connections, of shape (H, H)</span></div><div class="line"><span class="string">  - b: Biases of shape (H,)</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - h: Hidden states for the entire timeseries, of shape (N, T, H).</span></div><div class="line"><span class="string">  - cache: Values needed in the backward pass</span></div><div class="line"><span class="string">  """</span></div><div class="line">  h, cache = <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line">  N,T,D = x.shape</div><div class="line">  N,H = h0.shape</div><div class="line">  cache = []</div><div class="line">  prev_h = h0</div><div class="line">  h = np.zeros((N,T,H))</div><div class="line">  <span class="keyword">for</span> t <span class="keyword">in</span> xrange(T):</div><div class="line">    prev_h,cache_n = rnn_step_forward(x[:,t,:],prev_h,Wx,Wh,b)</div><div class="line">    cache.append(cache_n)</div><div class="line">    h[:,t,:] = prev_h</div><div class="line">  <span class="keyword">return</span> h, cache</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_backward</span><span class="params">(dh, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Compute the backward pass for a vanilla RNN over an entire sequence of data.</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - dh: Upstream gradients of all hidden states, of shape (N, T, H)</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - dx: Gradient of inputs, of shape (N, T, D)</span></div><div class="line"><span class="string">  - dh0: Gradient of initial hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - dWx: Gradient of input-to-hidden weights, of shape (D, H)</span></div><div class="line"><span class="string">  - dWh: Gradient of hidden-to-hidden</span></div><div class="line"><span class="string">  - db: Gradient of biases, of shape (H,)</span></div><div class="line"><span class="string">  """</span></div><div class="line">  dx, dh0, dWx, dWh, db = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line"></div><div class="line">  N,T,H = dh.shape</div><div class="line">  N,D = cache[<span class="number">0</span>][<span class="number">1</span>].shape</div><div class="line">  dx = np.zeros((N,T,D))</div><div class="line">  dWx = np.zeros((D,H))</div><div class="line">  dWh = np.zeros((H,H))</div><div class="line">  db = np.zeros((H,))</div><div class="line">  dprev_h = np.zeros((N,H))</div><div class="line">  <span class="keyword">for</span> t <span class="keyword">in</span> reversed(xrange(T)):</div><div class="line">    dx[:,t,:],dprev_h, dWx_n, dWh_n, db_n = rnn_step_backward(dprev_h+dh[:,t,:],cache[t])</div><div class="line">    dWh += dWh_n</div><div class="line">    dWx += dWx_n</div><div class="line">    db += db_n</div><div class="line">  dh0 = dprev_h</div><div class="line">  <span class="keyword">return</span> dx, dh0, dWx, dWh, db</div></pre></td></tr></table></figure>
<h3 id="Deep-RNN"><a href="#Deep-RNN" class="headerlink" title="Deep RNN"></a>Deep RNN</h3><p>$$<br>h^\prime, y = f_1(h,x) \ b^\prime, c = f_2(b, y) \ ….<br>$$</p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-12%20%E4%B8%8B%E5%8D%881.13.12.png" alt="Deep RNN"></p>
<h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p>$$<br>h^\prime, a = f_1(h, x), b^\prime, c= f_2(b, x), y = f_3(a, c)<br>$$</p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-12%20%E4%B8%8B%E5%8D%881.15.10.png" alt="双向RNN"></p>
<h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>$$<br>z^i = \tanh(W^ix^t+W^ih^{t-1})\\<br>z^f=\tanh(W^fx^t+W^fh^{t-1})\\<br>z^o=\tanh(W^0x^t+W^oh^{t-1})\\<br>$$</p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-12%20%E4%B8%8B%E5%8D%881.18.36.png" alt="LSTM"></p>
<p>对比分析：</p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-12%20%E4%B8%8B%E5%8D%881.23.59.png" alt="LSTM对比"></p>
<p>最左边的是标准的LSTM， 左边第二个是GRU， </p>
<p>可以看出： 没有output gate，forget gate, input gate, input activation function, output activation function都会对结果变差。forget gate和关于$c^t$的$\tanh$激活函数对性能影响较大。</p>
<p>下面是LSTM的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_forward</span><span class="params">(x, prev_h, prev_c, Wx, Wh, b)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Forward pass for a single timestep of an LSTM.</span></div><div class="line"><span class="string">  The input data has dimension D, the hidden state has dimension H, and we use</span></div><div class="line"><span class="string">  a minibatch size of N.</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - x: Input data, of shape (N, D)</span></div><div class="line"><span class="string">  - prev_h: Previous hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - prev_c: previous cell state, of shape (N, H)</span></div><div class="line"><span class="string">  - Wx: Input-to-hidden weights, of shape (D, 4H)</span></div><div class="line"><span class="string">  - Wh: Hidden-to-hidden weights, of shape (H, 4H)</span></div><div class="line"><span class="string">  - b: Biases, of shape (4H,)</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - next_h: Next hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - next_c: Next cell state, of shape (N, H)</span></div><div class="line"><span class="string">  - cache: Tuple of values needed for backward pass.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  next_h, next_c, cache = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line">  <span class="comment">#############################################################################</span></div><div class="line">  <span class="comment"># <span class="doctag">TODO:</span> Implement the forward pass for a single timestep of an LSTM.        #</span></div><div class="line">  <span class="comment"># You may want to use the numerically stable sigmoid implementation above.  #</span></div><div class="line">  <span class="comment">#############################################################################</span></div><div class="line">  a = x.dot(Wx)+prev_h.dot(Wh)+b</div><div class="line">  N,H = prev_h.shape</div><div class="line">  i = sigmoid(a[:,:H])</div><div class="line">  f = sigmoid(a[:,H:<span class="number">2</span>*H])</div><div class="line">  o = sigmoid(a[:,<span class="number">2</span>*H:<span class="number">3</span>*H])</div><div class="line">  g = np.tanh(a[:,<span class="number">3</span>*H:])</div><div class="line"></div><div class="line">  next_c = f*prev_c + i*g</div><div class="line">  next_h = o*np.tanh(next_c)</div><div class="line">  cache = (x,i,f,o,g,next_c,next_h,Wx,Wh,b,a,prev_c,prev_h)</div><div class="line"></div><div class="line"></div><div class="line">  <span class="keyword">return</span> next_h, next_c, cache</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_step_backward</span><span class="params">(dnext_h, dnext_c, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Backward pass foLSTM: forward</span></div><div class="line"><span class="string">  - dnext_h: Gradients of next hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - dnext_c: Gradients of next cell state, of shape (N, H)</span></div><div class="line"><span class="string">  - cache: Values from the forward pass</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - dx: Gradient of input data, of shape (N, D)</span></div><div class="line"><span class="string">  - dprev_h: Gradient of previous hidden state, of shape (N, H)</span></div><div class="line"><span class="string">  - dprev_c: Gradient of previous cell state, of shape (N, H)</span></div><div class="line"><span class="string">  - dWx: Gradient of input-to-hidden weights, of shape (D, 4H)</span></div><div class="line"><span class="string">  - dWh: Gradient of hidden-to-hidden weights, of shape (H, 4H)</span></div><div class="line"><span class="string">  - db: Gradient of biases, of shape (4H,)</span></div><div class="line"><span class="string">  """</span></div><div class="line">  dx, dprev_h, dprev_c, dWx, dWh, db = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line"></div><div class="line">  (x,i,f,o,g,next_c,next_h,Wx,Wh,b,a,prev_c,prev_h) = cache</div><div class="line">  (N,H) = dnext_h.shape</div><div class="line">  (N,D) = x.shape</div><div class="line"></div><div class="line"></div><div class="line">  dx = np.zeros(x.shape)</div><div class="line">  dprev_c = np.zeros(prev_c.shape)</div><div class="line">  dprev_h = np.zeros(prev_h.shape)</div><div class="line">  dWx = np.zeros(Wx.shape)</div><div class="line">  dWh = np.zeros(Wh.shape)</div><div class="line">  db = np.zeros(b.shape)</div><div class="line"></div><div class="line"></div><div class="line">  di = dnext_c*g</div><div class="line">  df = dnext_c*prev_c</div><div class="line">  do = dnext_h*np.tanh(next_c)</div><div class="line">  dg = dnext_c*i</div><div class="line"></div><div class="line">  da = np.zeros(a.shape)</div><div class="line"></div><div class="line">  da[:,:H] = di*i*(<span class="number">1</span>-i) <span class="comment">#i</span></div><div class="line">  da[:,H:<span class="number">2</span>*H] = df*f*(<span class="number">1</span>-f) <span class="comment">#f</span></div><div class="line">  da[:,<span class="number">2</span>*H:<span class="number">3</span>*H] = do*o*(<span class="number">1</span>-o) <span class="comment">#o</span></div><div class="line">  da[:,<span class="number">3</span>*H:] = dg*(<span class="number">1</span>-g**<span class="number">2</span>) <span class="comment">#g</span></div><div class="line"></div><div class="line">  dprev_h = np.dot(da,Wh.T)</div><div class="line">  dWx = np.dot(x.T,da)</div><div class="line">  dWh = np.dot(prev_h.T,da)</div><div class="line">  db = np.sum(da,axis=<span class="number">0</span>)</div><div class="line">  dprev_c = dnext_c*f</div><div class="line">  dx = np.dot(da,Wx.T)</div><div class="line"></div><div class="line">  <span class="keyword">return</span> dx, dprev_h, dprev_c, dWx, dWh, db</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_forward</span><span class="params">(x, h0, Wx, Wh, b)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Forward pass for an LSTM over an entire sequence of data. We assume an input</span></div><div class="line"><span class="string">  sequence composed of T vectors, each of dimension D. The LSTM uses a hidden</span></div><div class="line"><span class="string">  size of H, and we work over a minibatch containing N sequences. After running</span></div><div class="line"><span class="string">  the LSTM forward, we return the hidden states for all timesteps.</span></div><div class="line"><span class="string">  Note that the initial cell state is passed as input, but the initial cell</span></div><div class="line"><span class="string">  state is set to zero. Also note that the cell state is not returned; it is</span></div><div class="line"><span class="string">  an internal variable to the LSTM and is not accessed from outside.</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - x: Input data of shape (N, T, D)</span></div><div class="line"><span class="string">  - h0: Initial hidden state of shape (N, H)</span></div><div class="line"><span class="string">  - Wx: Weights for input-to-hidden connections, of shape (D, 4H)</span></div><div class="line"><span class="string">  - Wh: Weights for hidden-to-hidden connections, of shape (H, 4H)</span></div><div class="line"><span class="string">  - b: Biases of shape (4H,)</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - h: Hidden states for all timesteps of all sequences, of shape (N, T, H)</span></div><div class="line"><span class="string">  - cache: Values needed for the backward pass.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  h, cache = <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line"></div><div class="line">  (N,T,D) = x.shape</div><div class="line">  (N,H) = h0.shape</div><div class="line">  h = np.zeros((N,T,H))</div><div class="line">  cache = []</div><div class="line">  prev_c = np.zeros((N,H))</div><div class="line">  prev_h = h0</div><div class="line">  <span class="keyword">for</span> t <span class="keyword">in</span> xrange(T):</div><div class="line">      prev_h,prev_c,cache_n = lstm_step_forward(x[:,t,:],prev_h,prev_c,Wx,Wh,b)</div><div class="line">      cache.append(cache_n)</div><div class="line">      h[:,t,:] = prev_h</div><div class="line"></div><div class="line"></div><div class="line">  <span class="keyword">return</span> h, cache</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">lstm_backward</span><span class="params">(dh, cache)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Backward pass for an LSTM over an entire sequence of data.]</span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - dh: Upstream gradients of hidden states, of shape (N, T, H)</span></div><div class="line"><span class="string">  - cache: Values from the forward pass</span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - dx: Gradient of input data of shape (N, T, D)</span></div><div class="line"><span class="string">  - dh0: Gradient of initial hidden state of shape (N, H)</span></div><div class="line"><span class="string">  - dWx: Gradient of input-to-hidden weight matrix of shape (D, 4H)</span></div><div class="line"><span class="string">  - dWh: Gradient of hidden-to-hidden weight matrix of shape (H, 4H)</span></div><div class="line"><span class="string">  - db: Gradient of biases, of shape (4H,)</span></div><div class="line"><span class="string">  """</span></div><div class="line">  dx, dh0, dWx, dWh, db = <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span>, <span class="keyword">None</span></div><div class="line"></div><div class="line">  (N,D) = cache[<span class="number">0</span>][<span class="number">0</span>].shape</div><div class="line">  (N,T,H) = dh.shape</div><div class="line"></div><div class="line">  dprev_c = np.zeros((N,H))</div><div class="line">  dx = np.zeros((N,T,D))</div><div class="line">  dh0 = np.zeros((N,H))</div><div class="line">  dWx = np.zeros((D,<span class="number">4</span>*H))</div><div class="line">  dWh = np.zeros((H,<span class="number">4</span>*H))</div><div class="line">  db= np.zeros((<span class="number">4</span>*H,))</div><div class="line">  dprev_h = np.zeros((N,H))</div><div class="line"></div><div class="line">  <span class="keyword">for</span> t <span class="keyword">in</span> reversed(xrange(T)):</div><div class="line">      dx_n, dprev_h, dprev_c, dWx_n, dWh_n, db_n = lstm_step_backward(dh[:,t,:]+dprev_h,dprev_c,cache[t])</div><div class="line">      dWx += dWx_n</div><div class="line">      dWh_n += dWh_n</div><div class="line">      db += db_n</div><div class="line">      dx[:,t,:] = dx_n</div><div class="line"></div><div class="line">  <span class="keyword">return</span> dx, dh0, dWx, dWh, db</div></pre></td></tr></table></figure>
<p>###GRU</p>
<p>z在GRU充当的是LSTM里面forget gate和input gate一样的作用，将两者耦合在一起。</p>
<p><img src="http://ovshqtujw.bkt.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-12%20%E4%B8%8B%E5%8D%881.19.17.png" alt="GRU"></p>
]]></content>
      
        
        <tags>
            
            <tag> RNN </tag>
            
            <tag> Deep Learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mixup-Beyond Empirical Risk Minimization]]></title>
      <url>/2017/11/01/mixup/</url>
      <content type="html"><![CDATA[<p><strong>Gist</strong>: The authors propose a new training strategy  dubbed <strong>mixup</strong> that trains a neural network on convex combinations of pairs of examples and their labels and improves the generalization of state-of-the-art neural network architectures.    </p>
<p>​    </p>
<p><strong>Pytorch Code</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> (x1, y1), (x2, y2) <span class="keyword">in</span> zip(loader1, loader2): </div><div class="line">  	lam = numpy.random.beta(alpha, alpha)</div><div class="line">	x = Variable(lam * x1 + (<span class="number">1.</span> - lam) * x2)</div><div class="line">	y = Variable(lam * y1 + (<span class="number">1.</span> - lam) * y2) optimizer.zero_grad()</div><div class="line">    loss(net(x), y).backward()</div><div class="line">    optimizer.step()</div></pre></td></tr></table></figure>
<p><strong>Empirical Risk Minimization</strong></p>
<p>We need to minimize the <strong>expected risk</strong>, that is the average of the loss function $l$ over the data distribution $P$</p>
<p>$$R(f ) = \int l(f (x), y)dP (x, y)$$</p>
<p>$l$ is the loss function, $P(x,y)$ is a joint data distribution, $f\in F$ is a function that describes the relationship between a random vector X and a random target vector Y .</p>
<p>Unsually, the distribution of P is unknown. In most pracitical situation, we may approximate $P$ by the <strong><em>empirical distribution</em></strong>, though it is easy to compute, it ofen leads to the undesirable behaviour of $f$ outside the training data.</p>
<p>$$P_\sigma(x,y)=\frac{1}{n}\sum_{i=1}^{n}\sigma(x=x_i, y=y_i)$$</p>
<p>where $\sigma(x = x_i, y = y_i)$ is a Dirac mass centered at $(x_i, y_i)$</p>
<p>$$R_\sigma(f) = \frac{1}{n}\sum_{i=1}^nl(f(x_i), y_i)$$</p>
<p><strong>Vicinal Risk Minimization</strong></p>
<p>$$P_v (\widetilde{x}, \widetilde{y})=\frac{1}{n}\sum_{i=1}^nv(\widetilde{x}, \widetilde{y}|x_i,y_i)$$<br>where $v(\widetilde{x}, \widetilde{y}|x_i,y_i)$ is  a vicinity distribution that measures the probability of finding the virtual feature-target pair $(\widetilde{x}, \widetilde{y})$ in the vicinity of the training feature-target pair $(x_i,y_i)$</p>
<p>This paper propose a generic vicinal distribution, <strong><em>mixup</em></strong>:</p>
<p>$$\mu(\widetilde{x}, \widetilde{y}|x_i,y_i)=\frac{1}{n}\sum_j^n\mathbb{E}_\lambda[\sigma(\widetilde{x}=\lambda \cdot x_i+(1-\lambda)\cdot x_j,\widetilde{y} =\lambda \cdot y_i + (1-\lambda) \cdot y_j)]$$<br>where $\lambda \sim Beta(\alpha, \alpha)$ , for $\alpha \in (0, \infty)$Sampling from the mixup vicinal distribution:<br>$$\widetilde{x} = \lambda \cdot x_i + (1 − \lambda)\cdot x_j$$<br>$$\widetilde{y} = \lambda \cdot y_i + (1 − \lambda)\cdot y_j$$</p>
]]></content>
      
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> paper notes </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Single Shot Scale-invariant Face Detector]]></title>
      <url>/2017/11/01/Single-Shot-Scale-invariant-Face-Detector/</url>
      <content type="html"><![CDATA[<p>The authors propose to tile anchors on a wide range of layers to ensure that all scales of faces have enough features for detection. Besides, they try to improve the recall rate of small faces by a scale compensation anchor matching strategy. Max-out background label is used to reduce the false positive rate of small faces.</p>
<p>Key points:</p>
<ul>
<li>VGG net (throgh Pool5 layer) and some extra convolutional layers</li>
<li>Anchor  is 1:1 aspect ratio (face annotation)</li>
<li>two stages to improve the anchor matching strategy<ul>
<li>stage one: decrese the jaccord overlap threshold from 0.5 to 0.35</li>
<li>stage two: decrese the threshold to 0.1 and sort to select the top-N</li>
</ul>
</li>
<li>max-out operation is performed on the background label scores</li>
</ul>
<p>model architecture:</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-01%20%E4%B8%8B%E5%8D%887.46.53.png" alt=""></p>
]]></content>
      
        
        <tags>
            
            <tag> paper notes </tag>
            
            <tag> face detection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[A List of Saliency Detection Papers]]></title>
      <url>/2017/10/20/A-List-of-Saliency-Detection-Papers/</url>
      <content type="html"><![CDATA[<ol>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/A%20Deep%20Spatial%20Contextual%20Long-term%20Recurrent%20Convolutional%20Network%20for%20Saliency%20Detection.pdf" target="_blank" rel="external">A Deep Spatial Contextual Long-term Recurrent Convolutional Network for Saliency Detection</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/A%20Fast%20and%20Compact%20Saliency%20Score%20Regression%20Network%20Based%20on%20Fully%20Convolutional%20Network.pdf" target="_blank" rel="external">A Fast and Compact Saliency Score Regression Network Based on Fully Convolutional Network</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Amulet.pdf" target="_blank" rel="external">Amulet</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/DHSNet:%20Deep%20Hierarchical%20Saliency%20Network%20for%20Salient%20Object%20Detection%20.pdf" target="_blank" rel="external">DHSNet: Deep Hierarchical Saliency Network for Salient Object Detection</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Group-wise%20Deep%20Co-saliency%20Detection.pdf" target="_blank" rel="external">Group-wise Deep Co-saliency Detection</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Large-Scale%20Optimization%20of%20Hierarchical%20Features%20for%20Saliency%20Prediction%20in%20Natural%20Images.pdf" target="_blank" rel="external">Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Learning%20Uncertain%20Convolutional%20Features%20for%20Accurate%20Saliency%20Detection.pdf" target="_blank" rel="external">Learning Uncertain Convolutional Features for Accurate Saliency Detection</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/PiCANet.pdf" target="_blank" rel="external">PiCANet</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Recurrent%20Attentional%20Networks%20for%20Saliency%20Detection.pdf" target="_blank" rel="external">Recurrent Attentional Networks for Saliency Detection</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/SalGAN:%20Visual%20Saliency%20Prediction%20with%20Generative%20Adversarial%20Networks.pdf" target="_blank" rel="external">SalGAN: Visual Saliency Prediction with Generative Adversarial Networks</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Saliency%20Detection%20by%20Forward%20and%20Backward%20Cues%20in%20Deep-CNNs.pdf" target="_blank" rel="external">Saliency Detection by Forward and Backward Cues in Deep-CNNs</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Saliency%20Detection%20by%20Multi-Context%20Deep%20Learning.pdf" target="_blank" rel="external">Saliency Detection by Multi-Context Deep Learning.pdf</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Shallow%20and%20Deep%20Convolutional%20Networks%20for%20Saliency%20Prediction.pdf" target="_blank" rel="external">Shallow and Deep Convolutional Networks for Saliency Prediction</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Supervised%20Adversarial%20Networks%20for%20Image%20Saliency%20Detection.pdf" target="_blank" rel="external">Supervised Adversarial Networks for Image Saliency Detection</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Two-Stream%20Convolutional%20Networks%20for%20Dynamic%20Saliency%20Prediction.pdf" target="_blank" rel="external">Two-Stream Convolutional Networks for Dynamic Saliency Prediction</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Visual%20Saliency%20Detection%20Based%20on%20Multiscale%20Deep%20CNN%20Features.pdf" target="_blank" rel="external">Visual Saliency Detection Based on Multiscale Deep CNN Features</a></li>
<li><a href="http://7xkgro.com1.z0.glb.clouddn.com/Visual%20Saliency%20Prediction%20Using%20a%20Mixture%20of%20Deep%20Neural%20Networks.pdf" target="_blank" rel="external">Visual Saliency Prediction Using a Mixture of Deep Neural Networks</a></li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> paper </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[图个新鲜]]></title>
      <url>/2017/09/05/%E5%9B%BE%E4%B8%AA%E6%96%B0%E9%B2%9C/</url>
      <content type="html"><![CDATA[<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/2017-09-05%2017-15-19%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE.png" alt=""></p>
]]></content>
      
        
        <tags>
            
            <tag> 杂 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Overview of Object Detection]]></title>
      <url>/2017/09/05/overview-of-object-detection/</url>
      <content type="html"><![CDATA[<h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><p>主要有三个步骤：</p>
<ol>
<li>用selective search提取可能的objects<ol>
<li>使用<a href="http://cs.brown.edu/~pff/segment/" target="_blank" rel="external">Efficient Graph Based Image Segmentation</a>中的方法来得到region</li>
<li>得到所有region之间两两的相似度</li>
<li>合并最像的两个region</li>
<li>重新计算新合并region与其他region的相似度</li>
<li>重复上述过程直到整张图片都聚合成一个大的region</li>
<li>使用一种随机的计分方式给每个region打分，按照分数进行ranking，取出top k的子集，就是selective search的结果</li>
</ol>
</li>
<li>用CNN提取特征</li>
<li>用SVM对区域进行分类</li>
</ol>
<p><img src="https://tryolabs.com/images/blog/post-images/2017-08-30-object-detection/rcnn.jpg" alt="[Girshick, Ross, et al. &quot;Rich feature hierarchies for accurate object detection and semantic segmentation.&quot; 2014.](https://arxiv.org/abs/1311.2524)"></p>
<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h2><p>在feature map加入RoI Pooling,然今后做分类和回归（位置），这样可以end-to-end的训练了，缺点是依然依赖于selective search</p>
<p>每一个RoI都有一个四元组$（r,c,h,w）$表示，其中$（r，c）$表示左上角，而$（h，w）$则代表高度和宽度。这一层使用最大池化（max pooling）来将RoI区域转化成固定大小的$H<em>W$的特征图。假设一个RoI的窗口大小为$h</em>w$,则转换成$H<em>W$之后，每一个网格都是一个$h/H </em> w/W$大小的子网，利用最大池化将这个子网中的值映射到$H*W$窗口即可。Pooling对每一个特征图通道都是独立的</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/ROI.png" alt=""></p>
<p><img src="https://tryolabs.com/images/blog/post-images/2017-08-30-object-detection/fastrcnn.jpg" alt=""></p>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><p>加入region proposal network，为了代替selective search使得模型能够完全的end-to-end的训练。</p>
<p>这样的话就存在４个loss:</p>
<ol>
<li>RPN分类：是否是object</li>
<li>RPN box坐标回归</li>
<li>object分类</li>
<li>最终的坐标回归</li>
</ol>
<p><img src="http://shartoo.github.io/images/blog/rcnn9.png" alt=""></p>
<p>Anchor:</p>
<p>Anchors是一组大小固定的参考窗口：三种尺度{ $128^2，256^2，512^2$ }×三种长宽比{1:1，1:2，2:1}，如下图所示，<strong>表示RPN网络中对特征图滑窗时每个滑窗位置所对应的原图区域中9种可能的大小</strong>，相当于模板，对任意图像任意滑窗位置都是这9种模板。<strong>继而根据图像大小计算滑窗中心点对应原图区域的中心点</strong>，通过中心点和size就可以得到滑窗位置和原图位置的映射关系，由此原图位置并根据与Ground Truth重复率贴上正负标签，让RPN学习该Anchors是否有物体即可。对于每个滑窗位置，产生<strong>k=9</strong>个anchor对于一个大小为$W*H$的卷积feature map，总共会产生$WHk$个anchor。</p>
<p><img src="http://shartoo.github.io/images/blog/rcnn12.png" alt=""></p>
<p><img src="https://tryolabs.com/images/blog/post-images/2017-08-30-object-detection/fasterrcnn.jpg" alt="[Ren, Shaoqing, et al. &quot;Faster R-CNN: Towards real-time object detection with region proposal networks.&quot; 2015.](https://arxiv.org/abs/1506.01497)"></p>
<p><img src="http://img.blog.csdn.net/20160414164536029" alt=""></p>
<h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><p><strong>同时采用lower和upper的feature map做检测</strong></p>
<p>假设每个feature map cell有k个default box，那么对于每个default box都需要预测c个类别score和4个offset，那么如果一个feature map的大小是$m\times n$，也就是有<strong>$m\times n$</strong>个feature map cell，那么这个feature map就一共有$（c+4)\times k\times m\times n$ 个输出。这些输出个数的含义是：采用$3\times3$的卷积核对该层的feature map卷积时卷积核的个数，包含两部分：数量$c\times k\times m\times n$是confidence输出，表示每个default box的confidence，也就是类别的概率；数量$4\times k\times m\times n$是localization输出，表示每个default box回归后的坐标）。训练中还有一个东西：<strong>prior box</strong>，是指实际中选择的default box（每一个feature map cell 不是k个default box都取）。</p>
<ul>
<li>feature map cell 就是将 feature map 切分成 8×8 或者 4×4 之后的一个个格子；</li>
<li>而 default box 就是每一个格子上，一系列固定大小的 box，即图中虚线所形成的一系列 boxes。</li>
</ul>
<p><img src="http://img.blog.csdn.net/20160918092529925" alt=""></p>
<p><img src="http://img.blog.csdn.net/20160918092701558" alt=""></p>
<h2 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h2><p><img src="http://upload-images.jianshu.io/upload_images/75110-91ee171b49f3ea20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>YOLO首先将图像分为S×S的格子（grid cell）。如果一个目标的中心落入格子，该格子就负责检测该目标。每一个格子（grid cell）预测bounding boxes和该boxes的置信值（confidence score）。置信值代表box包含一个目标的置信度。然后，我们定义置信值为。如果没有目标，置信值为零。另外，我们希望预测的置信值和ground truth的intersection over union (IOU)相同。</p>
<p>每一个bounding box包含5个值：$x，y，w，h$和confidence。$（x，y）$代表与格子相关的box的中心。$（w，h）$为与全图信息相关的box的宽和高。confidence代表预测boxes的IOU和gound truth。</p>
<p>每个格子（grid cell）预测条件概率值C($Pr(Class_i|Object) $)。概率值C代表了格子包含一个目标的概率，每一格子只预测一类概率。在测试时，每个box通过类别概率和box置信度相乘来得到特定类别置信分数：<br>$$<br>Pr(Class_i|Object) \cdot Pr(Object)\cdot IOU_{pred}^{truth} = Pr(Class_i)\cdot IOU_{pred}^{truth}<br>$$<br>它将图片划分为S×S的网格，对于每个网格单元预测边界框(B)、边界框的置信度以及类别概率(C)，因此这些预测值可以表示为S×S×(B∗5+C)的张量。</p>
]]></content>
      
        
        <tags>
            
            <tag> deep learning </tag>
            
            <tag> notes </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[如何在圆内均匀采样]]></title>
      <url>/2017/05/18/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%9C%86%E5%86%85%E5%9D%87%E5%8C%80%E9%87%87%E6%A0%B7/</url>
      <content type="html"><![CDATA[<p>这个问题之前在面试网易游戏的时候碰到过，当时只想了一个很朴素(naive)的做法，现在有时间重新推导了一下：</p>
<p>假设圆是一个单元圆，半径为1, 面积为$\pi$。</p>
<p>当时面试的时候想的方法是用一个长度为1的外接正方形来代替采样，如果在圆内，则返回，不然继续采样，这样的采样方法明显是不稳定的，但是期望的采样步数很容易计算，是$\frac{4}{\pi}$。</p>
<p>后来想到说可以先采样角度，每个角度确定一个半径，再在半径上均匀采样，面试官有提示说在半径上是均匀的吗？ 明显在半径上采样是不均匀的，因为在半径上的每一个点对应的周长是不一样的！！</p>
<p>正确的姿势是这样的：</p>
<p>我们计算长度为$r(0\le r\le1)$的概率为$p(r)$:</p>
<p>首先我们需要计算落在$r\sim r+\Delta r$的概率，很直观，就是除以面积$\pi$，然后因为均匀采样所以需要除以$\Delta r$求得$p(r)$也就是：<br>$$<br>p(r\sim r+\Delta r) = \lim_{\Delta r\rightarrow0}\frac{\pi(r+\Delta r)^2-\pi r^2}{\pi}<br>$$</p>
<p>$$<br>p(r) = \lim_{\Delta r\rightarrow0}\frac{\pi(r+\Delta r)^2-\pi r^2}{\pi \Delta r}=2r<br>$$</p>
<p>接下来就是求$p(r)$的CDF,$P(r)$，积分即可：<br>$$<br>P(r) = \int_0^r p(x) dx=r^2<br>$$<br>然后求得它的逆函数$P^{-1}(r)$:</p>
<p>$$P^{-1}(r) = \sqrt r$$</p>
<p>算到这里，答案呼之欲出，我们用一个随机变量$\zeta$ 在$[0,1]$均匀采样，然后在通过$r = \sqrt \zeta$求得r,为什么是均匀的呢，只要把$\sqrt \zeta$带入$P(r)$就可以发现$P(r)=\zeta$。</p>
<p>如果面积变成3维，也就是单位球呢？做法还是一样的，首先还是对方向进行采样，这个自然是均匀的，然后就是在半径上采样，同样地，计算p(r)：<br>$$<br>p(r\sim r+\Delta r) = \lim_{\Delta r\rightarrow0}\frac{\frac{4}{3}\pi(r+\Delta r)^3-\frac{4}{3}\pi r^3}{\frac{4}{3}\pi}<br>$$</p>
<p>$$<br>p(r) = \lim_{\Delta r\rightarrow0}\frac{\frac{4}{3}\pi(r+\Delta r)^3-\frac{4}{3}\pi r^3}{\frac{4}{3}\pi\Delta r}=3r^2<br>$$</p>
<p>还是求CDF，后面就不继续了。。。依葫芦画瓢</p>
]]></content>
      
        
        <tags>
            
            <tag> math </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[一个离散概率分布中采样]]></title>
      <url>/2017/05/17/%E4%B8%80%E4%B8%AA%E7%A6%BB%E6%95%A3%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83%E4%B8%AD%E9%87%87%E6%A0%B7/</url>
      <content type="html"><![CDATA[<p>先考虑一个简单的例子：</p>
<p>一个n-sided dice. 其每一面是均匀的，也就是每一面的概率都是$\frac{1}{n}$,我们可以把区间[0,1)分成n份，采样的过程就可以变成：从[0,1)采样得到x，然后返回$\lfloor n\times x\rfloor$。</p>
<blockquote>
<h4 id="Algorithm-Simulating-a-Fair-Die"><a href="#Algorithm-Simulating-a-Fair-Die" class="headerlink" title="Algorithm: Simulating a Fair Die"></a>Algorithm: Simulating a Fair Die</h4><ol>
<li>Generate a uniformly-random value xx in the range [0,1).</li>
<li>Return $⌊x\times n⌋$</li>
</ol>
</blockquote>
<h2 id="朴素的做法"><a href="#朴素的做法" class="headerlink" title="朴素的做法"></a>朴素的做法</h2><p>但如果不是均匀的呢？假设给定各个离散值的概率p(x)，先计算CDF，即 P(x)。然后从[0,1)采样，得到a，我们需要确定a所在的区间，朴素的做法就是二分搜索P（x）（单调性）。所以时间复杂度为$O(\log(n))$</p>
<h2 id="The-Alias-Method"><a href="#The-Alias-Method" class="headerlink" title="The Alias Method"></a>The Alias Method</h2><p>如果想要用$O(1)$的时间采样呢？</p>
<p>考虑如下的情况：</p>
<p>有四个概率：$\frac{1}{2}, \frac{1}{3}, \frac{1}{12},\frac{1}{12}$</p>
<p><img src="http://www.keithschwarz.com/darts-dice-coins/images/aliasMethodInitialProbabilities.png" alt=""></p>
<p>首先，将他们归一化，用均值做归一化操作</p>
<p><img src="http://www.keithschwarz.com/darts-dice-coins/images/aliasMethodScaled.png" alt=""></p>
<p>先画一个$1\times 4$的矩形：</p>
<p><img src="http://www.keithschwarz.com/darts-dice-coins/images/aliasMethodSetup.png" alt=""></p>
<p>可以看到$\frac{1}{2}, \frac{1}{3}$并不是完全在矩形内，如果我们允许将自身的矩阵切除，然后补到其他区域内？例如将$\frac{1}{2}$切掉一部分补到最后那个区域：</p>
<p><img src="http://www.keithschwarz.com/darts-dice-coins/images/aliasMethodSetup2.png" alt=""></p>
<p>到现在，还是在矩阵之外的块，接下来，把$\frac{1}{2}$切掉足够的部分补到第三个中：</p>
<p><img src="http://www.keithschwarz.com/darts-dice-coins/images/aliasMethodSetup3.png" alt=""></p>
<p>最后：</p>
<p><img src="http://www.keithschwarz.com/darts-dice-coins/images/aliasMethodSetup4.png" alt=""></p>
<p>完美！</p>
<p>从上述可以看出有几条非常赞的性质：</p>
<ol>
<li>每个概率对应的面积都没有改变，随之对应的就是每个bar都是满的，这样保证了我每次采样都会命中！</li>
<li>每个bar最多有两种颜色。</li>
</ol>
<p>alias method主要依赖于两张表，一张概率表P还有一张alias表 Alias</p>
<p>构建完上述的表格以后，如何采样呢？</p>
<p><img src="http://www.keithschwarz.com/darts-dice-coins/images/completedAliasSetup.png" alt=""></p>
<p>首先对每列进行采样，列确定后，再采样，利用P和alias。过程非常简单，时间效率是$O(1)$</p>
<p>接下来就是证明这个alias表和P表是否一定存在！</p>
<blockquote>
<p><strong>Theorem:</strong> Given k width-one rectangles of heights $h_0,h_1,…,h_{k−1}$ such that $\sum_{i=0}^{k-1}h_i=k$, there is a way of cutting the rectangles and distributing them into k columns, each of which has height 1, such that each column contains at most two different rectangles and the $i$th column contains at least one piece of the $i$th rectangle.</p>
</blockquote>
<p>证明：</p>
<p>当k=1的时候，很明显是成立的。</p>
<p>假设当$k=x$的时候成立，那么我们就需要证明$k=x+1$时，是否满足。<br>考虑任一个宽度为$x+1$的矩形，高度分别是：$h_0, h_1, …, h_{k}$, 且满足$\sum_{i = 0}^{k}{h_i} =  x+ 1$,假设一些高度$h_l \le 1$ 还有一些$h_g\ge 1$。不可能同时大于0或者小于0。</p>
<p>接下来就是用$h_g$把$h_l$填满，这样我们就只剩下$x$个未解决的。所以。。成立！</p>
<p>具体的做法如下：</p>
<blockquote>
<h4 id="Algorithm-Naive-Alias-Method"><a href="#Algorithm-Naive-Alias-Method" class="headerlink" title="Algorithm: Naive Alias Method"></a>Algorithm: Naive Alias Method</h4><ul>
<li>Initialization:<ol>
<li>Multiply each probability $p_i$ by n.</li>
<li>Create arrays Alias and Prob, each of size n.</li>
<li>For j=1 to n−1:<ol>
<li>Find a probability pl satisfying $p_l\le1$.</li>
<li>Find a probability $p_g$ (with $l\ne g$) satisfying $p_g\ge1$</li>
<li>Set $Prob[l]=p_l$.</li>
<li>Set $Alias[l]=g$.</li>
<li>Remove $p_l$ from the list of initial probabilities.</li>
<li>Set $p_g:=p_g−(1−p_l)$.</li>
</ol>
</li>
<li>Let i be the last probability remaining, which must have weight 1.</li>
<li>Set $Prob[i]=1$.</li>
</ol>
</li>
<li>Generation:<ol>
<li>Generate a fair die roll from an n-sided die; call the side i.</li>
<li>Flip a biased coin that comes up heads with probability $Prob[i]$.</li>
<li>If the coin comes up “heads,” return i.</li>
<li>Otherwise, return $Alias[i]$.</li>
</ol>
</li>
</ul>
</blockquote>
]]></content>
      
        
        <tags>
            
            <tag> math </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CNN Case Study]]></title>
      <url>/2017/05/12/cnn-case-study/</url>
      <content type="html"><![CDATA[<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>结构：</p>
<p>CONV1-&gt;MAX POOL1-&gt;NORM1-&gt;CONV2-&gt;MAX POOL2-&gt;NORM-&gt;CONV3-&gt;CONV4-&gt;CONV5-&gt;MAX POOL3-&gt;FC6-&gt;FC7-&gt;FC8</p>
<p>输入： $227\times 227\times 3$ 的图像</p>
<p>第一层（CONV1），96个$11\times11$的卷积和，stride为4，,因为(227-11)/4+1=55</p>
<p>参数的大小是$11\times11\times3\times96=35K$,输出为$55\times55\times96$</p>
<p>第二层（MAX POOL1）， $3\times 3$， 步数为2，因为(55-3)/2+1=27,所以，输出为$27\times27\times96$</p>
<p>第三层（NORM1）</p>
<p>第四层CONV2，256个$5\times5$的卷积和，stride为1，pad为2，因为（27-5+2*2）/1+1= 27，所以输出为$27\times27\times256$</p>
<p>第五层（MAX POOL2）， $3\times 3$， stride为2，因为(27-3)/2+1=13,所以，输出为$13\times13\times256$</p>
<p>第六层 （NORM2）</p>
<p>第七层（CONV3），384个$3\times3$的卷积和，stride为1，pad为1，因为(13-3+1*2)/1+1 = 13,所以输出为$13\times13\times384$</p>
<p>第八层（CONV4），384个$3\times3$的卷积和，stride为1，pad为1，因为(13-3+1*2)/1+1 = 13,所以输出为$13\times13\times384$</p>
<p>第九层（CONV5），256个$3\times3$的卷积和，stride为1，pad为1，因为(13-3+1*2)/1+1 = 13,所以输出为$13\times13\times256$</p>
<p>第十层（MAX POOL2）， $3\times 3$， 步数为2，因为(13-3)/2+1=6,所以，输出为$6\times6\times256$</p>
<p>第十一层（FC6），4096个neurons</p>
<p>第十二层（FC7）， 4096个neurons</p>
<p>第十三层（FC8）， 1000个neurons</p>
<h2 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h2><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-27%20%E4%B8%8B%E5%8D%883.11.48.png" alt=""></p>
<p>为什么要使用小的卷积核（$3\times3$ conv）?</p>
<p>因为3个$3\times3$stride为1的conv堆起来的receptive field是和$7\times7$的conv layer是一样的，这样的话网络可以更深，同时非线性能力提高，而且前者参数数量为：$3*(3^2C^2)$ 后者为 $7^2C^2$,前者数量较少。</p>
<p>INPUT: $[224\times224\times3]$        memory:  $224<em>224</em>3$=150K   params: 0</p>
<p>CONV3-64:$ [224\times224\times64] $ memory:  $224<em>224</em>64$=3.2M   params:$ (3<em>3</em>3)*64 = 1,728$</p>
<p>CONV3-64:$ [224\times224\times64]$  memory:  $224<em>224</em>64$ =3.2M   params: $(3<em>3</em>64)*64 = 36,864$</p>
<p>POOL2: $[112\times112\times64]$  memory:  $112<em>112</em>64$=800K   params: 0</p>
<p>CONV3-128: $[112\times112\times128]$  memory:  $112<em>112</em>128$=1.6M   params: $(3<em>3</em>64)*128 = 73,728$</p>
<p>CONV3-128: $[112\times112\times128] $ memory: $112<em>112</em>128$=1.6M   params:$ (3<em>3</em>128)*128 = 147,456 $</p>
<p>POOL2:$ [56\times56\times128]$  memory:  $56<em>56</em>128=400K$   params: 0</p>
<p>CONV3-256:$ [56\times56\times256] $ memory:  $56<em>56</em>256=800K$   params:$ (3<em>3</em>128)*256 = 294,912$</p>
<p>CONV3-256:$ [56\times56\times256]$  memory:  $56<em>56</em>256=800K$   params:$ (3<em>3</em>256)*256 = 589,824 $</p>
<p>CONV3-256: $[56\times56\times256] $ memory:  $56<em>56</em>256=800K$   params:$ (3<em>3</em>256)*256 = 589,824$</p>
<p>POOL2: $[28\times28\times256]$  memory:  $28<em>28</em>256=200K$   params: 0</p>
<p>CONV3-512:$ [28\times28\times512] $ memory:  $28<em>28</em>512=400K$   params:$ (3<em>3</em>256)*512 = 1,179,648$</p>
<p>CONV3-512: $[28\times28\times512]$  memory: $ 28<em>28</em>512=400K $  params:$ (3<em>3</em>512)*512 = 2,359,296$</p>
<p>CONV3-512:$ [28\times28\times512]$  memory: $ 28<em>28</em>512=400K$   params: $(3<em>3</em>512)*512 = 2,359,296$</p>
<p>POOL2:$ [14\times14\times512]$  memory:  $14<em>14</em>512=100K$   params: 0 </p>
<p>CONV3-512:$ [14\times14\times512]$  memory: $ 14<em>14</em>512=100K$   params: $(3<em>3</em>512)*512 = 2,359,296$</p>
<p>CONV3-512:$ [14\times14\times512] $ memory: $ 14<em>14</em>512=100K$   params: $(3<em>3</em>512)*512 = 2,359,296 $</p>
<p>CONV3-512: $[14\times14\times512]$  memory:  $14<em>14</em>512=100K$   params: $(3<em>3</em>512)*512 = 2,359,296$</p>
<p>POOL2: $[7\times7\times512] $ memory:  $7<em>7</em>512=25K$  params: 0</p>
<p>FC: $[1\times1\times4096]$  memory:  4096  params: $7<em>7</em>512*4096 = 102,760,448 $</p>
<p>FC: $[1\times1\times4096]$  memory:  4096  params: $4096*4096 = 16,777,216$</p>
<p>FC: $[1\times1\times1000]$  memory:  1000 params: $4096*1000 = 4,096,000 $</p>
<p>总结一下：对于一张图片来说，需要花费的内存是24M*4 bytes = 96MB，而总共的参数有138M </p>
<p>VGG的FC7的特征非常棒！通常用来提特征。</p>
<h2 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h2><p>22层，有高效的inception module，没有FC层</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-27%20%E4%B8%8B%E5%8D%883.15.37.png" alt=""></p>
<p>重点分析一下Inception module,下图是一个朴素的inception module</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-27%20%E4%B8%8B%E5%8D%883.12.08.png" alt=""></p>
<p>采用的并行filter运算，有多个receptive field size的卷积，（$1\times1$,$3\times3$,$5\times5$）,从左向右第一个输出的size为$28\times28\times128$，第二个输出的size为$28\times28\times192$,第三个为$28\times28\times96$，第四个为$28\times28\times256$，concate以后的size为：$28\times28\times672$</p>
<p>缺点就是卷积运算过多：</p>
<p>$1\times1$ conv, 128=&gt;   $28\times28\times128\times1\times1\times256$</p>
<p> $3\times3$ conv, 192=&gt; $28\times28\times192\times3\times3\times256$</p>
<p> $5\times5$ conv, 96=&gt; $28\times28\times96\times5\times5\times256$</p>
<p>总共需要854M次运算</p>
<p>而且，最终的输出太大了！我们需要减少feature depth,可以用$1\times1$的卷积（$1\times1$ conv “bottleneck” layers）来解决，例如一个$56\times56\times64$的feature map经过32个$1\times1$以后，得到$56\times56\times32$,这样做就是将深度投影到较低的维度，（feature map的组合）</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-27%20%E4%B8%8B%E5%8D%883.12.36.png" alt=""></p>
<p>卷积运算的数量：</p>
<p>$[1\times1 conv, 64]$  $28\times28\times64\times1\times1\times256$</p>
<p>$[1\times1 conv, 64]$  $28\times28\times64\times1\times1\times256$</p>
<p>$[1\times1 conv, 128] $ $28\times28\times128\times1\times1\times256$</p>
<p>$[3\times3 conv, 192]$  $28\times28\times192\times3\times3\times64$</p>
<p>$[5\times5 conv, 96]$  $28\times28\times96\times5\times5\times64$</p>
<p>$[1\times1 conv, 64]$  $28\times28\times64\times1\times1\times256$ </p>
<p>Total: 358M ops</p>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><ul>
<li>每一层CONV层接BN</li>
<li>没有dropout</li>
</ul>
<p>具体见：</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-27%20%E4%B8%8B%E5%8D%883.17.12.png" alt=""></p>
]]></content>
      
        
        <tags>
            
            <tag> notes </tag>
            
            <tag> computer vision </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[机器学习中的向量化]]></title>
      <url>/2017/05/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96/</url>
      <content type="html"><![CDATA[<h2 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h2><p>以KNN算法为例，在训练过程中，也就是计算$X_{training}$和$X_{test}$的之间的距离的时候，可以用向量化，也就是矩阵运算加速，这里我们假设 $X_{train}\in R^{n\times d}$ ,$X_{test}\in R^{m\times d}$,那么我们就先需要计算一个$n\times m$ 的矩阵，最朴素的做法就是：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">num_test = X.shape[<span class="number">0</span>]</div><div class="line">num_train = self.X_train.shape[<span class="number">0</span>]</div><div class="line">dists = np.zeros((num_test, num_train))</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_test):</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_train):</div><div class="line">        dists[i, j] = np.sqrt(np.sum(np.square(X[i]-self.X_train[j])))</div><div class="line">        <span class="keyword">return</span> dists</div></pre></td></tr></table></figure>
<p>如果用向量化呢？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">num_test = X.shape[<span class="number">0</span>]</div><div class="line">num_train = self.X_train.shape[<span class="number">0</span>]</div><div class="line">dists = np.sqrt(<span class="number">-2</span>*np.dot(X, self.X_train.T) + np.sum(np.square(self.X_train), axis=<span class="number">1</span>) + np.sum(np.square(X), axis=<span class="number">1</span>).reshape(<span class="number">-1</span>, <span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>推导的过程是这样的：</p>
<p>对于第i个$X_{test}$和第j个$X_{train}$的距离来说，可以先将平方展开，可以发现由三部分组成，分别是$X_{test}$的平方，$X_{train}$的平方，两者的乘积。对于第三部分的分析比较简单就是$X_{train}X_{test}^T$, 而对于前面两部分的分析其实就是对于第二个维度求和，然后加到目标矩阵相应的维度即可。</p>
<p>看一下时间的对比：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Let's compare how fast the implementations are</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">time_function</span><span class="params">(f, *args)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Call a function f with args and return the time (in seconds) that it took to execute.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    <span class="keyword">import</span> time</div><div class="line">    tic = time.time()</div><div class="line">    f(*args)</div><div class="line">    toc = time.time()</div><div class="line">    <span class="keyword">return</span> toc - tic</div><div class="line"></div><div class="line">two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)</div><div class="line">print(<span class="string">'Two loop version took %f seconds'</span> % two_loop_time)</div><div class="line">no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)</div><div class="line">print(<span class="string">'No loop version took %f seconds'</span> % no_loop_time)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Two loop version took 21.228456 seconds</div><div class="line">No loop version took 0.182820 seconds</div></pre></td></tr></table></figure>
<p>提升非常明显</p>
<h2 id="Multi-class-Support-Vector-Machine"><a href="#Multi-class-Support-Vector-Machine" class="headerlink" title="Multi-class Support Vector Machine"></a>Multi-class Support Vector Machine</h2><p>那么它的loss function是：<br>$$<br>Li=\sum_{j≠yi}\max(0,s_j−s_{yi}+\Delta)<br>$$<br>$s_j = f(x_i, W)_j$, 这个loss function(hinge loss)其实保证的是label的score是最大的，否则不存在loss，还有梯度。</p>
<p>再转换一下：<br>$$<br>L_i = \sum_{j\neq y_i} \max(0, w_j^T x_i - w_{y_i}^T x_i + \Delta)<br>$$<br><img src="http://cs231n.github.io/assets/margin.jpg" alt=""></p>
<p>那么对于$X_{train}\in R^{N\times D}$, $W\in R^{D\times M}$，它的loss和梯度计算过程(朴素方法)如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Structured SVM loss function, naive implementation (with loops).</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Inputs have dimension D, there are C classes, and we operate on minibatches</span></div><div class="line"><span class="string">  of N examples.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - W: A numpy array of shape (D, C) containing weights.</span></div><div class="line"><span class="string">  - X: A numpy array of shape (N, D) containing a minibatch of data.</span></div><div class="line"><span class="string">  - y: A numpy array of shape (N,) containing training labels; y[i] = c means</span></div><div class="line"><span class="string">    that X[i] has label c, where 0 &lt;= c &lt; C.</span></div><div class="line"><span class="string">  - reg: (float) regularization strength</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - loss as single float</span></div><div class="line"><span class="string">  - gradient with respect to weights W; an array of same shape as W</span></div><div class="line"><span class="string">  """</span></div><div class="line">  dW = np.zeros(W.shape) <span class="comment"># initialize the gradient as zero</span></div><div class="line"></div><div class="line">  <span class="comment"># compute the loss and the gradient</span></div><div class="line">  num_classes = W.shape[<span class="number">1</span>]</div><div class="line">  num_train = X.shape[<span class="number">0</span>]</div><div class="line">  loss = <span class="number">0.0</span></div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_train):</div><div class="line">    scores = X[i].dot(W)</div><div class="line">    correct_class_score = scores[y[i]]</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_classes):</div><div class="line">      <span class="keyword">if</span> j == y[i]:</div><div class="line">        <span class="keyword">continue</span></div><div class="line">      margin = scores[j] - correct_class_score + <span class="number">1</span> <span class="comment"># note delta = 1</span></div><div class="line">      <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</div><div class="line">        loss += margin</div><div class="line"></div><div class="line">  <span class="comment"># Right now the loss is a sum over all training examples, but we want it</span></div><div class="line">  <span class="comment"># to be an average instead so we divide by num_train.</span></div><div class="line">  loss /= num_train</div><div class="line"></div><div class="line">  <span class="comment"># Add regularization to the loss.</span></div><div class="line">  loss += <span class="number">0.5</span> * reg * np.sum(W * W)</div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_train):</div><div class="line">    scores = X[i].dot(W)</div><div class="line">    correct_class_score = scores[y[i]]</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_classes):</div><div class="line">      <span class="keyword">if</span> j == y[i]:</div><div class="line">        <span class="keyword">continue</span></div><div class="line">      margin = scores[j] - correct_class_score + <span class="number">1</span> <span class="comment"># note delta = 1</span></div><div class="line">      <span class="keyword">if</span> margin &gt; <span class="number">0</span>:</div><div class="line">        dW[:, j] += X[i]</div><div class="line">        dW[:, y[i]] -= X[i]</div><div class="line">  dW /= num_train</div><div class="line">  dW += reg * W</div><div class="line">  <span class="keyword">return</span> loss, dW</div></pre></td></tr></table></figure>
<p>向量化之后就可以这样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">svm_loss_vectorized</span><span class="params">(W, X, y, reg)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Structured SVM loss function, vectorized implementation.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Inputs and outputs are the same as svm_loss_naive.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  loss = <span class="number">0.0</span></div><div class="line">  dW = np.zeros(W.shape) <span class="comment"># initialize the gradient as zero</span></div><div class="line">  num_classes = W.shape[<span class="number">1</span>]</div><div class="line">  num_train = X.shape[<span class="number">0</span>]</div><div class="line">  scores = (X.dot(W)).T</div><div class="line">  margins = np.maximum(<span class="number">0</span>, scores-scores[y, range(num_train)]+<span class="number">1</span>)</div><div class="line">  margins[y, range(num_train)] = <span class="number">0</span></div><div class="line">  loss += np.sum(margins) / num_train</div><div class="line">  loss += <span class="number">0.5</span> * reg * np.sum(W * W)</div><div class="line"></div><div class="line">  D = np.zeros_like(margins)</div><div class="line">  D[margins&gt;<span class="number">0</span>] = <span class="number">1</span></div><div class="line">  D[y, range(num_train)] = -np.sum(margins&gt;<span class="number">0</span>, axis=<span class="number">0</span>)</div><div class="line">  dW += np.dot(D, X).T</div><div class="line">  dW /= num_train</div><div class="line">  dW += reg  * W</div><div class="line"></div><div class="line">  <span class="keyword">return</span> loss, dW</div></pre></td></tr></table></figure>
<p>比较一下效率</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">tic = time.time()</div><div class="line">_, grad_naive = svm_loss_naive(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'Naive loss and gradient: computed in %fs'</span> % (toc - tic))</div><div class="line"></div><div class="line">tic = time.time()</div><div class="line">_, grad_vectorized = svm_loss_vectorized(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'Vectorized loss and gradient: computed in %fs'</span> % (toc - tic))</div><div class="line"></div><div class="line"><span class="comment"># The loss is a single number, so it is easy to compare the values computed</span></div><div class="line"><span class="comment"># by the two implementations. The gradient on the other hand is a matrix, so</span></div><div class="line"><span class="comment"># we use the Frobenius norm to compare them.</span></div><div class="line">difference = np.linalg.norm(grad_naive - grad_vectorized, ord=<span class="string">'fro'</span>)</div><div class="line">print(<span class="string">'difference: %f'</span> % difference)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Naive loss and gradient: computed in 0.141285s</div><div class="line">Vectorized loss and gradient: computed in 0.007416s</div><div class="line">difference: 0.000000</div></pre></td></tr></table></figure>
<p>提升非常大</p>
<h2 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h2><p>softmax分类器用的是交叉熵（cross entropy）,有以下的形式：<br>$$<br>L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.5in} \text{or equivalently} \hspace{0.5in} L_i = -f_{y_i} + \log\sum_j e^{f_j}<br>$$<br>对这个这个loss函数，可以有两种解释：</p>
<p>信息论的视角，也就是真的分布p和预测分布q之间的交叉熵：<br>$$<br>H(p,q) = - \sum_x p(x) \log q(x)<br>$$<br>p是这样一个向量：只有一个元素是1（$y_i$的位置），其他全是0。q就是模型输出的分布，所以两者相乘，得到上面的结果</p>
<p>还有就是概率的解释，例如下面的表达式：<br>$$<br>P(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }<br>$$<br>因此，我们就可以用最大似然估计（MLE）来求解，也就是最小化负的正确标签的log似然。</p>
<p>softmax函数定义了每个类别的概率估计。</p>
<p>朴素的求法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_naive</span><span class="params">(W, X, y, reg)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Softmax loss function, naive implementation (with loops)</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Inputs have dimension D, there are C classes, and we operate on minibatches</span></div><div class="line"><span class="string">  of N examples.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Inputs:</span></div><div class="line"><span class="string">  - W: A numpy array of shape (D, C) containing weights.</span></div><div class="line"><span class="string">  - X: A numpy array of shape (N, D) containing a minibatch of data.</span></div><div class="line"><span class="string">  - y: A numpy array of shape (N,) containing training labels; y[i] = c means</span></div><div class="line"><span class="string">    that X[i] has label c, where 0 &lt;= c &lt; C.</span></div><div class="line"><span class="string">  - reg: (float) regularization strength</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Returns a tuple of:</span></div><div class="line"><span class="string">  - loss as single float</span></div><div class="line"><span class="string">  - gradient with respect to weights W; an array of same shape as W</span></div><div class="line"><span class="string">  """</span></div><div class="line">  <span class="comment"># Initialize the loss and gradient to zero.</span></div><div class="line">  loss = <span class="number">0.0</span></div><div class="line">  dW = np.zeros_like(W)</div><div class="line">  num_train = X.shape[<span class="number">0</span>]</div><div class="line">  num_classes = W.shape[<span class="number">1</span>]</div><div class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> xrange(num_train):</div><div class="line">    score = X[i].dot(W)</div><div class="line">    score -= np.max(score)</div><div class="line">    exp_score = np.exp(score)</div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_classes):</div><div class="line">      dW[:, j] += X[i] * exp_score[j] / np.sum(exp_score)</div><div class="line">    dW[:, y[i]] -= X[i]</div><div class="line">    loss += -score[y[i]] + np.log(np.sum(exp_score))</div><div class="line">  loss /= num_train</div><div class="line">  loss += <span class="number">0.5</span> * reg * np.sum(W*W)</div><div class="line"></div><div class="line">  dW /= num_train</div><div class="line">  dW += reg * W</div><div class="line"></div><div class="line">  <span class="keyword">return</span> loss, dW</div></pre></td></tr></table></figure>
<p>向量化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax_loss_vectorized</span><span class="params">(W, X, y, reg)</span>:</span></div><div class="line">  <span class="string">"""</span></div><div class="line"><span class="string">  Softmax loss function, vectorized version.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">  Inputs and outputs are the same as softmax_loss_naive.</span></div><div class="line"><span class="string">  """</span></div><div class="line">  <span class="comment"># Initialize the loss and gradient to zero.</span></div><div class="line">  loss = <span class="number">0.0</span></div><div class="line">  dW = np.zeros_like(W)</div><div class="line">  num_train = X.shape[<span class="number">0</span>]</div><div class="line">  num_classes = W.shape[<span class="number">1</span>]</div><div class="line">  scores = X.dot(W).T</div><div class="line">  scores -= np.max(scores, axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)</div><div class="line">  exp_scores = np.exp(scores)</div><div class="line">  loss += np.sum(-scores[y, range(num_train)]) + np.sum(np.log(np.sum(exp_scores, axis=<span class="number">0</span>)))</div><div class="line">  loss /= num_train</div><div class="line">  loss += <span class="number">0.5</span> * reg * np.sum(W*W)</div><div class="line">  D = exp_scores / np.sum(exp_scores, axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)</div><div class="line">  D[y, range(num_train)] -= <span class="number">1.0</span></div><div class="line">  dW += D.dot(X).T</div><div class="line">  dW /= num_train</div><div class="line">  dW += reg * W</div><div class="line">  <span class="keyword">return</span> loss, dW</div></pre></td></tr></table></figure>
<p>对比一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Now that we have a naive implementation of the softmax loss function and its gradient,</span></div><div class="line"><span class="comment"># implement a vectorized version in softmax_loss_vectorized.</span></div><div class="line"><span class="comment"># The two versions should compute the same results, but the vectorized version should be</span></div><div class="line"><span class="comment"># much faster.</span></div><div class="line">tic = time.time()</div><div class="line">loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'naive loss: %e computed in %fs'</span> % (loss_naive, toc - tic))</div><div class="line"></div><div class="line"><span class="keyword">from</span> cs231n.classifiers.softmax <span class="keyword">import</span> softmax_loss_vectorized</div><div class="line">tic = time.time()</div><div class="line">loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, <span class="number">0.000005</span>)</div><div class="line">toc = time.time()</div><div class="line">print(<span class="string">'vectorized loss: %e computed in %fs'</span> % (loss_vectorized, toc - tic))</div><div class="line"></div><div class="line"><span class="comment"># As we did for the SVM, we use the Frobenius norm to compare the two versions</span></div><div class="line"><span class="comment"># of the gradient.</span></div><div class="line">grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord=<span class="string">'fro'</span>)</div><div class="line">print(<span class="string">'Loss difference: %f'</span> % np.abs(loss_naive - loss_vectorized))</div><div class="line">print(<span class="string">'Gradient difference: %f'</span> % grad_difference)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">naive loss: 2.332690e+00 computed in 0.397665s</div><div class="line">vectorized loss: 2.332690e+00 computed in 0.007957s</div><div class="line">Loss difference: 0.000000</div><div class="line">Gradient difference: 0.000000</div></pre></td></tr></table></figure>
<p>效果依然显著</p>
<h2 id="Softmax和SVM的对比"><a href="#Softmax和SVM的对比" class="headerlink" title="Softmax和SVM的对比"></a>Softmax和SVM的对比</h2><p><img src="http://cs231n.github.io/assets/svmvssoftmax.png" alt=""></p>
<p>其实两者性能上的差异非常小，对于SVM来说，如果正确的类的分数已经比其他类高了，那么它的loss为0，同时也没有梯度。而softmax则一直会有梯度，除非概率分布变成one-hot的形式且预测和标签相同。</p>
<blockquote>
<p>the Softmax classifier is never fully happy with the scores it produces: the correct class could always have a higher probability and the incorrect classes always a lower probability and the loss would always get better.</p>
</blockquote>
]]></content>
      
        
        <tags>
            
            <tag> notes </tag>
            
            <tag> machine learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[C++测试cache大小]]></title>
      <url>/2017/03/18/C-%E6%B5%8B%E8%AF%95cache%E5%A4%A7%E5%B0%8F/</url>
      <content type="html"><![CDATA[<p>思路其实不难，利用cache的性质，如果连续内存能够放到cache，那么随机访问的速度会比较快，反之会较慢，枚举cache的大小即可。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ctime&gt;</span></span></div><div class="line"></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">KB</span><span class="params">(<span class="keyword">int</span> a)</span> </span>&#123;</div><div class="line">	<span class="keyword">return</span> a &lt;&lt; <span class="number">10</span>;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line"></div><div class="line"></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> kb = <span class="number">1</span>; kb &lt; <span class="number">15</span>; kb++) &#123;</div><div class="line">		<span class="keyword">int</span> sz = KB(<span class="number">1</span>&lt;&lt;kb);</div><div class="line">		<span class="built_in">vector</span>&lt;<span class="keyword">char</span>&gt; a(sz, <span class="number">1</span>);</div><div class="line">		<span class="keyword">int</span> begin = clock();</div><div class="line">		<span class="keyword">int</span> haha = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; (<span class="number">1</span>&lt;&lt;<span class="number">25</span>); j++) &#123;</div><div class="line">			<span class="keyword">int</span> idx = random()%sz;<span class="comment">//随机存取</span></div><div class="line">			haha += a[idx];</div><div class="line">			idx = random()%sz;</div><div class="line">			haha += a[idx];</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">int</span> end = clock();</div><div class="line">		<span class="keyword">double</span> elapsed_secs = <span class="keyword">double</span>(end - begin) / CLOCKS_PER_SEC;<span class="comment">//时钟</span></div><div class="line">		<span class="built_in">cout</span> &lt;&lt; (<span class="number">1</span>&lt;&lt;kb) &lt;&lt; <span class="string">" KB "</span> &lt;&lt; elapsed_secs &lt;&lt; <span class="string">" sec"</span>&lt;&lt; <span class="built_in">endl</span>;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>输出是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">2 KB 1.07965 sec</div><div class="line">4 KB 1.08865 sec</div><div class="line">8 KB 1.08106 sec</div><div class="line">16 KB 1.08479 sec</div><div class="line">32 KB 1.08296 sec</div><div class="line">64 KB 1.09078 sec</div><div class="line">128 KB 1.09005 sec</div><div class="line">256 KB 1.08952 sec</div><div class="line">512 KB 1.16065 sec</div><div class="line">1024 KB 1.23121 sec</div><div class="line">2048 KB 1.37515 sec</div><div class="line">4096 KB 2.31725 sec</div><div class="line">8192 KB 3.23205 sec</div><div class="line">16384 KB 3.77682 sec</div></pre></td></tr></table></figure></p>
<p>cache大小大约为256KB，查看了一下系统属性</p>
<p><img src="http://7xkgro.com1.z0.glb.clouddn.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-11-27%20%E4%B8%8B%E5%8D%883.19.16.png" alt=""></p>
]]></content>
      
        
        <tags>
            
            <tag> notes </tag>
            
            <tag> algorithms </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
