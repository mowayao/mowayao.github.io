<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Mowayao&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/16886497103686372c55fdd8ac89f177</icon>
  <subtitle>一往无前虎山行</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://wulimengmeng.top/"/>
  <updated>2018-06-01T14:35:16.322Z</updated>
  <id>http://wulimengmeng.top/</id>
  
  <author>
    <name>Mowayao</name>
    <email>zpyao1992@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kaggle比赛小结-iMaterialist Challenge (Furniture) at FGVC5</title>
    <link href="http://wulimengmeng.top/2018/06/01/Kaggle%E6%AF%94%E8%B5%9B%E5%B0%8F%E7%BB%93-iMaterialist-Challenge-Furniture-at-FGVC5/"/>
    <id>http://wulimengmeng.top/2018/06/01/Kaggle比赛小结-iMaterialist-Challenge-Furniture-at-FGVC5/</id>
    <published>2018-06-01T14:21:47.000Z</published>
    <updated>2018-06-01T14:35:16.322Z</updated>
    
    <content type="html"><![CDATA[<p>https://www.kaggle.com/c/imaterialist-challenge-furniture-2018</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1frw1y1wwhhj31fa02adg9.jpg" alt=""></p><p>参加完比赛，做个简单的总结：</p><ul><li>数据增强：random flip, color jitter, resize and crop</li><li>数据的不平衡需要设置采样权重(这个好像不一定能work)</li><li>网络模型，DenseNet201，SENet，InceptionResNetv2，SEResNext</li><li>Focal Loss不work</li><li>Adam or SGD</li><li>Multi-crop for testing</li><li>Ensemble: 取log后相加</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;https://www.kaggle.com/c/imaterialist-challenge-furniture-2018&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ws1.sinaimg.cn/large/006tNc79ly1frw1y1wwhhj31fa02
      
    
    </summary>
    
      <category term="competition" scheme="http://wulimengmeng.top/categories/competition/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="classifcation" scheme="http://wulimengmeng.top/tags/classifcation/"/>
    
      <category term="computer vision" scheme="http://wulimengmeng.top/tags/computer-vision/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode Hard DP</title>
    <link href="http://wulimengmeng.top/2018/06/01/Leetcode-Hard-DP/"/>
    <id>http://wulimengmeng.top/2018/06/01/Leetcode-Hard-DP/</id>
    <published>2018-06-01T14:13:48.000Z</published>
    <updated>2018-06-08T07:28:59.714Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><p>###72. Edit Distance</p><p>Given two words word1 and word2, find the minimum number of operations required to convert word1 to word2.You have the following 3 operations permitted on a word:</p><ol><li>Insert a character</li><li>Delete a character</li><li>Replace a character</li></ol><p>Example 1:</p><p>Input: word1 = &quot;horse&quot;, word2 = &quot;ros&quot;Output: 3Explanation:horse -&gt; rorse (replace 'h' with 'r')rorse -&gt; rose (remove 'r')rose -&gt; ros (remove 'e')</p><p>Example 2:</p><p>Input: word1 = &quot;intention&quot;, word2 = &quot;execution&quot;Output: 5Explanation:intention -&gt; inention (remove 't')inention -&gt; enention (replace 'i' with 'e')enention -&gt; exention (replace 'n' with 'x')exention -&gt; exection (replace 'n' with 'c')exection -&gt; execution (insert 'u')</p><p>dp(i,j)的后续状态有dp(i-1, j)+1, dp(i, j-1)+1, dp(i-1, j-1)+1分别表示(删除或添加)和(替换)</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minDistance</span><span class="params">(<span class="built_in">string</span> word1, <span class="built_in">string</span> word2)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = word1.size(), m = word2.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; dp(n+<span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(m+<span class="number">1</span>, <span class="number">1e9</span>));</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= n; i++) dp[i][<span class="number">0</span>] = i;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= m; j++) dp[<span class="number">0</span>][j] = j;</div><div class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= m; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (word1[i<span class="number">-1</span>] == word2[j<span class="number">-1</span>]) &#123;</div><div class="line">                    dp[i][j] = min(dp[i][j], dp[i<span class="number">-1</span>][j<span class="number">-1</span>]);</div><div class="line">                &#125;</div><div class="line">                dp[i][j] = min(dp[i][j], min(dp[i<span class="number">-1</span>][j], min(dp[i][j<span class="number">-1</span>], dp[i<span class="number">-1</span>][j<span class="number">-1</span>]))+<span class="number">1</span>);</div><div class="line">            &#125;</div><div class="line">        </div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[n][m];</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minDistance</span><span class="params">(<span class="built_in">string</span> word1, <span class="built_in">string</span> word2)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = word1.size(), m = word2.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(m+<span class="number">1</span>, <span class="number">1e9</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= m; i++) dp[i] = i;</div><div class="line">        <span class="comment">//dp[i-1j-1]</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</div><div class="line">            <span class="keyword">int</span> before = dp[<span class="number">0</span>];</div><div class="line">            dp[<span class="number">0</span>] = i;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= m; j++) &#123;</div><div class="line">                <span class="keyword">int</span> ret = <span class="number">1e9</span>;</div><div class="line">                <span class="keyword">if</span> (word1[i<span class="number">-1</span>] == word2[j<span class="number">-1</span>]) &#123;</div><div class="line">                    ret = min(ret, before);</div><div class="line">                &#125;</div><div class="line">                ret = min(ret, min(dp[j]+<span class="number">1</span>, min(dp[j<span class="number">-1</span>]+<span class="number">1</span>, before+<span class="number">1</span>)));</div><div class="line">                before = dp[j];</div><div class="line">                dp[j] = ret;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[m];</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><p>###664. Strange Printer</p><p>There is a strange printer with the following two special requirements:</p><ol><li>The printer can only print a sequence of the same character each time.</li><li>At each turn, the printer can print new characters starting from and ending at any places, and will cover the original existing characters.</li></ol><p>Given a string consists of lower English letters only, your job is to count the minimum number of turns the printer needed in order to print it.Example 1:</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Input: &quot;aaabbb&quot;</div><div class="line">Output: 2</div><div class="line">Explanation: Print &quot;aaa&quot; first and then print &quot;bbb&quot;.</div></pre></td></tr></table></figure></p><p>Example 2:</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Input: &quot;aba&quot;</div><div class="line">Output: 2</div><div class="line">Explanation: Print &quot;aaa&quot; first and then print &quot;b&quot; from the second place of the string, which will cover the existing character &apos;a&apos;.</div></pre></td></tr></table></figure></p><p>Hint: Length of the given string will not exceed 100.</p><p>dp(i, j)　如果s[i]=s[j]，那么可以选择由dp(i-1, j)或者dp(i, j-1)搞定，否则的话就是寻找最佳的分割点</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; dp, <span class="built_in">string</span>&amp; s)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (l == r) <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span> (dp[l][r] != <span class="number">-1</span>) <span class="keyword">return</span> dp[l][r];</div><div class="line">        <span class="keyword">int</span> ret = <span class="number">1e9</span>;</div><div class="line">        <span class="keyword">if</span> (s[l] == s[r]) &#123;</div><div class="line">            ret = min(dfs(l+<span class="number">1</span>, r, dp, s), dfs(l, r<span class="number">-1</span>, dp, s));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = l; i &lt; r; i++) &#123;</div><div class="line">            ret = min(ret, dfs(l, i, dp, s)+dfs(i+<span class="number">1</span>,r, dp, s));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[l][r] = ret;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">strangePrinter</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = s.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; dp(n, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n, <span class="number">-1</span>));</div><div class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, s);</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>730. Count Different Palindromic Subsequences</h3><p>Given a string S, find the number of different non-empty palindromic subsequences in S, and <strong>return that number modulo 10^9 + 7.</strong></p><p>A subsequence of a string S is obtained by deleting 0 or more characters from S.</p><p>A sequence is palindromic if it is equal to the sequence reversed.</p><p>Two sequences <code>A_1, A_2, ...</code> and <code>B_1, B_2, ...</code> are different if there is some <code>i</code> for which <code>A_i != B_i</code>.</p><p><strong>Example 1:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Input: </div><div class="line">S = &apos;bccb&apos;</div><div class="line">Output: 6</div><div class="line">Explanation: </div><div class="line">The 6 different non-empty palindromic subsequences are &apos;b&apos;, &apos;c&apos;, &apos;bb&apos;, &apos;cc&apos;, &apos;bcb&apos;, &apos;bccb&apos;.</div><div class="line">Note that &apos;bcb&apos; is counted only once, even though it occurs twice.</div></pre></td></tr></table></figure></p><p><strong>Example 2:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Input: </div><div class="line">S = &apos;abcdabcdabcdabcdabcdabcdabcdabcddcbadcbadcbadcbadcbadcbadcbadcba&apos;</div><div class="line">Output: 104860361</div><div class="line">Explanation: </div><div class="line">There are 3104860382 different non-empty palindromic subsequences, which is 104860361 modulo 10^9 + 7.</div></pre></td></tr></table></figure></p><p><strong>Note:</strong></p><p>The length of <code>S</code> will be in the range <code>[1, 1000]</code>.</p><p>Each character <code>S[i]</code> will be in the set <code>{'a', 'b', 'c', 'd'}</code>.</p><p>枚举当前位置可选择的字符，再往下迭代，如果存在一对合理的，那么总共有３种选择，一种是偶数结束，一种是奇数结束，还有一种是选择这两个继续向下迭代，这样保证没有重复，非常tricky!!!!</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> ll;</div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> mod = <span class="number">1e9</span> + <span class="number">7</span>;</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">countPalindromicSubsequences</span><span class="params">(<span class="built_in">string</span> S)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = S.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;ll&gt;&gt; dp(n, <span class="built_in">vector</span>&lt;ll&gt;(n, <span class="number">-1</span>));</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; idxs(<span class="number">4</span>);</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            idxs[S[i]-<span class="string">'a'</span>].push_back(i);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> d = dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, idxs);</div><div class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, idxs);</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function">ll <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;ll&gt;&gt;&amp;dp, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; idxs)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (start &gt; end) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="keyword">if</span> (dp[start][end] != <span class="number">-1</span>) <span class="keyword">return</span> dp[start][end];</div><div class="line">        ll ans = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</div><div class="line">            <span class="keyword">auto</span> l = lower_bound(idxs[i].begin(), idxs[i].end(), start);</div><div class="line">            <span class="keyword">if</span> (l == idxs[i].end()) &#123;</div><div class="line">                <span class="keyword">continue</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">int</span> left = *l;</div><div class="line">            <span class="keyword">auto</span> r = upper_bound(idxs[i].begin(), idxs[i].end(), end);</div><div class="line">            <span class="keyword">int</span> right = <span class="number">-1</span>;</div><div class="line">            <span class="keyword">if</span> (r == idxs[i].end()) &#123;</div><div class="line">                right = idxs[i].back();</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                r--;</div><div class="line">                right = *r;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">if</span> (right == left) &#123;</div><div class="line">                ans = (ans + <span class="number">1</span>) % mod;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (right &gt; left) &#123;</div><div class="line">                ans = (ans + dfs(left+<span class="number">1</span>, right<span class="number">-1</span>, dp, idxs) + <span class="number">2</span>) % mod;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[start][end] = ans;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>97. Interleaving String</h3><p>Given <em>s1</em>, <em>s2</em>, <em>s3</em>, find whether <em>s3</em> is formed by the interleaving of <em>s1</em> and <em>s2</em>.</p><p><strong>Example 1:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: s1 = &quot;aabcc&quot;, s2 = &quot;dbbca&quot;, s3 = &quot;aadbbcbcac&quot;</div><div class="line">Output: true</div></pre></td></tr></table></figure></p><p><strong>Example 2:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Input: s1 = &quot;aabcc&quot;, s2 = &quot;dbbca&quot;, s3 = &quot;aadbbbaccc&quot;</div><div class="line">Output: false</div></pre></td></tr></table></figure></p><p>注意边界条件</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">isInterleave</span><span class="params">(<span class="built_in">string</span> s1, <span class="built_in">string</span> s2, <span class="built_in">string</span> s3)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = s1.size(), m = s2.size(), t = s3.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>)  <span class="keyword">return</span> s2 == s3;</div><div class="line">        <span class="keyword">if</span> (m == <span class="number">0</span>)  <span class="keyword">return</span> s1 == s3;</div><div class="line">        <span class="keyword">if</span> (t == <span class="number">0</span>)  <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        <span class="keyword">if</span> (n+m != t) <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;&gt; dp(n+<span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="keyword">bool</span>&gt;(m+<span class="number">1</span>, <span class="literal">false</span>));</div><div class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="literal">true</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">if</span> (s3[i] == s1[i]) &#123;</div><div class="line">                dp[i+<span class="number">1</span>][<span class="number">0</span>] = dp[i][<span class="number">0</span>];</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                dp[i+<span class="number">1</span>][<span class="number">0</span>] = <span class="literal">false</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        </div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; m; i++) &#123;</div><div class="line">            <span class="keyword">if</span> (s3[i] == s2[i]) &#123;</div><div class="line">                dp[<span class="number">0</span>][i+<span class="number">1</span>] = dp[<span class="number">0</span>][i];</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                dp[<span class="number">0</span>][i+<span class="number">1</span>] = <span class="literal">false</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; m; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (s3[i+j+<span class="number">1</span>] == s2[j]) &#123;</div><div class="line">                    dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = dp[i+<span class="number">1</span>][j+<span class="number">1</span>] || dp[i+<span class="number">1</span>][j];</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">if</span> (s3[i+j+<span class="number">1</span>] == s1[i]) &#123;</div><div class="line">                    dp[i+<span class="number">1</span>][j+<span class="number">1</span>] = dp[i+<span class="number">1</span>][j+<span class="number">1</span>] || dp[i][j+<span class="number">1</span>];</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[n][m];</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>312. Burst Balloons</h3><p>Given <code>n</code> balloons, indexed from <code>0</code> to <code>n-1</code>. Each balloon is painted with a number on it represented by array <code>nums</code>. You are asked to burst all the balloons. If the you burst balloon <code>i</code> you will get <code>nums[left] * nums[i] * nums[right]</code> coins. Here <code>left</code> and <code>right</code>are adjacent indices of <code>i</code>. After the burst, the <code>left</code> and <code>right</code> then becomes adjacent.</p><p>Find the maximum coins you can collect by bursting the balloons wisely.</p><p><strong>Note:</strong></p><ul><li>You may imagine <code>nums[-1] = nums[n] = 1</code>. They are not real therefore you can not burst them.</li><li>0 ≤ <code>n</code> ≤ 500, 0 ≤ <code>nums[i]</code> ≤ 100</li></ul><p><strong>Example:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">Input: [3,1,5,8]</div><div class="line">Output: 167 </div><div class="line">Explanation: nums = [3,1,5,8] --&gt; [3,5,8] --&gt;   [3,8]   --&gt;  [8]  --&gt; []</div><div class="line">             coins =  3*1*5      +  3*5*8    +  1*3*8      + 1*8*1   = 167</div></pre></td></tr></table></figure></p><p>区间dp，选择中间burst的气球，然后分割区间，一个比较好用的trick就是在头尾补1</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxCoins</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">        nums.insert(nums.begin(), <span class="number">1</span>);</div><div class="line">        nums.insert(nums.end(), <span class="number">1</span>);</div><div class="line">        </div><div class="line">        <span class="keyword">int</span> n = nums.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; dp(n, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n, <span class="number">-1</span>));</div><div class="line">        <span class="keyword">return</span> dfs(<span class="number">0</span>, n<span class="number">-1</span>, dp, nums);</div><div class="line">        <span class="comment">//return 0;</span></div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; dp, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (l+<span class="number">1</span> &gt;= r) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> (dp[l][r] != <span class="number">-1</span>) <span class="keyword">return</span> dp[l][r];</div><div class="line">        <span class="keyword">int</span> ret = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = l+<span class="number">1</span>; i &lt; r; i++) &#123;</div><div class="line">            ret = max(ret, nums[l]*nums[i]*nums[r] + dfs(l, i, dp, nums) + dfs(i, r, dp, nums));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[l][r] = ret;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>354. Russian Doll Envelopes</h3><p>You have a number of envelopes with widths and heights given as a pair of integers <code>(w, h)</code>. One envelope can fit into another if and only if both the width and height of one envelope is greater than the width and height of the other envelope.</p><p>What is the maximum number of envelopes can you Russian doll? (put one inside other)</p><p><strong>Example:</strong>Given envelopes = <code>[[5,4],[6,4],[6,7],[2,3]]</code>, the maximum number of envelopes you can Russian doll is <code>3</code> ([2,3] =&gt; [5,4] =&gt; [6,7]).</p><p>思路类似最长上升子序列</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxEnvelopes</span><span class="params">(<span class="built_in">vector</span>&lt;pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;&amp; envelopes)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = envelopes.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        sort(envelopes.begin(), envelopes.end());</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(n, <span class="number">0</span>);</div><div class="line">        dp[<span class="number">0</span>] = <span class="number">1</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++) &#123;</div><div class="line">            dp[i] = <span class="number">1</span>;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (envelopes[j].first &lt; envelopes[i].first &amp;&amp; envelopes[j].second &lt; envelopes[i].second)</div><div class="line">                    dp[i] = max(dp[i], dp[j]+<span class="number">1</span>);</div><div class="line">            &#125;</div><div class="line">           <span class="comment">// cout &lt;&lt; dp[i] &lt;&lt; endl;</span></div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> ret = <span class="number">1</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            ret = max(ret, dp[i]);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> ret;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">maxEnvelopes</span><span class="params">(<span class="built_in">vector</span>&lt;pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;&amp; envelopes)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = envelopes.size();</div><div class="line">        <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        sort(envelopes.begin(), envelopes.end(), [](pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&amp; p1, pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&amp; p2)&#123;</div><div class="line">            <span class="keyword">return</span> p1.first == p2.first ? p1.second &gt; p2.second : p1.first &lt; p2.first; <span class="comment">//当first相同时，second按大到小排序避免冲突！！！</span></div><div class="line">        &#125;);</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">int</span> l = lower_bound(dp.begin(), dp.end(), envelopes[i].second) - dp.begin();</div><div class="line">            <span class="keyword">if</span> (l == dp.size()) &#123;</div><div class="line">                dp.push_back(envelopes[i].second);</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                dp[l] = envelopes[i].second;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp.size();</div><div class="line">      </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>140. Word Break II</h3><p>Given a <strong>non-empty</strong> string <em>s</em> and a dictionary <em>wordDict</em> containing a list of <strong>non-empty</strong> words, add spaces in <em>s</em> to construct a sentence where each word is a valid dictionary word. Return all such possible sentences.</p><p><strong>Note:</strong></p><ul><li>The same word in the dictionary may be reused multiple times in the segmentation.</li><li>You may assume the dictionary does not contain duplicate words.</li></ul><p><strong>Example 1:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">s = &quot;catsanddog&quot;</div><div class="line">wordDict = [&quot;cat&quot;, &quot;cats&quot;, &quot;and&quot;, &quot;sand&quot;, &quot;dog&quot;]</div><div class="line">Output:</div><div class="line">[</div><div class="line">  &quot;cats and dog&quot;,</div><div class="line">  &quot;cat sand dog&quot;</div><div class="line">]</div></pre></td></tr></table></figure></p><p><strong>Example 2:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">s = &quot;pineapplepenapple&quot;</div><div class="line">wordDict = [&quot;apple&quot;, &quot;pen&quot;, &quot;applepen&quot;, &quot;pine&quot;, &quot;pineapple&quot;]</div><div class="line">Output:</div><div class="line">[</div><div class="line">  &quot;pine apple pen apple&quot;,</div><div class="line">  &quot;pineapple pen apple&quot;,</div><div class="line">  &quot;pine applepen apple&quot;</div><div class="line">]</div><div class="line">Explanation: Note that you are allowed to reuse a dictionary word.</div></pre></td></tr></table></figure></p><p><strong>Example 3:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">s = &quot;catsandog&quot;</div><div class="line">wordDict = [&quot;cats&quot;, &quot;dog&quot;, &quot;sand&quot;, &quot;and&quot;, &quot;cat&quot;]</div><div class="line">Output:</div><div class="line">[]</div></pre></td></tr></table></figure></p><p>预处理</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; wordBreak(<span class="built_in">string</span> s, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; wordDict) &#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; ret;</div><div class="line">        </div><div class="line">        <span class="built_in">unordered_map</span>&lt;<span class="built_in">string</span>, <span class="keyword">bool</span>&gt; dict;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> word: wordDict) &#123;</div><div class="line">            dict[word] = <span class="literal">true</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">int</span> n = s.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; pre(n+<span class="number">1</span>);</div><div class="line">        pre[<span class="number">0</span>].push_back(<span class="number">-1</span>);</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</div><div class="line">                <span class="built_in">string</span> substr = s.substr(j, i-j);</div><div class="line">                <span class="keyword">if</span> (dict[substr] &amp;&amp; pre[j].size() != <span class="number">0</span>) &#123;</div><div class="line">                    pre[i].push_back(j);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt; cur;</div><div class="line">        dfs(cur, n, ret, pre, s);</div><div class="line">        <span class="keyword">return</span> ret;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp;cur, <span class="keyword">int</span> idx, <span class="built_in">vector</span>&lt;<span class="built_in">string</span>&gt;&amp; ret, <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&amp; pre, <span class="built_in">string</span>&amp; s)</span> </span>&#123;</div><div class="line">        <span class="keyword">if</span> (idx == <span class="number">0</span>) &#123;</div><div class="line">            <span class="built_in">string</span> str;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = cur.size()<span class="number">-1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</div><div class="line">                <span class="keyword">if</span> (i != cur.size()<span class="number">-1</span>) str += <span class="string">" "</span>;</div><div class="line">                str += cur[i];</div><div class="line">            &#125;</div><div class="line">            ret.push_back(str);</div><div class="line">            <span class="keyword">return</span>;</div><div class="line">        &#125; </div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> t: pre[idx]) &#123;</div><div class="line">            cur.push_back(s.substr(t, idx-t));</div><div class="line">            dfs(cur, t, ret, pre, s);</div><div class="line">            cur.pop_back();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>410. Split Array Largest Sum</h3><p>Given an array which consists of non-negative integers and an integer <em>m</em>, you can split the array into <em>m</em> non-empty continuous subarrays. Write an algorithm to minimize the largest sum among these <em>m</em> subarrays.</p><p><strong>Note:</strong>If <em>n</em> is the length of array, assume the following constraints are satisfied:</p><ul><li>1 ≤ <em>n</em> ≤ 1000</li><li>1 ≤ <em>m</em> ≤ min(50, <em>n</em>)</li></ul><p><strong>Examples:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">Input:</div><div class="line">nums = [7,2,5,10,8]</div><div class="line">m = 2</div><div class="line"></div><div class="line">Output:</div><div class="line">18</div><div class="line"></div><div class="line">Explanation:</div><div class="line">There are four ways to split nums into two subarrays.</div><div class="line">The best way is to split it into [7,2,5] and [10,8],</div><div class="line">where the largest sum among the two subarrays is only 18.</div></pre></td></tr></table></figure></p><p>二分,贪心</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> ll;</div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">splitArray</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> m)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = nums.size();</div><div class="line">        ll s = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            s += nums[i];</div><div class="line">        &#125;</div><div class="line">        ll l = <span class="number">0</span>, r = s;</div><div class="line">       <span class="keyword">while</span> (l &lt;= r) &#123;</div><div class="line">            ll mid = (l+r) / <span class="number">2</span>;</div><div class="line">            <span class="keyword">if</span> (!check(mid, nums, m)) &#123;</div><div class="line">                l = mid + <span class="number">1</span>;</div><div class="line">            &#125;</div><div class="line">            <span class="keyword">else</span> &#123;</div><div class="line">                r = mid - <span class="number">1</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> l;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">check</span><span class="params">(ll x, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> m)</span> </span>&#123;</div><div class="line">        </div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.size(); i++) &#123;</div><div class="line">            <span class="keyword">int</span> j = i<span class="number">-1</span>;</div><div class="line">            ll s = <span class="number">0</span>;</div><div class="line">            <span class="keyword">while</span>(j+<span class="number">1</span> &lt; nums.size() &amp;&amp; s+nums[j+<span class="number">1</span>] &lt;= x) s += nums[j+<span class="number">1</span>], ++j;</div><div class="line">            <span class="keyword">if</span> (j &lt; i) <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">            --m;</div><div class="line">            i = j;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span> (m &gt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>818. Race Car</h3><p>Your car starts at position 0 and speed +1 on an infinite number line.  (Your car can go into negative positions.)</p><p>Your car drives automatically according to a sequence of instructions A (accelerate) and R (reverse).</p><p>When you get an instruction &quot;A&quot;, your car does the following: <code>position += speed, speed *= 2</code>.</p><p>When you get an instruction &quot;R&quot;, your car does the following: if your speed is positive then <code>speed = -1</code> , otherwise <code>speed = 1</code>.  (Your position stays the same.)</p><p>For example, after commands &quot;AAR&quot;, your car goes to positions 0-&gt;1-&gt;3-&gt;3, and your speed goes to 1-&gt;2-&gt;4-&gt;-1.</p><p>Now for some target position, say the <strong>length</strong> of the shortest sequence of instructions to get there.</p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Example 1:</div><div class="line">Input: </div><div class="line">target = 3</div><div class="line">Output: 2</div><div class="line">Explanation: </div><div class="line">The shortest instruction sequence is &quot;AA&quot;.</div><div class="line">Your position goes from 0-&gt;1-&gt;3.</div></pre></td></tr></table></figure></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">Example 2:</div><div class="line">Input: </div><div class="line">target = 6</div><div class="line">Output: 5</div><div class="line">Explanation: </div><div class="line">The shortest instruction sequence is &quot;AAARA&quot;.</div><div class="line">Your position goes from 0-&gt;1-&gt;3-&gt;7-&gt;7-&gt;6.</div></pre></td></tr></table></figure></p><p><strong>Note:</strong></p><ul><li><code>1 &lt;= target &lt;= 10000</code>.</li></ul><p>贪心，选择合适的策略，没到，回去或超过再回去</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">racecar</span><span class="params">(<span class="keyword">int</span> target)</span> </span>&#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(target+<span class="number">1</span>, <span class="number">-1</span>);</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> dfs(target, dp);</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> target, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; dp)</span> </span>&#123;</div><div class="line">        </div><div class="line">        <span class="keyword">if</span> (target == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="keyword">if</span> (dp[target] != <span class="number">-1</span>) <span class="keyword">return</span> dp[target];</div><div class="line">        </div><div class="line">        <span class="keyword">int</span> t = <span class="built_in">floor</span>(log2(target+<span class="number">1</span>));</div><div class="line">        <span class="comment">//cout &lt;&lt; target &lt;&lt;" " &lt;&lt; t &lt;&lt; endl;</span></div><div class="line">        <span class="keyword">if</span> (<span class="number">1</span>&lt;&lt;t == target+<span class="number">1</span>) <span class="keyword">return</span> dp[target] = t;</div><div class="line">        <span class="keyword">int</span> ret = dfs((<span class="number">1</span>&lt;&lt;(t+<span class="number">1</span>))<span class="number">-1</span>-target, dp) + t + <span class="number">2</span>; <span class="comment">//forward excess target then backward t+1 + 1(reverse)</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; t; i++) &#123;</div><div class="line">            ret = min(ret, dfs(target - (<span class="number">1</span>&lt;&lt;t) + (<span class="number">1</span>&lt;&lt;i), dp) + t + i + <span class="number">2</span>); <span class="comment">//forward n then backward m (reverse twice)</span></div><div class="line">        &#125;</div><div class="line">        </div><div class="line">        <span class="keyword">return</span> dp[target] = ret;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p><h3>132. Palindrome Partitioning II</h3><p>Given a string <em>s</em>, partition <em>s</em> such that every substring of the partition is a palindrome.</p><p>Return the minimum cuts needed for a palindrome partitioning of <em>s</em>.</p><p><strong>Example:</strong></p><p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Input: &quot;aab&quot;</div><div class="line">Output: 1</div><div class="line">Explanation: The palindrome partitioning [&quot;aa&quot;,&quot;b&quot;] could be produced using 1 cut.</div></pre></td></tr></table></figure></p><p>预处理</p><p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">judge_palindrom</span><span class="params">(<span class="built_in">string</span>&amp;s, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</div><div class="line">        <span class="keyword">while</span> (i &lt; j) &#123;</div><div class="line">            <span class="keyword">if</span> (s[i] != s[j]) <span class="keyword">return</span> <span class="literal">false</span>;</div><div class="line">            i++;</div><div class="line">            j--;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">minCut</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</div><div class="line">        <span class="keyword">int</span> n = s.size();</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; palindrom(n);</div><div class="line">        <span class="comment">//vector&lt;vector&lt;bool&gt;&gt; isPalindrom(n, vector&lt;bool&gt;(n, false));</span></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= i; j++) &#123;</div><div class="line">                <span class="keyword">if</span> (judge_palindrom(s, j, i)) &#123;</div><div class="line">                    palindrom[i].push_back(j);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; dp(n, <span class="number">1e9</span>);</div><div class="line">        dp[<span class="number">0</span>] = <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</div><div class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; palindrom[i].size(); j++) &#123;</div><div class="line">                <span class="keyword">int</span> idx = palindrom[i][j];</div><div class="line">                <span class="keyword">if</span> (idx == <span class="number">0</span>) &#123;</div><div class="line">                    dp[i] = <span class="number">1</span>;</div><div class="line">                &#125;</div><div class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (dp[idx<span class="number">-1</span>] != <span class="number">1e9</span> &amp;&amp; dp[i] &gt; dp[idx<span class="number">-1</span>]+<span class="number">1</span>) &#123;</div><div class="line">                    dp[i] = dp[idx<span class="number">-1</span>] + <span class="number">1</span>;</div><div class="line">                &#125; </div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> dp[n<span class="number">-1</span>] - <span class="number">1</span>;</div><div class="line">        </div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;###72. Edit Distance&lt;/p&gt;
&lt;p&gt;Given two words word1 and word2, find the minimum number of operations required to convert word1
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="Leetcode" scheme="http://wulimengmeng.top/tags/Leetcode/"/>
    
      <category term="DP" scheme="http://wulimengmeng.top/tags/DP/"/>
    
  </entry>
  
  <entry>
    <title>感受野的计算及延伸</title>
    <link href="http://wulimengmeng.top/2018/05/15/%E6%84%9F%E5%8F%97%E9%87%8E%E7%9A%84%E8%AE%A1%E7%AE%97%E5%8F%8A%E5%BB%B6%E4%BC%B8/"/>
    <id>http://wulimengmeng.top/2018/05/15/感受野的计算及延伸/</id>
    <published>2018-05-15T08:18:47.000Z</published>
    <updated>2018-05-15T11:45:46.956Z</updated>
    
    <content type="html"><![CDATA[<p>感受野(receptive field)的定义:</p><blockquote><p><em>The</em> <strong>receptive field</strong> <em>is defined as the region in the input space that a particular CNN’s feature is looking at (i.e. be affected by)</em></p></blockquote><p>当我们计算feature map的大小时，假设输入的大小为: $n\times n$，卷积的参数是k(kernel size), p(padding), s(stride)，我们将得到$\lfloor \frac{n+2<em>p-k}{s}\rfloor+1$，如果我们引入dilation这个参数(相当于连续</em>标准卷积<em>的堆叠的receptive field)，那么最终的大小是$\lfloor \frac{n+2</em>p-k-d*(k-1)}{s}\rfloor+1$，pooling的参数是k，s，那么输出就是$\lfloor \frac{n-k}{s}\rfloor+1$</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1frc4o653j2j30u00bi0u6.jpg" alt=""></p><p>为了简化计算，我们假设图像是正方形的，主要有几个式子：$$j_{out} = j_{in}\times s$$</p><p>$$r_{out} = r_{in} + (k-1)\times j_{in}$$</p><p>$$c_{out} = c_{in} + (\frac{k-1}{2}-p)\times j_{in}$$</p><p>第一个等式计算的是jump in the output feature map，s是stride，相当于做完降采样以后，作用域进行了放大（感受野进行了放大，之后每次感受野的增加都需要乘上相应的倍数(jump的数量)），第二个等式计算的是receptive field，k是kernel size（如果没有放大倍数，那么就是按照kernel的大小的进行扩展，如果有倍数的话就乘以相应的倍数，因为这里的一个像素等于原图的jump数个像素）第三个式子计算的是receptive field的中心。那么如果考虑到dialated conv，那么对于receptive field的计算就变成了：$$r_{out} = r_{in} + (k-1+(k-1)\times (d-1))\times j_{in} = r_{in} + ((k-1)\times d)\times j_{in}$$</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;感受野(receptive field)的定义:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The&lt;/em&gt; &lt;strong&gt;receptive field&lt;/strong&gt; &lt;em&gt;is defined as the region in the input spac
      
    
    </summary>
    
    
      <category term="notes" scheme="http://wulimengmeng.top/tags/notes/"/>
    
      <category term="computer vision" scheme="http://wulimengmeng.top/tags/computer-vision/"/>
    
  </entry>
  
  <entry>
    <title>正则化的理解</title>
    <link href="http://wulimengmeng.top/2018/05/07/%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://wulimengmeng.top/2018/05/07/正则化的理解/</id>
    <published>2018-05-07T06:57:45.000Z</published>
    <updated>2018-05-09T07:53:48.281Z</updated>
    
    <content type="html"><![CDATA[<p>本文主要介绍一些正则化方法降低模型复杂度的原理（目的是防止过拟合，通过约束参数达到），主要是对l1正则和l2正则的原理进行思考。</p><p>这里先对优化问题进行简要介绍，主要有三种最优化问题（凸优化）：</p><ol><li>无约束的优化问题：就是没有任何约束条件，直接求导求极值点即可</li><li>有等式约束的优化问题：</li></ol><p>$$\min f(X) \ s.t. g(x) = 0$$</p><p>通常使用拉格朗日乘子法就行求解，转换成$L(\lambda, x) = f(x) + \lambda g(x)$，分别对x和$\lambda$求偏导，得到极值点集合，然后再验证</p><ol start="3"><li>有不等式约束的优化问题：</li></ol><p>$$\min f(X) \ s.t. g(x) = 0, h(x)  \le 0$$</p><p>f和h为凸函数，g是仿射函数，常用解法还是利用拉格朗日乘子法，即转化成$L(\lambda,\mu,x) = f(x) + \lambda g(x)+ \mu h(x)$，利用其最优化的KKT条件：</p><ul><li>$L(\lambda, \mu, x)$对变量的导数为0</li><li>g(x) = 0</li><li>$\mu h(x)=0$</li></ul><p>以简单的线性回归为例，将$E_D(w)$表示为data-dependent error，$E_w(w)$表示为regularization term，所以整个的error可以表示为：$$\frac{1}{2}\sum_{n=1}^N{t_n-w^T\phi(x_n)}^2+\frac{\lambda}{2}\sum_{j=1}^M|w_j|^q$$<img src="https://ws4.sinaimg.cn/large/006tNc79ly1fr52eorbknj31kw0jradg.jpg" alt=""></p><p>我们可以把上式写成一般的形式：$$J(w) = f(w) + \lambda h(w)$$也可以还原成有等式约束的形式：$$\min f(w) \ s.t. \lambda h(w) \le c$$特定的regularizer也叫做weight decay，顾名思义，就是会让参数向0作decay（变相地降低模型复杂度），q=1时，也叫做lasso，q=2时，叫做ridge。这里还需要解释一个问题：为什么q=1时，很容易出现参数为0的情况，也就是经常会得到稀疏解（和l2相比更容易得到稀疏解而不是一定会得到稀疏解），下图可以解释：</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fr51ndkgxjj313a0qegou.jpg" alt=""></p><p>对于l1正则来说，就图中的例子来说，<strong><em>边界</em></strong>可以转化成$w_1+w_2=\frac{c}{\lambda}$，在图中就是一个菱形，而l2正则则可以转化为$w_1^2+w_2^2=\frac{c}{\lambda}$的<strong><em>边界</em></strong>，在图中则是一个圆形。而损失函数图像是圆形（大部分情况是椭圆形），使得菱形和圆形更容易相较于坐标轴上！<strong><em>随着惩罚项$\lambda$增大，菱形和圆形的面积会越来越小，所以求得参数也越来越小！起到降低模型复杂度的效果！</em></strong></p><h5>prior</h5><p>对于bayesian view来说，通过最大化后验概率得到：$$w^* = \arg\max_w p(w|D) = \arg\max_w\frac{p(D|w)*p(w)}{p(D)} = \arg\max_w p(D|w) * p(w)$$其中p(D|w)是似然函数，表示在w条件下数据D出现的概率，p(w)是参数的先验函数。</p><p>对于似然函数，我们假设数据之间都是i.i.d，那么我们有:$$p(D|w) = \prod_{k=1}^np(D_i|w)$$对最大后验概率去log：$$\arg\max_w p(D|w)*p(w) =\prod_{k=1}^np(D_i|w)p(w) = \log\prod_{k=1}^np(D_i|w)p(w) = \arg\min_w -\sum_{k=0}^n \log p(D|w) - \log p(w)$$当假设w服从高斯分布，那么经过转化以后就变成了l2正则，当假设w服从拉普拉斯分布，就可以转换成l1正则。</p><p>下图是拉普拉斯分布，可以发现，拉普拉斯分布在0值附近非常突出，而高斯分布更加平缓，所以拉普拉斯更倾向于产生稀疏解，而高斯分布对权值大的惩罚更大（从几何图形也可以看出）</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fr5382j3pqj311y0t23zb.jpg" alt=""></p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fr535b1edsj31040r3gp3.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文主要介绍一些正则化方法降低模型复杂度的原理（目的是防止过拟合，通过约束参数达到），主要是对l1正则和l2正则的原理进行思考。&lt;/p&gt;
&lt;p&gt;这里先对优化问题进行简要介绍，主要有三种最优化问题（凸优化）：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;无约束的优化问题：就是没有任何约束条件，
      
    
    </summary>
    
    
      <category term="notes" scheme="http://wulimengmeng.top/tags/notes/"/>
    
      <category term="machine learning" scheme="http://wulimengmeng.top/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>R-FCN笔记</title>
    <link href="http://wulimengmeng.top/2018/05/02/R-FCN%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/05/02/R-FCN笔记/</id>
    <published>2018-05-02T04:58:00.000Z</published>
    <updated>2018-05-07T08:05:12.699Z</updated>
    
    <content type="html"><![CDATA[<p>论文：R-FCN: Object Detection via Region-based Fully Convolutional Networks，<strong>NIPS</strong> 2017</p><p>作者：Jifeng Dai, Yi Li, Kaiming He, Jian Sun</p><p>链接：https://arxiv.org/pdf/1605.06409.pdf</p><p>代码：https://github.com/daijifeng001/r-fcn</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fr2thjx8v0j31ce0oa0zb.jpg" alt=""></p><p><strong>objective:</strong> address a dilemma between translation-invariance in image classification and translation-variance in object detection</p><p><strong>solution:</strong> position-sensitive score maps</p><ul><li>83.6% mAP on the 2007 set, 82.0% the 2012 set</li><li>a test-time speed of 170ms per image, 2.5-20× faster than the Faster R-CNN counterpart</li></ul><h5>Architecture</h5><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2ttte6q5j30wo0vy1kx.jpg" alt=""></p><p>模型的backbone是ResNet-101，并将最后的fc层改成1024d的1x1的conv layer。</p><p>在image classification中，网络需要较好的translation invariance，但是在detection中，因为需要准确地定位object的位置，这需要网络具有定位的representation，有一定的translation-variant，例如在candidate box中，网络最好能够对在box中的object的一些translation，例如旋转，平移等有一定的响应。所以为了引入translation invariance，作者提出了Region-based Fully Convolutional Network (R-FCN)。</p><p>R-FCN通过构造position-sensitive的score map，每个score map都会对object的相对空间信息进行编码（encode），例如在object的左边还是右边。</p><p>对于最后一层的conv layer，它会输出每个类别的$k^2$个position-sensitive score maps，所以一共有$k^2(C+1)$个channel，$k^2$个score maps分别对应$k\times k$的格子，例如k=3，就可以对相对位置进行了编码：{top-left, top-center, top-right, ..., bottom-right}，然后再用一个position-sensitive ROI pooling进行信息的整合，文中的做法就是相加</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2sgoe0jtj31cc0omth7.jpg" alt=""></p><h5>Experiments</h5><p>Table 2是与其他模型的比较，对于R-FCN来说，去k=7要优于k=3</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2tw517esj313u0dadij.jpg" alt=""></p><p>Table 3是R-FCN和faster r-cnn在训练和测试的效率比较，可以发现R-FCN的效率要高于Faster r-cnn，同时准确率也要高于faster r-cnn。</p><p>Table 4-6是R-FCN和其他模型在PASCAL VOC2007，PASCAL VOC2012，COCO数据集上的比较</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fr2u19dx60j30zg0twdne.jpg" alt=""></p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fr2u6dkj5nj30xm0bkn08.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：R-FCN: Object Detection via Region-based Fully Convolutional Networks，&lt;strong&gt;NIPS&lt;/strong&gt; 2017&lt;/p&gt;
&lt;p&gt;作者：Jifeng Dai, Yi Li, Kaiming 
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>FPN论文笔记</title>
    <link href="http://wulimengmeng.top/2018/04/21/FPN%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/04/21/FPN论文笔记/</id>
    <published>2018-04-21T03:50:20.000Z</published>
    <updated>2018-04-24T07:04:44.351Z</updated>
    
    <content type="html"><![CDATA[<p>论文：Feature Pyramid Networks for Object Detection，<strong>CVPR</strong> 2017</p><p>作者：Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie</p><p>链接：https://arxiv.org/pdf/1612.03144.pdf</p><p>代码(unofficial)：https://github.com/unsky/FPN</p><ul><li>feature pyramid在物体识别中比较常用，作者将其应用到object detection中</li><li>不同于SSD，作者使用top-down的结构将来自更高pyramid level的semantically stronger的feature map和higher resolution features相结合，使得detection的结构更加准确</li></ul><p>Figure 1是不同类型的feature map的使用方法，作者使用的是(d)的结构，SSD使用的是(c)的结构</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqnpdczxhuj30w20usgvn.jpg" alt=""></p><h5>Feature Pyramid Networks</h5><p>Figure 3是top-down pathway的示意结构，现将来自higher pyramid的feature maps升采样，再将该层的feature map做1x1的conv，减少channel dimension（固定为256d），再用element-wise addtion做merge，然后再用3x3的conv去消除上采样aliasing的影响。在C5上（最高层），先用1x1 conv产生粗糙的特征图。</p><p>${C2, C3, C4, C5}$层对应的融合特征层为${P2, P3, P4, P5}$</p><p>通过这样的操作来加强特征，即<strong>保留空间信息并增强语义信息</strong>。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqnpkyj02ej30tk0jcn00.jpg" alt=""></p><h5>Applications</h5><p><strong>Feature Pyramid Networks for RPN</strong></p><p>RPN的参数配置和Faster R-CNN类似，作者提到了一点就是在feature pyramid的detection head参数是可以共享的，结果和不共享接近，这说明了<strong>不同level的pyramid的semantic level是相似的</strong>！</p><p><strong>Feature Pyramid Networks for Fast R-CNN</strong></p><p>这里的重点是ROI的分配：</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqnqq1o4irj30m2034dg3.jpg" alt=""></p><p>w,h是ROI的宽和高，$k_0$=4，表示的是大小为224x224的ROI的target level，利用这个式子进行转换，分配到相应的pyramid level。</p><h5>Experiments</h5><p><strong>Ablation Study</strong></p><p>Table 1，2，3是ablation study的表格</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fqnqwou2qwj315g0uc7ef.jpg" alt=""></p><p>Table 4是单模型在COCO detection benchmark上的表现，FPN取得SOTA的表现</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqnr7se6qpj31kw0iatgv.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：Feature Pyramid Networks for Object Detection，&lt;strong&gt;CVPR&lt;/strong&gt; 2017&lt;/p&gt;
&lt;p&gt;作者：Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>RON论文笔记</title>
    <link href="http://wulimengmeng.top/2018/04/21/RON%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/04/21/RON论文笔记/</id>
    <published>2018-04-21T03:50:01.000Z</published>
    <updated>2018-04-23T07:44:01.506Z</updated>
    
    <content type="html"><![CDATA[<p>论文：RON: Reverse Connection with Objectness Prior Networks for Object Detection，<strong>CVPR</strong> 2017</p><p>作者：Tao Kong，Fuchun Sun，Anbang Yao，Huaping Liu，Ming Lu，Yurong Chen</p><p>链接：https://arxiv.org/pdf/1707.01691.pdf</p><p>代码：https://github.com/taokong/RON</p><p><strong>objective：</strong></p><ul><li>bridge the gap between the region-based and region-free methodologies</li></ul><p><strong>solution</strong>：</p><ul><li>Multi-scale object localization，利用多个scale的feature map做detection<ul><li>建立reverse connection，为前面的层提供highly semantic的information</li></ul></li><li>Negative space mining<ul><li>通过建立objectness prior减少objects的搜索空间</li></ul></li></ul><p>384x384的输入，PASCAL VOC 2007 81.3% mAP，PASCAL VOC 2012 80.7% mAP，COCO 27.4%</p><p>效率较高，1.5G的 GPU内存，forward的速度是15FPS</p><p>Figure 2是RON的网络模型，有4个scales feature map做detection。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqk5dydd50j30t20tcqde.jpg" alt=""></p><h5>Architecture</h5><p>网络以VGG 16为backbone，将FC6和FC7改造为conv layer，在FC7处降采样。</p><p>所以每个用于detection的feature map大小为：1/8 (conv 4 3), 1/16 (conv 5 3), 1/32 (conv 6) and 1/64 (conv 7)</p><p><strong>Reverse Connection</strong></p><p>reverse connection的结构见Figure 3，将后一层的输出经过deconv做upsampling，deconv的通道是512，当前层经过conv，再用summation的方式做merge。</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqk5exvqeej30io0g6my5.jpg" alt=""></p><p><strong>Reference Boxes</strong></p><p>不同层的网络对应不同的receptive field，所以需要设计对应层的ref box的scale和ratio，下面是scale的设计：</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqmjznn3cij30rc02umxf.jpg" alt=""></p><p>这里$s_{min}$设为$\frac{1}{10}$,不同的对应ratios是${\frac{1}{3},\frac{1}{2}, 1, 2, 3}$</p><p><strong>Objectness Prior</strong></p><p>针对正负样本比例严重失调， 这里使用 Objectness Prior 来过滤大部分负样本，具体的做法就是利用conv通道的设计，因为每个cell有10个default boxes，所以通道数是10，然后就是做二分类。这里需要设定阈值，将objectness score大于$o_p$的选为样本，这里$o_p$设为0.03，可以过滤掉大部分的样本。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqmmemlca0j30s00fwduh.jpg" alt=""></p><p><strong>Detection and Bounding Box Regression</strong></p><p>Figure 5是detection bbox reg head的结构，可以发现在分类的module中，作者加入了两个inception module来提高分类的精度</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqk5fg7sxbj30tg0dimz5.jpg" alt=""></p><h5>Training</h5><p><strong>Loss</strong></p><p>相似的，也是multi-task loss</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqmmnkgq8jj30so04igm3.jpg" alt=""></p><h5>Experiments</h5><p>Table 1-3是模型在PASCAL VOC 2007, 2012和COCO上的结果。</p><ul><li>可以发现RON对小物体的检测提升比较明显，例如boat和bottle。</li></ul><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqmmqfxmthj31ko0dqq9a.jpg" alt=""></p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqmmraplo7j31kw0g2gt8.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqmmvqkb0xj30tg0hydjk.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：RON: Reverse Connection with Objectness Prior Networks for Object Detection，&lt;strong&gt;CVPR&lt;/strong&gt; 2017&lt;/p&gt;
&lt;p&gt;作者：Tao Kong，Fuchun Sun，A
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>OHEM算法笔记</title>
    <link href="http://wulimengmeng.top/2018/04/18/OHEM%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/04/18/OHEM算法笔记/</id>
    <published>2018-04-18T07:43:38.000Z</published>
    <updated>2018-04-18T12:45:28.778Z</updated>
    
    <content type="html"><![CDATA[<p>论文：Training Region-based Object Detectors with Online Hard Example Mining，<strong>CVPR</strong> 2016</p><p>作者：Abhinav Shrivastava, Abhinav Gupta, Ross Girshick</p><p>链接：https://arxiv.org/pdf/1604.03540.pdf</p><p>代码：https://github.com/abhi2610/ohem</p><p>Hard example mining是机器学习模型训练经常会用的trick，顾名思义，就是sample目前对于模型比较难的example进行“强化”学习。在CNN中对于patch选择根据策略的不同，主要有sliding window和proposal。大部分的情况是根据loss来判断是否是hard，只是作为训练的一个trick。文章针对Fast R-CNN，提出online hard example mining的算法对其进行优化。在VOC2007, 2012都取得了SOTA，mAP分别是78.9%，76.3%。</p><h5>Fast R-CNN</h5><p>FRCNN中，proposal的选择由它与gt的overlap决定，确定一个proposal为背景的阈值范围是：$[bg_{lo},0.5]$，这个范围的假设是这样的proposal是hard的可能性较大。作者认为这样得到的结果很可能是次优的，因为在其他位置可能存在更hard但是infrequent的样本，OHEM算法中移除了这个阈值</p><h5>OHEM</h5><p>idea很简单，就是在forward的时候根据loss排序，然后选择loss最大的，也就是最worst的样本进行backward更新模型的参数。但是这样会存在一个问题，就是当两个ROI位置相近的时候，在feature map上对应的是同一个位置，loss是相近的，所以作者提出了对hard examples做NMS，选择B/N个ROI最backward，这里NMS的阈值为0.7。</p><p>接下来就是工程上的优化，ROI进行backward的时候，空间和时间的消耗较大，如果直接做backward，那些没有选中的ROI还是会做backward，所以作者提出了Figure 2的网络结构，包含两个一样的的ROI network，其中一个是immutable的，用于计算forward的loss，只有在forward的时候分配内存，然后hard RoI sampling module使用刚才所说的方法进行采样，作为输入传到第二个ROI network，进行forward和backward，然后累积gradient，再backward。</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgutzexflj31kw0v41kx.jpg" alt=""></p><h5>Experiments</h5><p>Table 3和Table 4是模型在VOC 2007和VOC 2012的表现，都是SOTA，对FRCN提升明显。</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqh3cawf16j31600radsm.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：Training Region-based Object Detectors with Online Hard Example Mining，&lt;strong&gt;CVPR&lt;/strong&gt; 2016&lt;/p&gt;
&lt;p&gt;作者：Abhinav Shrivastava, Abhin
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>SSD笔记</title>
    <link href="http://wulimengmeng.top/2018/04/11/SSD%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/04/11/SSD笔记/</id>
    <published>2018-04-11T05:10:28.000Z</published>
    <updated>2018-04-18T12:49:38.684Z</updated>
    
    <content type="html"><![CDATA[<p>论文：SSD: Single Shot MultiBox Detector，<strong>ECCV</strong> 2016</p><p>作者：Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg</p><p>链接：https://arxiv.org/pdf/1512.02325.pdf</p><p>代码：https://github.com/weiliu89/caffe/tree/ssd</p><p>gluon实现：https://github.com/mowayao/gluon_SSD</p><ul><li>将bbox的输出空间离散化到一些默认的priors，也就是默认设定的anchors</li><li>不同Faster R-CNN的two stage的方式，SSD采用的是one shot的方法，精度和faster r-cnn接近，但是效率更高</li><li>将多尺度的feature maps应用到detection中，针对不同尺度的feature map，采用不同scale和ratio</li></ul><p>#####The Single Shot Detector (SSD)</p><p>将feature map分成nxn的cells，每个cell可以预测固定数量的box的conf和offset</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fqfue2u6o9j316a0taww0.jpg" alt=""></p><p><strong>Model</strong></p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgroawjivj315i0r0dnf.jpg" alt=""></p><p>模型是基于pretrained的VGG-16进行修改和fine-tune</p><ul><li>Multi-scale feature map for detection: 在base net后加了conv feature layers用来做detection，这些layer使得feature maps的size逐渐降低，这样就可以做多尺度的预测</li><li>Convolutional predictors for detection：在添加的conv feature layer后加入输出层，即conv predictor，生成固定大小的输出，对于mxn，p个channel的feature map，使用3x3xp的卷积核，预测conf和loc。</li><li>Default boxes and aspect ratios：每个cell预测k个boxes，以及类别的数量是c，那么最后的输出channel则是(c+4)*k</li></ul><p><strong>Training</strong></p><ul><li>Matching strategy: 需要将default boxes做划分，将与gt与box的jaccard overlap大于0.5的定为gt，其他定为background</li><li>Training objective:</li></ul><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fqgqb60zbdj30wo040q3a.jpg" alt=""></p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqgqb6a4gij30zg09wmyu.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgqb74a9zj315c04mdgq.jpg" alt=""></p><ul><li>Choosing scales and aspect ratios for default boxes: 为了针对不同scale的object，scale被定义为：</li></ul><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fqgrc1164dj30wa03q3yw.jpg" alt=""></p><p>$s_{min}=0.2, s_{max}=0.9,$ratios $a_r\in {1,2,3,\frac{1}{2}, \frac{1}{3}}$，$w_k=s_k\sqrt a_r, h_k=s_k/\sqrt a_r$。另外对于 ratio = 1 的情况，再指定 scale 为$，s_k=\sqrt {s_ks_{k+1}}$也就是总共有 6 种不同的 default box</p><ul><li>Hard negative mining: 在做完matching后，大部分的box都是背景，所以需要做采样，选择loss最高的几个，并且保持3:1的比例</li><li>Data augmentation：<ul><li>使用全图作为输入，</li><li>使用IOU和目标物体为0.1, 0.3，0.5, 0.7, 0.9的patch （这些 patch 在原图的大小的 $[0.1,1]$ 之间， 相应的宽高比在$[1/2,2]$之间）</li><li>随机采取一个patch</li></ul></li></ul><h5>Experimental Results</h5><p>Table 1是SSD在PASCAL VOC2007上的表现，可以发现SSD512的表现优于Faster R-CNN，SSD300兼顾性能和效率</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgqghdz3lj31600k2wo1.jpg" alt=""></p><p>Table 4是SSD在 PASCAL VOC2012上的表现，可以发现SSD512取得了SOTA的表现</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgrepc7k2j316w0es7b4.jpg" alt=""></p><p>Table 5是在COCO上的表现，同样是SOTA</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fqgreqfglbj316i0dwtd9.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：SSD: Single Shot MultiBox Detector，&lt;strong&gt;ECCV&lt;/strong&gt; 2016&lt;/p&gt;
&lt;p&gt;作者：Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, 
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>YOLO&amp;YOLOv2笔记</title>
    <link href="http://wulimengmeng.top/2018/04/07/YOLO&amp;YOLOv2%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/04/07/YOLO&amp;YOLOv2笔记/</id>
    <published>2018-04-07T08:02:37.000Z</published>
    <updated>2018-04-10T14:31:57.274Z</updated>
    
    <content type="html"><![CDATA[<h3>YOLO</h3><p>论文：You Only Look Once: Unified, Real-Time Object Detection，<strong>CVPR</strong> 2016</p><p>作者：Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi</p><p>链接：https://arxiv.org/pdf/1506.02640.pdf</p><p>代码：https://pjreddie.com/darknet/yolo/</p><ul><li>将detection的分类问题转化为回归问题</li><li>在VOC 2007上，达到45FPS，mAP 63.4%，Fast YOLO可以达到155FPS，mAP 52.7%</li><li>将整张图划分为7x7的网格，每个格子预测置信度score和坐标位置，5个输出</li><li>没有利用proposal（不同于SSD和fast r-cnn），对小目标不是很友好</li><li>使用全局的context信息，背景错误较少</li></ul><h5>Unified Detection</h5><p>首先将输入图像分成SxS块，每个grid cell预测B个bounding box和confidence scores，以及预测C类。这样网络最后一层的输出是SxSx(Bx5+C)的tensor。如果一个object的中心落在某个grid，那么这个grid就需要负责预测这个object。文中的参数S=7,B=2,C=20。所以最后的输出的tensor大小为7x7x30。</p><p>confidence score的计算则是:$P(object)\times IOU_{pred}^{gt}$，第一项是表示是否落入grid，第二项则是预测的框和实际的框的IOU值。</p><p>loss function的设计为：</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7loi7sgqj30ro0hotao.jpg" alt=""></p><p>可以发现作者的一个trick，就是对于宽和长，做了开根号的处理，这样做的目的是当物体很小的时候相对于大物体有同等的差值，可以获得更大的loss。</p><p>网络结构Figure 3所示，启发于GoogLeNet，但是没有使用inception，而是使用1x1的conv，共有24个卷积层加2个全连接层，先在ImageNet上预训练。</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7l4n5bd5j31kw0pjtfl.jpg" alt=""></p><p><strong>Limitations of YOLO</strong></p><ol><li>对bounding box的预测做了较强的空间假设，每个grid只能预测两个boxes，并且只属于一类。这样就对小物体的预测非常不友好，特别是当一些小物体成群出现的时候。</li><li>在测试的时候，如果objects有不同的或者不寻常的比例的时候，泛化性会比较差</li><li>loss function的设计还需要再优化</li></ol><h5>Experiments</h5><p>Table 1是各个object detection实时系统的比较，可以发现Fast YOLO的速度非常高，同时保持较高的mAP。</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fq7mi5up9aj30v20su0yx.jpg" alt=""></p><p>Figure 4是Fast R-CNN和YOLO的错误组成对比，可以发现YOLO对于背景的预测较好，因为利用了全局的context，但是loc的错误较大，这和loss function的设计不无关系。</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7mknid1jj30t60mun1s.jpg" alt=""></p><h3>YOLO v2</h3><p>论文：YOLO9000: Better, Faster, Stronger Joseph，<strong>CVPR</strong> 2017</p><p>作者：Joseph Redmon, Ali Farhadi</p><p>链接：http://openaccess.thecvf.com/content_cvpr_2017/papers/Redmon_YOLO9000_Better_Faster_CVPR_2017_paper.pdf</p><p>代码：http://pjreddie.com/yolo9000/</p><h5>Better</h5><ul><li><p>Batch Normalization:在每个conv后加入bn，取消dropout，mAP提高了2%</p></li><li><p>High Resolution Classifie: pretrain的时候就把图像分辨率调高，从224x224变成448x448，提高了4%</p></li><li><p>Convolutional With Anchor Boxes: 吸收Faster R-CNN中RPN的思想，去掉全连接层，加入anchor boxes，这样导致acc略有下降，但是召回率提高较多</p></li><li><p>Dimension Clusters: 通过k-means选择较好的priors，也就是anchor，选择k=5作为复杂度和高召回率的折中，将distance metric定义为：</p></li><li><p>$$d(box, centroid) = 1-IOU(box, centroid)$$</p><p>在k=5的前提下，召回率和使用9个anchor box的相近</p></li><li><p>Direct location prediction: 对坐标进行转换，和fast r-cnn等类似，提升5%，见Figure 3</p></li><li><p>Fine-Grained Features: 为了得到奇数大小的feature maps，将图像分辨率调整到416，得到奇数大小的好处是改点就是这个区域的中心，然后调整降采样的步长为32，这样就是416/32=13，参考SSD和faster r-cnn利用多尺度的feature maps，作者提出passthrough layer，将high resolution features和low resolution features结合，对于high resolution的feature maps，将相邻的特征分配到不同的channels，例如26x26x512变换成13x13x2048，再和原来的特征图相连接，相当于把feature maps做深度的扩充，这样有1%的提升</p></li></ul><p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fq7upwxukoj30t60teadt.jpg" alt=""></p><ul><li>Multi-Scale Training: 每隔10个batches，随机选择一个scale，sclales有：320，352…,608。Table 3是不同尺度的结果，可以发现 544的最优！mAP达到78.6。在288x288的scale上，可以得到90FPS，同时mAP和Fast R-CNN一样</li></ul><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fq7vdy6vauj30ty0skjya.jpg" alt=""></p><p>Table 2是ablation studies的结果</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fq7vx9xa1aj31kw0nwjy5.jpg" alt=""></p><h5>Faster</h5><p>提出darknet-19，效率相较于VGG 16有了较大的提升。</p><p>VGG-16对于224x224的图像做一次forward，卷积层的浮点数计算为30.69 billion。而darknet-19的卷积层浮点数计算为8.52 billion，但是在分类的准确性上略有降低。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fq7x1hlp1vj30jm0pujve.jpg" alt=""></p><h5>Stronger</h5><p>这里作者提出了一个非常fancy的idea，WordNet，解决不同数据集之间label mutually exclusive的问题。WordNet通过构建hierarchical tree来简化问题，并且选择最短的到达root的路径，Figure 6为图示。利用有向图对条件概率计算进行优化，分层地计算概率，然后做出预测。</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fq7wy9z9kxj30pc0wkqaw.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3&gt;YOLO&lt;/h3&gt;
&lt;p&gt;论文：You Only Look Once: Unified, Real-Time Object Detection，&lt;strong&gt;CVPR&lt;/strong&gt; 2016&lt;/p&gt;
&lt;p&gt;作者：Joseph Redmon, Santosh Divv
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>Faster R-CNN笔记</title>
    <link href="http://wulimengmeng.top/2018/04/02/Faster-R-CNN%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/04/02/Faster-R-CNN笔记/</id>
    <published>2018-04-02T11:11:52.000Z</published>
    <updated>2018-04-06T11:11:46.297Z</updated>
    
    <content type="html"><![CDATA[<p>论文：Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks，TPAMI 2016</p><p>作者：Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun</p><p>链接：https://arxiv.org/pdf/1506.01497.pdf</p><p>代码：https://github.com/rbgirshick/py-faster-rcnn</p><ul><li>在Fast R-CNN的基础上进行优化，将Region Proposal Network（RPN）取代Selective Search，可以更加有效地检测object candidates，与Fast R-CNN共享参数，RPN的任务是预测物体的bbox和objectness score</li><li>在RPN的基础上，提出anchor的概念，每个anchor可以代表不同的scale和ratio，从而达到translation-invariant的效果</li></ul><p>Figure 2的Faster R-CNN的结构图，主要要经过3个步骤：</p><ol><li>输入图像进入CNNs，得到相应的feature maps</li><li>将feature maps输入到RPN中，得到region proposals</li><li>将region proposals输入到Fast R-CNN中，得到detection的结果</li></ol><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpyjflds95j30ny0tcq81.jpg" alt=""></p><h5>Architecture</h5><p><strong>RPN</strong></p><p>RPN的输入为任意形状的图像，输出是一堆proposals的坐标，以及对应的confidence score。为了生成一堆region proposals，对于nxn的feature maps来说，作者通过sliding window（其实也就是3x3的conv）将其映射到固定维度的特征空间，然后再对得到的特征向量做分类和回归（将全连接改造成1x1的卷积，可以接受任何大小的输入）。</p><p><strong>anchors</strong></p><p>对于每个滑动窗口来说，假设该窗口有k个对应的proposals。这样reg layer就有4k的输出，cls layer有2k个输出。Figure 3就是anchor的示例。anchor可以解释为sliding window的中心点，通过假设这个中心点来自不同原始区域池化得到，所以可以根据这个中心点(anchor)逆推得到这些区域坐标和种类。假设现在有3中scales和3种ratios，以及feature maps的大小是WxH，那么总共有9xWxH个anchors，也可以将其理解成先验的bounding box。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpynk5f034j31d40k8nle.jpg" alt=""></p><h5>Experiments</h5><p>首先是坐标空间的转换，将其转到相对空间，这在R-CNN中已经介绍过。其实是Multi-task的训练：</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fpyo96peu1j30ke064t97.jpg" alt=""></p><p><strong>RPN训练</strong></p><p>RPN就直接用end-to-end的方法进行训练，对于每张图像，采样256个anchors，正负比例为1：1，如果正样本不够则用负样本补足。</p><p><strong>Fast R-CNN训练</strong></p><p>两个网络的训练需要比较多的trick，作者采用4-Step Alternating Training:</p><ol><li>对网络初始化（pretrained model），end-to-end地训练RPN</li><li>用RPN生成propals训练Fast R-CNN</li><li>将共享的卷积层fix住，训练RPN相关的层</li><li>将共享的卷积层fix住，训练Fast R-CNN相关的层</li></ol><p>Table 6和Table 7是Faster R-CNN在PASCAL VOC 2007和PASCAL VOC 2012两个数据集上的结果们也是RPN和SS的比较，可以看出RPN要好于SS</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fq0p3j4jrnj31580ictfx.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks，TPAMI 2016&lt;/p&gt;
&lt;p&gt;作者：Shaoqing Ren, Kaiming He, Ross Gir
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>Fast R-CNN笔记</title>
    <link href="http://wulimengmeng.top/2018/03/22/Fast-R-CNN%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/03/22/Fast-R-CNN笔记/</id>
    <published>2018-03-22T05:32:39.000Z</published>
    <updated>2018-03-28T04:38:57.011Z</updated>
    
    <content type="html"><![CDATA[<p>论文：Fast R-CNN，<strong>ICCV</strong> 2015</p><p>作者：Ross Girshick</p><p>链接：https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf</p><p>代码：https://github.com/rbgirshick/fast-rcnn</p><ul><li><p>简化训练过程，实现end-to-end的训练方式</p><ul><li>将SVM分类器换成softmax，整合到网络中，鼓励类间竞争</li><li>将bounding box regression整合到网络中</li></ul></li><li><p>在Fast-RCNN中，region proposal的计算都是share的，避免重复计算</p></li><li><p>提出ROI pooling layer使得每个region proposal可以得到确定长度的特征向量</p></li><li><p>探索了一些训练的tricks，可以参考！</p><p>​</p><p>Figure 1是Fast R-CNN的图示</p></li></ul><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FuPCSWv0EUA2laIjMRDcJTU9oA0F" alt=""></p><h5>Architecture</h5><p>下图是R-CNN和Fast R-CNN的比较</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FurXilgjM6ixsxoU1HRAgilULtUt" alt=""></p><p>回顾一下R-CNN：</p><ol><li>用selective search提取region proposals</li><li>将region warp到固定大小，用CNN提取特征，得到一定长度的特征向量</li><li>对于提取到的特征，放到若干个SVM，得到各个类别的概率，再用简单的线性回归模型做 bounding box regression（就是对候选区域进行微调）</li><li>利用NMS优化结果</li></ol><p>可以发现：</p><ol><li>R-CNN存在着大量的重复计算，即对每个region propasal使用CNN提取特征，如果有n个patch就需要网络n次的forward</li><li>需要将region warp到固定大小，造成物体变形分辨率降低影响分类结果</li><li>没有end-to-end。。。</li></ol><p><strong>改进</strong></p><p>首先，R-CNN重复大量计算，需要针对这点进行优化，将卷积计算的结果重复利用，减少不必要的重复计算，先用CNN对全图提取特征，得到feature maps，然后用selective search对原图提取region proposals，根据缩放比例，在feature maps上找到相应的区域，再对这个区域进行分类和bounding box的回归。这样我们只需要做一次卷积就可以了。但是这又面临一个问题，这些区域的特征长度是不固定的，所以，收到SPP-Net的启发，提出ROI Pooling layer，使得feature maps输入能够得到固定长度的特征向量。</p><p>其次，Fast R-CNN将softmax分类器替换SVM，同时将bounding box regression融合到网络中，实现end-to-end的训练，其实就是通过multi-task的思想，实现对CNN的fine tune。</p><p><strong>ROI POOLING</strong></p><p>为了能够使得每个region得到相同固定大小的特征，我们需要调整它的维度使得它能够适应全连接层。所以论文提出了ROI POOLING这个方法，下面介绍一下ROI POOLING的工作原理：</p><p>假设输入的feature maps的维度是CxHxW，C,H,W分别表示feature maps的深度，高，宽。因为C是固定的而H和W是不固定的，所以论文采用了一种和SPPNet近似的方法。加入我们想要得到固定大小Cxhxw的输出，采用动态pooling的方法，将pooling的kernel size设置成(H/h, W/w)，步长也是一样。这样就可以得到固定长度的feature maps了。</p><p><strong>Scale Invariance</strong></p><p>为了实现object detector的scale invariance，作者探索了两者方法：</p><ol><li>直接暴力地resize</li><li>使用图像金字塔</li></ol><p><strong>Truncated SVD</strong></p><p>在训练的时候，因为ROIs数量不多，所以大部分的时间花在卷积运算上，而在测试的时候，需要计算每个ROIs的后验概率，有一半的时间花在全连接上，所以文章提出truncated SVD优化计算，将两个全连接取代一个全连接。$$W \approx U\Sigma_tV^T$$U是一个$u\times t$的矩阵，$\Sigma_t$是$t\times t$的矩阵，V是$v\times t$的矩阵，所以参数从$uv$减少到了$t(v+u)$，如果t要远小于$\min(u,v)$。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/Frc5IQiqhfIQW8Z39bNmc8BF3-vM" alt=""></p><p><strong>Mini-batch sampling</strong></p><p>在训练的时候，每次mini-batch中，从中采样两张图像，每张图像采样64个ROIs，这样每个batch的大小就是128，正负样本比例为1：3。</p><h5>Experiments</h5><p>Table 1-3是Fast R-CNN在VOC 2007, 2010, 2012三个数据集上的表现，都是SOAT。</p><p>Table 4是Fast-RCNN,RCNN以及SPPnet在training和testing效率上的比较，可以发现效率提升非常明显。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FozRMPEXdJimmQmIloMArAEK4bjz" alt=""></p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/FkHrR24XRqVg4etaxtFh-t2IF5G3" alt=""></p><h5>Design evaluation</h5><ul><li>Multi-task训练可以提高分类结果</li><li>Multi-scale detection可以帮助提高结果，但是提升不大，折中之下，选了single scale</li><li>training data越多越好，数据增强，将VOC2012的数据加到VOC2007中，提升明显！</li><li>在FRCN中，softmax要好于SVM，鼓励类间竞争</li><li>并不是proposals越多越好，需要取个合适的数量</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：Fast R-CNN，&lt;strong&gt;ICCV&lt;/strong&gt; 2015&lt;/p&gt;
&lt;p&gt;作者：Ross Girshick&lt;/p&gt;
&lt;p&gt;链接：https://www.cv-foundation.org/openaccess/content_iccv_2015/pap
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>SPPNet笔记</title>
    <link href="http://wulimengmeng.top/2018/03/20/SPPNet%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/03/20/SPPNet笔记/</id>
    <published>2018-03-20T11:23:38.000Z</published>
    <updated>2018-03-21T08:49:46.609Z</updated>
    
    <content type="html"><![CDATA[<p>论文：Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition，<strong>TPAMI</strong> 2015</p><p>作者：Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun</p><p>链接：https://arxiv.org/pdf/1406.4729.pdf</p><p>代码：https://github.com/ShaoqingRen/SPP_net</p><ul><li>提出spatial pyramid pooling layer，使得网络能够接受任意大小的输入，同时利用multi-level的spatial bins做hierarchy information aggregation，提高模型的鲁棒性</li><li>对image classification和object detection（针对RCNN的优化）都可以提升模型的表现</li><li>在ILSVRC 2014 object detection中排名第2，image classification中排名第3</li></ul><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/56717690.jpg" alt=""></p><p>在RCNN中，我们提取各个region proposals，然后将其warp到指定的大小，再用CNN提特征，这样的问题是图像object经过warp以后，会变形严重并且影响分辨率，从而影响分类的结果，所以作者提出SPP layer，使得对于任何大小的输入图像，神经网络都可以输出固定长度的特征，同时提高分类的鲁棒性。</p><h5>Architecture</h5><p>见Figure 3，将卷积层的输出经过SPP layer以后，利用max pooling分成3种的spatial bins，第一种是4x4，第二种是2x2，第三种是1x1(global pooling)。在做完pooling以后，我们可以得到16x256,4x256,1x256这三种维度的特征，256是输入的feature map的深度，拼接以后得到21x256长度的特征，其实可以将SPP layer看成是特征层面的re-scaled。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/71347165.jpg" alt=""></p><p>例如输入的feature map的大小是axa，需要产生3x3，2x2，1x1的特征向量，那么pooling的window size是ceil(a/n)，步长是floor(a/n)。将这些特征拼接得到固定长度的特征向量，再连接全连接层进行分类。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/44112090.jpg" alt=""></p><h5>Training Strategy</h5><p><strong>Multi-size Training</strong></p><p>在分类任务的模型训练过程中，采用多个size的输入可以提高模型的结果。对于有两个不同大小输入的训练策略，使用两个固定大小（框架所限）的相同参数的网络进行交替训练。</p><p><strong>Full-image Representation</strong></p><p>在分类任务的模型训练过程中，将图像resize到min(w,h)=256，保持长宽比不变。</p><h5>Experiments</h5><p><strong>Image Classifications</strong></p><p>Table 1是三种base network的结构。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/11136760.jpg" alt=""></p><p>在分类任务中，作者通过实验证明，SPP layer，multi-size training，能够提高分类的精度（见Table 2）。SPP layer能够提高精度是因为利用spatial pyramid pooling可以提高鲁棒性。multi-size training中，有三种策略，一种是单个大小，第二种是180和224，还有一种是从[180,224]随机选择其中的一个size，实验证明，第二种精度最高。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/84456005.jpg" alt=""></p><p>从Table 3看，full-image representation相比较于central crop，可以提高准确率。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/81983088.jpg" alt=""></p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/64521005.jpg" alt=""></p><p><strong>Object Detection</strong></p><p>下图是R-CNN和SPP-Net的对比，R-CNN的缺点是计算量大，包括了大量的重复计算。</p><p><img src="http://img.blog.csdn.net/20170617102150673?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdjFfdml2aWFu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p><p>其具体步骤和R-CNN类似：</p><ol><li>通过selective search得到2000个候选窗口</li><li>将整张图像输入到CNN中，完成特征的提取，然后在feature map上找到候选框的区域，在对候选框进行spaital pyramid pooling，得到定长的特征向量,这样做可以大大提高效率。</li><li>采用SVM模型，对物体进行分类。</li></ol><p>从Table 9看出，SPPNet相较于R-CNN计算效率有了较高的提升，同时准确率也有提高。</p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/35453761.jpg" alt=""></p><p><img src="http://7xkgro.com1.z0.glb.clouddn.com/18-3-21/27949731.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition，&lt;strong&gt;TPAMI&lt;/strong&gt; 2015&lt;/p&gt;
&lt;p&gt;作者：Kaiming He, Xiangyu
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>RCNN笔记</title>
    <link href="http://wulimengmeng.top/2018/03/13/RCNN%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/03/13/RCNN笔记/</id>
    <published>2018-03-13T06:21:29.000Z</published>
    <updated>2018-03-14T12:26:25.593Z</updated>
    
    <content type="html"><![CDATA[<p>论文：Rich feature hierarchies for accurate object detection and semantic segmentation，CVPR 2014</p><p>作者：Ross Girshick，Jeff Donahue，Trevor Darrell，Jitendra Malik</p><p>链接：https://arxiv.org/pdf/1311.2524.pdf</p><p>代码：https://github.com/rbgirshick/rcnn</p><h5>Idea</h5><ul><li>之前的object detection算法都是用一些手工特征，例如SIFT或者HOG等，R-CNN使用pretrained的CNN提取region的特征，然后再用SVM分类做finetune（bridging the gap between image classification and object detection）</li><li>尝试不同层的feature作为分类的特征</li></ul><h5>Architecture</h5><p>R-CNN的模型见Figure 1，主要包括3个部分：</p><ol><li>提取region proposals</li><li>用CNN提取特征，得到一定长度的特征向量</li><li>对于提取到的特征，喂到若干个SVM，得到各个类别的概率</li><li>利用NMS优化结果</li></ol><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fpbdwp017oj30tq0mq0wc.jpg" alt=""></p><p><strong>Region proposals</strong></p><p>对于region proposals的提取，主要利用selective search这个启发式搜索方法。</p><p>selective search的步骤为：</p><ul><li>使用<a href="http://cs.brown.edu/~pff/segment/" target="_blank" rel="external">Efficient Graph Based Image Segmentation</a>中的方法来得到region</li><li>得到所有region之间两两的相似度</li><li>合并最像的两个region</li><li>重新计算新合并region与其他region的相似度</li><li>重复上述过程直到整张图片都聚合成一个大的region</li><li>使用一种随机的计分方式给每个region打分，按照分数进行ranking，取出top k的子集，就是selective search的结果</li></ul><hr><p><strong>Feature extraction</strong></p><p>使用AlexNet提取特征，AlexNet现在ILSVRC 2012(IMAGENET)上做pre train。将图像的region patch warp到227x227，然后喂到网络，得到特征。</p><p><strong>Object category classifier</strong></p><p>对于每个类别，训练各自的SVM，这样就可以得到每个类的score，训练的时候将gt视为正样本，与gt的IoU &lt; 0.3视为负样本。因为负样本往往远远大于正样本，所以需要做hard negative mining，控制合理的比例，一般设置为1：3。</p><p><strong>Bounding box regression</strong></p><p>输入是n对${(P^i,G^i)}i=1,…,N$，其中$P^i=(P_x^i,P_y^i,P_w^i,P_h^i)$，对应bounding box的中心，长宽，$G^i=(G_x,G_y,G_w,G_h)$。将P进行映射（前两者是平移，后两个是缩放）：$$\hat{G}_x = P_wd_x(P)+P_x \ \hat{G}_y = P_hd_y(P)+P_y \ \hat{G}<em>x = P_w\exp (d_w(P))\ \hat{G}<em>h = P_h\exp(d_h(P)) \d</em>\star(P)=w</em>\star^T\phi_5(P)$$训练的时候对gt的四个坐标进行转换（上面的逆运算，使得$t_x,t_y$）：$$t_x = (G_x-P_x)/P_w \ t_y =(G_y −P_y)/P_h \ t_w = \log(G_w/P_w)\t_h = \log(G_h/P_h).$$经过这样的变换，$t_x,t_y$为需要学习的平移量，$t_w, t_h$为需要学习的缩放量。</p><p>其中，$G$表示的是ground truth，P表示的训练样本，我们的任务是求解$W_\star$，其实就是通过梯度下降或者最小二乘法求解ridge regression问题，:$$w_\star =  \arg\min_{\hat{w}<em>\star}(t^i</em>\star − \hat{w}^T_\star \phi_5(P^i))^2+\lambda ||\hat{w}_\star||^2$$其中$\phi_5(P^i)$表示的是第5个pooling的输出。需要注意的是，正则系数$\lambda=1000$，而且当G和P相差很大的时候，效果会不好，所以需要设置IoU阈值，将其设为0.6。</p><h5>Experiments</h5><p>Table 1是模型在VOC 2012 test上的表现，可以看出R-CNN BB远超其他baseline，证明了模型的性能。</p><p>Table 2是模型在VOC 2007 test上的表现，可以在上面做一些ablation study：</p><ul><li>对于不finetune的模型，第一行到第三行，可以发现fc6的结果最好，这样就可以移除fc7的参数，简化模型。</li><li>对于finetune的模型，第四行到第六行，可以发现fc7的结果最好，经过网络的同层比较，可以发现finetune可以大大提升模型的performance。</li><li>通过第七行与第六行比较，可以看出bounding box regression可以较为显著地提升模型性能。</li><li>跟其他手工特征相比，CNN提取的特征具有更强的表达能力。</li></ul><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpbidj661zj31kw0eeq6d.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fpbi5y3ykqj31kw0k9wjg.jpg" alt=""></p><p>​</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：Rich feature hierarchies for accurate object detection and semantic segmentation，CVPR 2014&lt;/p&gt;
&lt;p&gt;作者：Ross Girshick，Jeff Donahue，Trevor
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="object detection" scheme="http://wulimengmeng.top/tags/object-detection/"/>
    
  </entry>
  
  <entry>
    <title>ResNeXt笔记</title>
    <link href="http://wulimengmeng.top/2018/03/06/ResNeXt%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/03/06/ResNeXt笔记/</id>
    <published>2018-03-06T12:42:27.000Z</published>
    <updated>2018-03-07T10:40:16.056Z</updated>
    
    <content type="html"><![CDATA[<p>论文 :Aggregated Residual Transformations for Deep Neural Networks, CVPR 2017</p><p>链接：https://arxiv.org/pdf/1611.05431.pdf</p><p>作者:  Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He</p><p>源码：https://github.com/facebookresearch/ResNeXt</p><h5>Idea</h5><p>提出ResNeXt网络，基于ResNet和GoogleNet。</p><p>提出cardinality的概念，对于每个conv block，对输入做多种不同的（结构相同，参数不同）transformations，然后再aggregation，而transformations的数量就是cardinality。</p><p>结构启发于inception module，同样是split-transform-merge的策略，这里的merge和transform都和inception不一样。split-transform-merge的策略主要是<strong><em>通过在一个尽可能小的计算复杂度的前提下，提高模型的表达能力</em></strong>（approach the representational power of large and dense layers, but at a considerably lower computational complexity）！ Inception的问题在于每个block都需要定制，导致了模型的灵活性较差，这些block的定制化设计相当于引入了一堆的超参，大量的超参对模型来讲无疑是不利的。而这篇文章就是基于这点进行改进！</p><ul><li>模块化</li><li>超参少</li><li>表达能力强</li></ul><h5>Architecture</h5><p>首先，总结了两点block设计的原则：</p><ol><li>对于相同大小的feature map，block的超参要相同，也就是conv的filter参数要一样。【if producing spatial maps of the same size, the blocks share the same hyper-parameters (width and filter sizes)】</li><li>如果空间维度减半，那么feature maps的数量要加倍。【each time when the spatial map is downsampled by a factor of 2, the width of the blocks is multiplied by a factor of 2】</li></ol><p>Figure 1是ResNet和ResNeXt的block结构比较，重点看ResNeXt，可以看到这里将256维的输入做32个不同的transformations，每个transformation先通过1x1的conv做降维(information embedding)，然后再经过几个conv，最后将这32个输出做aggregation。</p><p>将其公式化:$$F(x) = \sum_{i=1}^C \tau_i(x)$$$\tau_i$的作用就是将x投影到低维空间（embeeding），然后做transform。C就是做transformation的数量，也就是cardinaty。aggregation后，再用short connection做identity mapping。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fp3f3tppr3j30te0i0jur.jpg" alt=""></p><p>Figure 3是异构的三种结构，（a）是初始版本，（b）concat，（c）group conv，这三者可以说是等价的。那么在实现上，可以利用group conv，更加方便！</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fp4d6cqzx8j31cq0i2q8m.jpg" alt=""></p><p>​Table 1是ResNet-50和ResNeXt-50的参数对比</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fp4fhovd49j30nw0uaq8x.jpg" alt=""></p><h5>Experiment</h5><p>Table 3是各个版本的ResNeXt以及ResNet在ImageNet-1K数据集上的表现，可以发现随着Cardinaty增加，模型总体上是变好的，体现在top-1 error逐渐在降低。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcly1fp4fegkbv6j30oc0jqn0j.jpg" alt=""></p><p>Table 6是ResNet和ResNeXt在ImageNet-5K上的比较，可以可发现后者都要好于前者。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1fp4fkycmlxj30pi0eotbv.jpg" alt=""></p><p>Table 5则是各个state-of-the-art的模型在ImageNet-1K数据集上表现，可以发现模型达到了最好的结果。</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcly1fp4fmo7mobj30ow0gaacv.jpg" alt=""></p><p>从Table 7可以发现，相同的参数，ResNeXt比Wide ResNet表现更好。</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcly1fp4fojev6aj30pc09sgn0.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文 :Aggregated Residual Transformations for Deep Neural Networks, CVPR 2017&lt;/p&gt;
&lt;p&gt;链接：https://arxiv.org/pdf/1611.05431.pdf&lt;/p&gt;
&lt;p&gt;作者:  Sa
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="classification" scheme="http://wulimengmeng.top/tags/classification/"/>
    
  </entry>
  
  <entry>
    <title>DenseNet笔记</title>
    <link href="http://wulimengmeng.top/2018/03/06/DenseNet%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/03/06/DenseNet笔记/</id>
    <published>2018-03-06T06:34:45.000Z</published>
    <updated>2018-03-06T13:19:24.247Z</updated>
    
    <content type="html"><![CDATA[<p>论文 ：Densely Connected Convolutional Networks, CVPR 2017</p><p>链接：http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.pdf</p><p>作者: Huang Gao, Liu Zhuang, Weinberger, K. Q., &amp; van der Maaten, L.</p><p>源码：https://github.com/liuzhuang13/DenseNet.</p><h5>Idea</h5><p>DenseNet的idea和ResNet有点相近，既然ResNet可以通过一个skip connection就提高模型的性能，那为什么不多几个呢？</p><p>这样的话就可以使得梯度信息的回传更加有效（ResNet通过identity mapping进行另一条路径的梯度回传,而DenseNet的每一层梯度都可以直接回传回它前面的层），可以充分利用各个level的特征，也可以减少参数等。</p><ul><li>alleviate the vanishing-gradient problem，利用dense connection有效回传梯度</li><li>strengthen feature propagation，利用dense connection融合(concat)不同level的特征，使得浅层的特征更容易传播到高层，同时也可以让浅层的conv学一些discriminative features。</li><li>encourage feature reuse</li><li>substantially reduce the number of parameters，通过控制growth rate减少参数量</li></ul><p>假设有L层网络，那么如果将网络视为DAG，那么如果实行全连接，并且保证网络前向传播，共有$\frac{L\times(L+1)}{2}$条边。</p><h5>Architecture</h5><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fp33t32d1mj31kw0bt0xv.jpg" alt=""></p><p><strong>Dense Block</strong></p><p>首先，将其公式化，我们考虑第l层网络的输入和输出，$x_l$表示为第l层的输出，那么有:$$x_l = H_l([x_0,x_1,...,x_{l-1}])$$这里，$[x_0,x_1,...,x_{l-1}]$表示feature map的按通道拼接，形成新的tensor。</p><p>$H_l$是一个组合函数，BN-ReLU-Conv(3x3)。</p><p>为了将模型简化，将预想中的DenseNet分拆成若干个dense block，见Figure 2。</p><p><strong>Growth Rate</strong></p><p>$H_l$的输出是k个feature maps，也被叫做是growth rate。</p><p>对于每个dense block来说，假设输入的深度是$k_0$，对于第l个层的输出，则有$k\times(l-1)+k_0$的深度，从Figure 2就可以简单得出。作者将这种dense connection解释为collective knowledge，获取前面层的输出，growth rate则是起到限制knowledge容量的作用，使得knowledge精简化!</p><p><strong>Transition Layer</strong></p><p>每个block之间用transition layer，包括1x1的conv和pooling层。transition layer起到压缩网络模型的作用，如果每个block包括m个feature maps，那么经过压缩后，就变成$\theta m, 0\le \theta \le 1$，同时利用pooling降采样。我们把$\theta =0.5$的结构（将feature maps的数量降为原来的一般）记作DenseNet-C。</p><p><strong>Bottleneck Layer</strong></p><p>因为每个block的输出都是k，但是它的输入往往比k更大，所以引入bottleneck layer起到降维的作用，同时保留尽可能多的信息。这样$H_l$就变成了BN-ReLU-Conv(1x1)-BN-ReLU-Conv(3x3)，我们将使用bottleneck layer的版本记作DenseNet-B。</p><p>Table 1是模型的参数结构。</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fp3b35pbwqj31kw0qqair.jpg" alt=""></p><h5>实验结果</h5><p><strong>训练细节</strong></p><p>对于CIFAR和SVHN,初始lr设为0.1，在训练50%和75%的epochs时，除以10。</p><p>对于IMAGENET,初始lr设为0.1，在30和60个epochs后，除以10。</p><p>SGD，weight decay $10^{-4}$</p><p>因为CIFAR和SVHN数据集较小，所以在conv后（除第一个）都加了dropout，ratio为0.2。</p><p>Tabel 2是各个模型在CIFAR-10，CIFAR-100，SVHN三个数据集上的结果，+号表示做数据增强，将用了Bottleneck layer和feature maps compression的记做DenseNet-BC。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fp3bafnkxmj314u0pwgtx.jpg" alt=""></p><p>总的来说，数据增强可以提升表现！</p><ul><li>可以发现，和ResNet相比，参数更少，错误率更低，模型参数利用率高！</li><li>在C10和C100上，DenseNet-BC(L=190,k=40)达到最优的结果。</li><li>观察原始的DenseNet（没有BC），可以发现，随着L和k的增大，模型性能在提升（参数量上升，模型容量提升，表达能力提升），说明dense block有较强的抗过拟合的能力。</li><li>在SVHN上，DenseNet-BC结果要比没有原始的DenseNet，这可能是数据集过小，模型过拟合了。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文 ：Densely Connected Convolutional Networks, CVPR 2017&lt;/p&gt;
&lt;p&gt;链接：http://openaccess.thecvf.com/content_cvpr_2017/papers/Huang_Densely_Con
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="classification" scheme="http://wulimengmeng.top/tags/classification/"/>
    
  </entry>
  
  <entry>
    <title>SegNet笔记</title>
    <link href="http://wulimengmeng.top/2018/02/26/SegNet%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/02/26/SegNet笔记/</id>
    <published>2018-02-26T04:41:03.000Z</published>
    <updated>2018-02-26T08:25:46.640Z</updated>
    
    <content type="html"><![CDATA[<p>论文 ：SegNet: Identity Mappings in Deep Residual Networks, ECCV 2016</p><p>链接：http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7803544</p><p>作者: Vijay Badrinarayanan, Alex Kendall , and Roberto Cipolla</p><p><strong>Idea</strong></p><ul><li>SegNet基于FCN，包含encoder和decoder两个部分，encoder使用VGGNet，decoder则使用skip architecture将相同分辨率的feature map结合再做后续的预测。</li><li>上采样的方法不同于transposed convolution和双线性插值等方法，使用maxpooling的逆运算的方法做上采样，得到稀疏的feature map，再做卷积得到稠密的feature map。</li></ul><p><strong>Architecture</strong></p><p>具体的框架结构件Fig.2，主要由两部分组成，encoder和decoder。</p><p>encoder的部分包含VGGNet在全连接层前的所有卷积层，这样共有13个卷积层，并且参数是直接从在imagenet预训练过的VGGNet直接拷贝过来，进行初始化。通过移除全连接层，可以大大地减少参数量和提高运算效率，参数量从134M减少到了14.7M。</p><p>文章的重点部分在于decoder的设计，decoder部分包含和encoder一样的卷积层数量，并且参数配置一一对应。在VGGNet中，max pooling的stride是2，kernel size是2，所以它的下采样是没有重叠的。在升采样上，和其他类似U-Net等不同的是，SegNet使用的是maxpooling逆运算，也就是利用保存的max pooling的元素下标，将feature map恢复到原来的大小，再利用可训练的卷积层得到稠密的feature map。具体的过程见Fig.3。</p><p>因为使用max pooling可以提高特征的translation invariance，同时提高分类的鲁棒性，但是同时也损失了很多边缘信息，因为我们把边缘的位置信息丢弃了。通常来说，响应比较强的都是一些纹理边缘，而max pooling本质上是一个滤波器，将局部最大值保留下来，舍去其他值。通过将max pooling的下标保留下来，可以帮助我们尽可能的恢复边缘位置信息。</p><p>使用上述上采样的方法有以下的好处：</p><ul><li>可以得到更加细致的轮廓</li><li>减少训练参数，同时能够end-to-end的训练</li><li>可以将其融入到任何encoder-decoder的结构中，具有普适性。</li></ul><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fotu08o3s4j312u0e4ajm.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotuej8g3gj313a0eo429.jpg" alt=""></p><p>Pytorch代码实现：</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">segnet</span><span class="params">(nn.Module)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_classes=<span class="number">21</span>, in_channels=<span class="number">3</span>, is_unpooling=True)</span>:</span></div><div class="line">        super(segnet, self).__init__()</div><div class="line"></div><div class="line">        self.in_channels = in_channels</div><div class="line">        self.is_unpooling = is_unpooling</div><div class="line"></div><div class="line">        self.down1 = segnetDown2(self.in_channels, <span class="number">64</span>)</div><div class="line">        self.down2 = segnetDown2(<span class="number">64</span>, <span class="number">128</span>)</div><div class="line">        self.down3 = segnetDown3(<span class="number">128</span>, <span class="number">256</span>)</div><div class="line">        self.down4 = segnetDown3(<span class="number">256</span>, <span class="number">512</span>)</div><div class="line">        self.down5 = segnetDown3(<span class="number">512</span>, <span class="number">512</span>)</div><div class="line"></div><div class="line">        self.up5 = segnetUp3(<span class="number">512</span>, <span class="number">512</span>)</div><div class="line">        self.up4 = segnetUp3(<span class="number">512</span>, <span class="number">256</span>)</div><div class="line">        self.up3 = segnetUp3(<span class="number">256</span>, <span class="number">128</span>)</div><div class="line">        self.up2 = segnetUp2(<span class="number">128</span>, <span class="number">64</span>)</div><div class="line">        self.up1 = segnetUp2(<span class="number">64</span>, n_classes)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs)</span>:</span></div><div class="line"></div><div class="line">        down1, indices_1, unpool_shape1 = self.down1(inputs)</div><div class="line">        down2, indices_2, unpool_shape2 = self.down2(down1)</div><div class="line">        down3, indices_3, unpool_shape3 = self.down3(down2)</div><div class="line">        down4, indices_4, unpool_shape4 = self.down4(down3)</div><div class="line">        down5, indices_5, unpool_shape5 = self.down5(down4)</div><div class="line"></div><div class="line">        up5 = self.up5(down5, indices_5, unpool_shape5)</div><div class="line">        up4 = self.up4(up5, indices_4, unpool_shape4)</div><div class="line">        up3 = self.up3(up4, indices_3, unpool_shape3)</div><div class="line">        up2 = self.up2(up3, indices_2, unpool_shape2)</div><div class="line">        up1 = self.up1(up2, indices_1, unpool_shape1)</div><div class="line"></div><div class="line">        <span class="keyword">return</span> up1</div></pre></td></tr></table></figure></p><p><strong>实验</strong></p><p>首先针对deocder做了以下几种变形：</p><ul><li>SegNet-basic: 4个编码块和4个解码块，编码块由conv,bn,relu组成，然后加max pooling，解码器由conv，bn组成，并且没有bias。所有的卷积核的大小都是7x7。</li><li>SegNet-Basic-SingleChannelDecoder：卷积是单通道的，分别和对应的feature map层做卷积，这样可以减少训练参数，同时提高inference的速度。</li><li>FCN-basic：和SegNet-basic类似，不同的是使用FCN的上采样方法。</li><li>FCN-basic-NoAddition：不进行feature map相加，只通过deconv上采样。</li><li>Bilinear-Interpolation：使用双线性插值上采样。</li><li>SegNet-Basic-EncoderAddition：和FCN的方法类似，比较消耗显存，将几个feature map相加得到最终的feature map</li><li>FCN-Basic-NoDimReduction：再输出最终的结果之间不进行降维，FCN-basic会将维度降低到64，然后在做1x1的卷积。</li></ul><p>比较结果见TABLE 1。参数数量上，FCN-Basic和FCN-Basic-NoAddition最少，inference time则是FCN-Basic-NoAddition最少。</p><ul><li>在性能上，bilinear-interpolation表现最差，说明了decoder需要学习，而不是简单粗暴的直接上采样！</li><li>SegNet-Basic和FCN-Basic相比，精度相近，区别在于后者的显存消耗更大因为后者需要存储多个feature map，而前者只需要存储max pooling的下标。除此之外，后者的forward时间更短，因为它在做预测前对feature map做了降维。</li><li>FCN-Basic-NoAddition和SegNet-Basic：两者的decoder最为相似，因为都是直接学上采样，没有feature map的相加，在精度上，SegNet-Basic较好，说明了利用低层次的feature map的重要性，也就是将高层次语义信息和低层次位置信息结合的重要性。</li><li>FCN-Basic-NoAddition-NoDimReduction和SegNet-Basic：前者的模型要大于后者，因为没有做降维。在性能上，前者也不如后者。说明并不是模型越大，表现越好，重要的是需要capture更多的边缘信息。</li><li>FCN-Basic-NoAddition 和SegNet-Basic-SingleChannelDecoder：证明了当面临存储消耗，精度和inference时间的妥协的时候，我们可以选择SegNet!</li><li>当内存和inference时间不受限的时候，模型越大，表现越好。因为FCN-Basic-NoDimReduction和SegNet-EncoderAddition比其他变种要好。</li><li>class balance的影响：在class average accuracy和mIoU指标上，可以发现没有class weighted的时候比经过class weighted的要差，而在global accuracy上，情况则相反，这是因为绝大部分的像素都是天空，道路和建筑。</li></ul><p>总结一下：</p><ul><li>内存受限的时候，可以用过降维，存储max pooling下标来提升表现。</li><li>编码器一定，解码越大，性能越好</li><li>编码器的feature map被完整保留下来时，效果最好，毕竟是空间换性能！</li></ul><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotvqp2uqsj313y0g2agk.jpg" alt=""></p><p>模型在CamVid数据集上的比较结果见TABLE 3，CamVid是一个用于自动驾驶的室外场景，可以发现在迭代次数较少的时候，SegNet要好于其他方法其他方法，但是当迭代次数较高的时候，整体上SegNet还是表现最优，但是在BF指标上不如DeconvNet。</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79ly1fotwygav2aj313c0a8tc7.jpg" alt=""></p><p>模型在SUNRGB-D数据集上的比较结果见TABLE 4，可以发现，所有方法的表现都比较差，在G，C，BF指标上，SegNet好于其他模型，但是mIoU比DeepLab-LargeFOV要差。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fotx37mf6nj31360c642m.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文 ：SegNet: Identity Mappings in Deep Residual Networks, ECCV 2016&lt;/p&gt;
&lt;p&gt;链接：http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;amp;arnumber=
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="segmentation" scheme="http://wulimengmeng.top/tags/segmentation/"/>
    
  </entry>
  
  <entry>
    <title>Fully Convolutional Networks for Semantic Segmentation(FCN)笔记</title>
    <link href="http://wulimengmeng.top/2018/02/26/Fully-Convolutional-Networks-for-Semantic-Segmentation-FCN-%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/02/26/Fully-Convolutional-Networks-for-Semantic-Segmentation-FCN-笔记/</id>
    <published>2018-02-26T04:40:25.000Z</published>
    <updated>2018-02-26T05:59:30.340Z</updated>
    
    <content type="html"><![CDATA[<p>论文：Fully Convolutional Networks for Semantic Segmentation，CVPR 2015</p><p>链接：https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf</p><p>作者：Jonathan Long, Evan Shelhamer, Trevor Darrell</p><p><strong>Idea</strong></p><p>传统的图像分割算法主要依赖于：</p><ol><li>图像patch的训练，使得效率和准确率都不够。</li><li>后处理</li><li>multi-scale pyramid的预处理</li><li>ensemble</li></ol><p>…</p><p>这篇文章的主要贡献就是建立构造了全卷积神经网络，在显存足够的前提下可以接受任意大小的输入，然后得到对应大小的输出。作者将VGGNet,GoogleNet用于物体分类并预训练好的网络改造成全卷积神经网络，能够实现end-to-end的训练，并将其finetune，用来做图像的语义分割。除此之外，在升采样的过程中，由于之前的降采样丢失了大量的位置信息，所以作者采用了skip architecture将低层的输出传给高层，实现浅层的位置信息和高层的语义信息的融合。</p><p><strong>网络结构</strong></p><p>以VGGNet为例，见Figure3，最后的全连接层的维度是4096，为了将其改造成全卷积，将全连接层改成1x1的卷积，这样它的输出变成了4096x1x1。然后，通过deconvotion的操作对feature map进行升采样，恢复到和原图一样的大小，所以最终的输出的大小为WxHxC，其中W,H是原图的大小，而C是像素的种类数，每个空间位置表示的是各个类别的概率。降采样会提高感受野，同时也会包含越来越多的语义信息，但是也会丢失位置信息，所以，为了做出更好的像素分类结果，需要将高层的语义信息(what)和底层的位置信息(where)结合起来，使用skip architecture的结构，用低层信息对结果进行修正，提高模型的性能。除此之外，作者还提供了3个变种，即FCN-32s，FCN-16s，FCN-8s。顾名思义，FCN-32s就是通过deconvolution进行32倍的升采样直接输出。FCN-16s则是联合pool4和2倍升采样的conv7，再做16倍的升采样。FCN-8s是pool3，2倍升采样的pool4和4倍升采样的conv7，结合以后再做8倍的升采样。</p><p>升采样的方法有多种，可以采用双线性插值等非学习性方法，也可以采用transposed convolution，通过设定步长等参数进行升采样。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79ly1fotrxkpssoj31j20tw113.jpg" alt=""></p><p>下面是FCN-8的pytorch实现。</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">fcn_8s</span><span class="params">(nn.Module)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes)</span>:</span></div><div class="line">        super(fcn, self).__init__()</div><div class="line">        self.stage1 = nn.Sequential(*list(pretrained_net.children())[:<span class="number">-4</span>])</div><div class="line">        self.stage2 = list(pretrained_net.children())[<span class="number">-4</span>]</div><div class="line">        self.stage3 = list(pretrained_net.children())[<span class="number">-3</span>] </div><div class="line">        </div><div class="line">        self.scores1 = nn.Conv2d(<span class="number">512</span>, num_classes, <span class="number">1</span>)</div><div class="line">        self.scores2 = nn.Conv2d(<span class="number">256</span>, num_classes, <span class="number">1</span>)</div><div class="line">        self.scores3 = nn.Conv2d(<span class="number">128</span>, num_classes, <span class="number">1</span>)</div><div class="line">        </div><div class="line">        self.upsample_8x = nn.ConvTranspose2d(num_classes, num_classes, <span class="number">16</span>, <span class="number">8</span>, <span class="number">4</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.upsample_4x = nn.ConvTranspose2d(num_classes, num_classes, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span>)</div><div class="line">        self.upsample_2x = nn.ConvTranspose2d(num_classes, num_classes, <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span>, bias=<span class="keyword">False</span>)   </div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        x = self.stage1(x)</div><div class="line">        s1 = x <span class="comment"># 1/8</span></div><div class="line">        </div><div class="line">        x = self.stage2(x)</div><div class="line">        s2 = x <span class="comment"># 1/16</span></div><div class="line">    </div><div class="line">        x = self.stage3(x)</div><div class="line">        s3 = x <span class="comment"># 1/32</span></div><div class="line">        </div><div class="line">        s3 = self.scores1(s3)</div><div class="line">        s3 = self.upsample_2x(s3)</div><div class="line">        s2 = self.scores2(s2)</div><div class="line">        s2 = s2 + s3</div><div class="line">        </div><div class="line">        s1 = self.scores3(s1)</div><div class="line">        s2 = self.upsample_4x(s2)</div><div class="line">        s = s1 + s2</div><div class="line">        s = self.upsample_8x(s2)</div><div class="line">        <span class="keyword">return</span> s</div></pre></td></tr></table></figure></p><p><strong>实验</strong></p><p>3个变种的效果在PASCAL VOS数据集上的比较，见Table 2和Figure 4，可以发现都是FCN-8s更胜一筹。</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79ly1fotswcnw1kj30q60dw76m.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotsvv8zbuj30rw0h4win.jpg" alt=""></p><p>3种分类模型在PASCAL VOC 2011数据集的比较：AlexNet，VGGNet，GoogleNet，见Table1，可以发现VGGNet超出其他两个模型很多。</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79ly1fotsyeuufij30q60me42k.jpg" alt=""></p><p>同时，FCN在PASCAL-S，NYUDv2，SIFT FLOW数据集也取得了state-of-the-art的结果。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文：Fully Convolutional Networks for Semantic Segmentation，CVPR 2015&lt;/p&gt;
&lt;p&gt;链接：https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fc
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="segmentation" scheme="http://wulimengmeng.top/tags/segmentation/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle比赛小结-Camera Model Identification</title>
    <link href="http://wulimengmeng.top/2018/02/09/Kaggle%E6%AF%94%E8%B5%9B%E5%B0%8F%E7%BB%93-Camera-Model-Identification/"/>
    <id>http://wulimengmeng.top/2018/02/09/Kaggle比赛小结-Camera-Model-Identification/</id>
    <published>2018-02-09T05:43:29.000Z</published>
    <updated>2018-02-09T05:54:13.030Z</updated>
    
    <content type="html"><![CDATA[<p>https://www.kaggle.com/c/sp-society-camera-model-identification</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1foa5fw8h19j31k20483yy.jpg" alt=""></p><p>参加完比赛，做个简单的总结：</p><ul><li>数据增强：JPEG压缩，resizing，gamma修正</li><li>数据的不平衡需要设置采样权重</li><li>Random Crop，尽可能大，取512的结果好于256，先crop 1024，做完数据增强后再crop 512</li><li>网络模型，Dense201&gt;Dense161…..</li><li>Focal Loss可以提高结果</li><li>learning rate: 1e-4，optimizer: Adam，batch size: 16…...</li><li>ensemble</li></ul><p>可以考虑的点：</p><ul><li>因为验证集的结果还不错，可以将测试集用训练得到的模型做分类，再训练，做数据扩充</li><li>可以人工地下载更多的数据。。。</li><li>结合手工提取的特征做结果的修正，例如noise pattern:https://www.kaggle.com/zeemeen/i-have-a-clue-what-i-am-doing-noise-patterns</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;https://www.kaggle.com/c/sp-society-camera-model-identification&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ws3.sinaimg.cn/large/006tKfTcgy1foa5fw8h19j31k20
      
    
    </summary>
    
      <category term="competition" scheme="http://wulimengmeng.top/categories/competition/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="classifcation" scheme="http://wulimengmeng.top/tags/classifcation/"/>
    
      <category term="computer vision" scheme="http://wulimengmeng.top/tags/computer-vision/"/>
    
  </entry>
  
  <entry>
    <title>Inception-v4, Inception-ResNet and(Inception v4)笔记</title>
    <link href="http://wulimengmeng.top/2018/02/07/Inception-v4-Inception-ResNet-and-Inception-v4-%E7%AC%94%E8%AE%B0/"/>
    <id>http://wulimengmeng.top/2018/02/07/Inception-v4-Inception-ResNet-and-Inception-v4-笔记/</id>
    <published>2018-02-07T07:36:00.000Z</published>
    <updated>2018-02-10T07:57:47.175Z</updated>
    
    <content type="html"><![CDATA[<p>论文 ：Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, AAAI 2017</p><p>链接：https://arxiv.org/abs/1602.07261</p><p>作者: Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi</p><p>呃。。。这篇文章的主要贡献是了尝试了ResNet和Inception结合的多种可能性。。。。对Inception block进行修改和优化，提出了Inception v4（Figure 9），Inception-ResNet-v1和Inception-ResNet-v2（Figure 15），将ImageNet classification task的top-5 error刷到了3.08%。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobembpr0rj30ee0rcwhc.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdqhuy1oj30eo0de3zr.jpg" alt=""></p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobdr5dh4pj30ek0c6myf.jpg" alt=""></p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobdrmnbfwj30es0fitab.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdroxsyfj30fi0h2jt6.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobdsgyknpj30eg0m8wg5.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdss6xhkj30f40femyk.jpg" alt=""></p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fobdsvxatrj30fg0j6dhi.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdt1ggqpj30ew0cc75o.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdtqs6ylj30g00jsdhj.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdu21ayyj30cw0kkgnb.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobdvixvgxj30ek0lewgk.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdvwhgcdj30ek0fe3zx.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdvyzlfvj30ek0j0myu.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobdw3cijkj30fi0c20u5.jpg" alt=""></p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fobdw6e7fqj30f20iiwg6.jpg" alt=""></p><p>实验发现：如果feature map的数量超过1000，网络会不work，训练的时候会不稳定，而且在早期就会“die”。所以在residual加个scaling，使得数值偏小，见Figure 20。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fobe052il4j30s00o4q62.jpg" alt=""></p><h5>实验</h5><p>single crop和single model的比较结果见Table 2，可以发现Inception-ResNet-v2略胜一筹，但是和Inception-v4差距不大。</p><p>小数量的crop和single model的比较结果见Table 3，和Table 2的结果类似。</p><p>dense crop和single model的比较结果见Table 4，结果依然类似。</p><p>以及，crop的数量对结果影响还是很大的！</p><p>144 crop的模型ensemble后的比较结果见Table 5。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobe29be8mj30t60e6q5l.jpg" alt=""></p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobe24s4gmj30sq0e80vm.jpg" alt=""></p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fobe25u8vpj30tq0dmju6.jpg" alt=""></p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fobe291a2tj30uw0gu0wt.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;论文 ：Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning, AAAI 2017&lt;/p&gt;
&lt;p&gt;链接：https://arxiv.org/abs/1602.072
      
    
    </summary>
    
      <category term="algorithms" scheme="http://wulimengmeng.top/categories/algorithms/"/>
    
    
      <category term="deep learning" scheme="http://wulimengmeng.top/tags/deep-learning/"/>
    
      <category term="classifcation" scheme="http://wulimengmeng.top/tags/classifcation/"/>
    
  </entry>
  
</feed>
