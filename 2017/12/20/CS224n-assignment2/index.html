<!DOCTYPE HTML>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>CS224n-assignment2 | Mowayao&#39;s Blog</title>
  <meta name="author" content="Mowayao">
  
  <meta name="description" content="Tensorflow Softmax(a) 用TensorFlow实现softmax
123456789101112131415def softmax(x):    &#34;&#34;&#34;    Compute the softmax function in tensorflow.    Args:        ">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="CS224n-assignment2"/>
  <meta property="og:site_name" content="Mowayao&#39;s Blog"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-110229492-1', 'auto');
  ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?cb5448498d7169c668b07c2b255d62c1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</head>

 <body>  
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Mowayao&#39;s Blog</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		  <li>
			<a href="/atom.xml" title="Subscribe me.">
			  <i class="fa fa-user"></i>RSS
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">
			<h1> CS224n-assignment2</h1>
		</div>
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <h2 id="Tensorflow-Softmax"><a href="#Tensorflow-Softmax" class="headerlink" title="Tensorflow Softmax"></a>Tensorflow Softmax</h2><p>(a) 用TensorFlow实现softmax</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">softmax</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Compute the softmax function in tensorflow.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        x:   tf.Tensor with shape (n_samples, n_features).</span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        out: tf.Tensor with shape (n_sample, n_features). You need to construct this</span></div><div class="line"><span class="string">                  tensor in this problem.</span></div><div class="line"><span class="string">    """</span></div><div class="line"></div><div class="line">    x -= tf.reduce_max(x, axis=<span class="number">1</span>, keep_dims=<span class="keyword">True</span>)</div><div class="line">    out = tf.exp(x) / tf.reduce_sum(tf.exp(x), axis=<span class="number">1</span>)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> out</div></pre></td></tr></table></figure>
<p>(b) 实现TensorFlow实现cross entropy loss</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">cross_entropy_loss</span><span class="params">(y, yhat)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line"><span class="string">    Compute the cross entropy loss in tensorflow.</span></div><div class="line"><span class="string">    The loss should be summed over the current minibatch.</span></div><div class="line"><span class="string">    Args:</span></div><div class="line"><span class="string">        y:    tf.Tensor with shape (n_samples, n_classes). One-hot encoded.</span></div><div class="line"><span class="string">        yhat: tf.Tensorwith shape (n_sample, n_classes). Each row encodes a</span></div><div class="line"><span class="string">                    probability distribution and should sum to 1.</span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">        out:  tf.Tensor with shape (1,) (Scalar output). You need to construct this</span></div><div class="line"><span class="string">                    tensor in the problem.</span></div><div class="line"><span class="string">    """</span></div><div class="line">    out = -tf.reduce_sum((tf.to_float(y)*tf.log(yhat)))</div><div class="line"></div><div class="line">    <span class="keyword">return</span> out</div></pre></td></tr></table></figure>
<p>(c), (d), (e) 实现简单的softmax classifer</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftmaxModel</span><span class="params">(Model)</span>:</span></div><div class="line">    <span class="string">"""Implements a Softmax classifier with cross-entropy loss."""</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_placeholders</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Generates placeholder variables to represent the input tensors.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        These placeholders are used as inputs by the rest of the model building</span></div><div class="line"><span class="string">        and will be fed data during training.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Adds following nodes to the computational graph</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        input_placeholder: Input placeholder tensor of shape</span></div><div class="line"><span class="string">                                              (batch_size, n_features), type tf.float32</span></div><div class="line"><span class="string">        labels_placeholder: Labels placeholder tensor of shape</span></div><div class="line"><span class="string">                                              (batch_size, n_classes), type tf.int32</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Add these placeholders to self as the instance variables</span></div><div class="line"><span class="string">            self.input_placeholder</span></div><div class="line"><span class="string">            self.labels_placeholder</span></div><div class="line"><span class="string">        """</span></div><div class="line">        self.input_placeholder = tf.placeholder(dtype=tf.float32, shape=(Config.batch_size, Config.n_features))</div><div class="line">        self.labels_placeholder = tf.placeholder(dtype=tf.int32, shape=(Config.batch_size, Config.n_classes))</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">create_feed_dict</span><span class="params">(self, inputs_batch, labels_batch=None)</span>:</span></div><div class="line">        <span class="string">"""Creates the feed_dict for training the given step.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        A feed_dict takes the form of:</span></div><div class="line"><span class="string">        feed_dict = &#123;</span></div><div class="line"><span class="string">                &lt;placeholder&gt;: &lt;tensor of values to be passed for placeholder&gt;,</span></div><div class="line"><span class="string">                ....</span></div><div class="line"><span class="string">        &#125;</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        If label_batch is None, then no labels are added to feed_dict.</span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">            inputs_batch: A batch of input data.</span></div><div class="line"><span class="string">            labels_batch: A batch of label data.</span></div><div class="line"><span class="string">        Returns:</span></div><div class="line"><span class="string">            feed_dict: The feed dictionary mapping from placeholders to values.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        feed_dict = &#123;</div><div class="line">            self.input_placeholder: inputs_batch,</div><div class="line">            self.labels_placeholder: labels_batch</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> feed_dict</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_prediction_op</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="string">"""Adds the core transformation for this model which transforms a batch of input</span></div><div class="line"><span class="string">        data into a batch of predictions. In this case, the transformation is a linear layer plus a</span></div><div class="line"><span class="string">        softmax transformation:</span></div><div class="line"><span class="string">        y = softmax(Wx + b)</span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">            input_data: A tensor of shape (batch_size, n_features).</span></div><div class="line"><span class="string">        Returns:</span></div><div class="line"><span class="string">            pred: A tensor of shape (batch_size, n_classes)</span></div><div class="line"><span class="string">        """</span></div><div class="line">        W = tf.Variable(tf.zeros(shape=[self.config.n_features, self.config.n_classes]))</div><div class="line">        b = tf.Variable(tf.zeros(shape=[self.config.n_classes]))</div><div class="line">        pred = tf.add(tf.matmul(self.input_placeholder, W), b)</div><div class="line">        pred = softmax(pred)</div><div class="line">        <span class="keyword">return</span> pred</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_loss_op</span><span class="params">(self, pred)</span>:</span></div><div class="line">        <span class="string">"""Adds cross_entropy_loss ops to the computational graph.</span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">            pred: A tensor of shape (batch_size, n_classes)</span></div><div class="line"><span class="string">        Returns:</span></div><div class="line"><span class="string">            loss: A 0-d tensor (scalar)</span></div><div class="line"><span class="string">        """</span></div><div class="line">        loss = cross_entropy_loss(self.labels_placeholder, pred)</div><div class="line">        <span class="keyword">return</span> loss</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_training_op</span><span class="params">(self, loss)</span>:</span></div><div class="line">        <span class="string">"""Sets up the training Ops.</span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">            loss: Loss tensor, from cross_entropy_loss.</span></div><div class="line"><span class="string">        Returns:</span></div><div class="line"><span class="string">            train_op: The Op for training.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        optimizer = tf.train.GradientDescentOptimizer(Config.lr)</div><div class="line">        train_op = optimizer.minimize(loss)</div><div class="line">        <span class="keyword">return</span> train_op</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_epoch</span><span class="params">(self, sess, inputs, labels)</span>:</span></div><div class="line">        <span class="string">"""Runs an epoch of training.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">            sess: tf.Session() object</span></div><div class="line"><span class="string">            inputs: np.ndarray of shape (n_samples, n_features)</span></div><div class="line"><span class="string">            labels: np.ndarray of shape (n_samples, n_classes)</span></div><div class="line"><span class="string">        Returns:</span></div><div class="line"><span class="string">            average_loss: scalar. Average minibatch loss of model on epoch.</span></div><div class="line"><span class="string">        """</span></div><div class="line">        n_minibatches, total_loss = <span class="number">0</span>, <span class="number">0</span></div><div class="line">        <span class="keyword">for</span> input_batch, labels_batch <span class="keyword">in</span> get_minibatches([inputs, labels], self.config.batch_size):</div><div class="line">            n_minibatches += <span class="number">1</span></div><div class="line">            total_loss += self.train_on_batch(sess, input_batch, labels_batch)</div><div class="line">        <span class="keyword">return</span> total_loss / n_minibatches</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, sess, inputs, labels)</span>:</span></div><div class="line">        <span class="string">"""Fit model on provided data.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">            sess: tf.Session()</span></div><div class="line"><span class="string">            inputs: np.ndarray of shape (n_samples, n_features)</span></div><div class="line"><span class="string">            labels: np.ndarray of shape (n_samples, n_classes)</span></div><div class="line"><span class="string">        Returns:</span></div><div class="line"><span class="string">            losses: list of loss per epoch</span></div><div class="line"><span class="string">        """</span></div><div class="line">        losses = []</div><div class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(self.config.n_epochs):</div><div class="line">            start_time = time.time()</div><div class="line">            average_loss = self.run_epoch(sess, inputs, labels)</div><div class="line">            duration = time.time() - start_time</div><div class="line">            <span class="keyword">print</span> <span class="string">'Epoch &#123;:&#125;: loss = &#123;:.2f&#125; (&#123;:.3f&#125; sec)'</span>.format(epoch, average_loss, duration)</div><div class="line">            losses.append(average_loss)</div><div class="line">        <span class="keyword">return</span> losses</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, config)</span>:</span></div><div class="line">        <span class="string">"""Initializes the model.</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">        Args:</span></div><div class="line"><span class="string">            config: A model configuration object of type Config</span></div><div class="line"><span class="string">        """</span></div><div class="line">        self.config = config</div><div class="line">        self.build()</div></pre></td></tr></table></figure>
	  
	</div>

	<div>
  	<center>
	<div class="pagination">

    
    
    <a href="/2018/01/05/Comic-Generation/" type="button" class="btn btn-default"><i
                class="fa fa-arrow-circle-o-left"></i> Prev</a>
    

    <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
    
    <a href="/2017/12/18/CS224n-assignment1/" type="button" class="btn btn-default ">Next<i
                class="fa fa-arrow-circle-o-right"></i></a>
    

    
</div>

    </center>
	</div>
	
	<!-- comment -->
	
<section id="comment">
    <h2 class="title">Comments</h2>

    
</section>


	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2017-12-20 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/algorithms/">algorithms<span>6</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/notes/">notes<span>7</span></a></li>
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2018 Mowayao
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a>,<a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>,<a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a> and <a href="http://getbootstrap.com/" target="_blank">BOOTSTRA.386</a>. 
     <br> Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind.386</a>.    
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>





<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ['\\(','\\)'] ],
      displayMath: [ ['$$','$$'], ['\[','\]'] ], 
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->


</body>
   </html>
